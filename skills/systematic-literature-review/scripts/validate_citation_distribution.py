#!/usr/bin/env python3
"""
validate_citation_distribution.py - éªŒè¯ LaTeX æ–‡ä»¶ä¸­çš„å¼•ç”¨åˆ†å¸ƒ

ç›®æ ‡ï¼šæ£€æŸ¥å¼•ç”¨åˆ†å¸ƒæ˜¯å¦ç¬¦åˆäººç±»å­¦æœ¯å†™ä½œä¹ æƒ¯
- å•ç¯‡å¼•ç”¨ï¼ˆ1ç¯‡ï¼‰ï¼šçº¦ 70%
- å°ç»„å¼•ç”¨ï¼ˆ2-4ç¯‡ï¼‰ï¼šçº¦ 25%
- å¤§ç»„å¼•ç”¨ï¼ˆ>4ç¯‡ï¼‰ï¼š<5%
- å¼•ç”¨å¤šæ ·æ€§ï¼šæ®µè½é—´å¼•ç”¨å‡åŒ€ã€æ–‡çŒ®åˆ©ç”¨ç‡é«˜

ä½¿ç”¨ç¤ºä¾‹ï¼š
    python scripts/validate_citation_distribution.py review.tex
    python scripts/validate_citation_distribution.py review.tex --output report.json
    python scripts/validate_citation_distribution.py review.tex --check-diversity
"""

import argparse
import json
import re
from collections import defaultdict
from pathlib import Path
from statistics import stdev
from typing import Dict, List, Tuple, Optional


def extract_citations(tex_content: str) -> List[Tuple[str, int, int, List[str]]]:
    """
    æå–æ‰€æœ‰ \\cite{} å‘½ä»¤åŠå…¶ä½ç½®

    Args:
        tex_content: LaTeX æ–‡ä»¶å†…å®¹

    Returns:
        List of (cite_command, number_of_keys, line_number, [keys])
    """
    pattern = r'\\cite\{([^}]+)\}'
    citations = []
    lines = tex_content.split('\n')

    for line_num, line in enumerate(lines, 1):
        # è·³è¿‡æ³¨é‡Šè¡Œ
        stripped = line.strip()
        if stripped.startswith('%'):
            continue

        matches = re.finditer(pattern, line)
        for match in matches:
            keys = [k.strip() for k in match.group(1).split(',') if k.strip()]
            n_keys = len(keys)
            citations.append((match.group(0), n_keys, line_num, keys))

    return citations


def analyze_distribution(citations: List[Tuple[str, int, int, List[str]]]) -> Dict:
    """
    åˆ†æå¼•ç”¨åˆ†å¸ƒå¹¶ä¸ç›®æ ‡å¯¹æ¯”

    Args:
        citations: å¼•ç”¨åˆ—è¡¨

    Returns:
        åŒ…å«åˆ†å¸ƒç»Ÿè®¡å’Œé€šè¿‡çŠ¶æ€çš„å­—å…¸
    """
    total = len(citations)
    if total == 0:
        return {
            "error": "No citations found",
            "total_citations": 0
        }

    # ç»Ÿè®¡å„ç±»å‹å¼•ç”¨
    single = sum(1 for _, n, _, _ in citations if n == 1)
    small_group = sum(1 for _, n, _, _ in citations if 2 <= n <= 4)
    large_group = sum(1 for _, n, _, _ in citations if n > 4)

    # è®¡ç®—ç™¾åˆ†æ¯”
    distribution = {
        "total_citations": total,
        "single_cite_count": single,
        "single_cite_pct": round(single / total * 100, 1),
        "small_group_count": small_group,
        "small_group_pct": round(small_group / total * 100, 1),
        "large_group_count": large_group,
        "large_group_pct": round(large_group / total * 100, 1),
        "max_keys_in_one_cite": max(n for _, n, _, _ in citations),
    }

    # ç›®æ ‡èŒƒå›´ï¼ˆå…è®¸ä¸€å®šå®¹å·®ï¼‰
    target = {
        "single_target": 70.0,
        "single_tolerance": 5.0,  # 65%-75%
        "small_group_target": 25.0,
        "small_group_tolerance": 5.0,  # 20%-30%
        "large_group_max": 5.0,
        "large_group_tolerance": 5.0,  # å…è®¸åˆ° 10%
    }

    # æ£€æŸ¥æ˜¯å¦ç¬¦åˆç›®æ ‡
    single_ok = abs(distribution["single_cite_pct"] - target["single_target"]) <= target["single_tolerance"]
    small_group_ok = abs(distribution["small_group_pct"] - target["small_group_target"]) <= target["small_group_tolerance"]
    large_group_ok = distribution["large_group_pct"] <= (target["large_group_max"] + target["large_group_tolerance"])

    status = {
        "single_ok": single_ok,
        "small_group_ok": small_group_ok,
        "large_group_ok": large_group_ok,
        "overall_pass": single_ok and small_group_ok and large_group_ok
    }

    return {
        "distribution": distribution,
        "target": target,
        "status": status
    }


def find_violations(citations: List[Tuple[str, int, int, List[str]]], threshold: int = 5) -> List[Dict]:
    """
    æ‰¾å‡ºè¿è§„çš„å¼•ç”¨ï¼ˆå¼•ç”¨æ•°é‡è¶…è¿‡é˜ˆå€¼ï¼‰

    Args:
        citations: å¼•ç”¨åˆ—è¡¨
        threshold: å¼•ç”¨æ•°é‡é˜ˆå€¼ï¼Œé»˜è®¤ 5

    Returns:
        è¿è§„å¼•ç”¨åˆ—è¡¨
    """
    violations = []
    for cite_cmd, n_keys, line_num, _ in citations:
        if n_keys > threshold:
            violations.append({
                "line": line_num,
                "citation": cite_cmd,
                "count": n_keys
            })
    return violations


def generate_recommendations(result: Dict, violations: List[Dict]) -> List[str]:
    """
    æ ¹æ®åˆ†æç»“æœç”Ÿæˆæ”¹è¿›å»ºè®®

    Args:
        result: åˆ†æç»“æœ
        violations: è¿è§„åˆ—è¡¨

    Returns:
        å»ºè®®åˆ—è¡¨
    """
    recommendations = []

    dist = result.get("distribution", {})
    status = result.get("status", {})

    # æ£€æŸ¥å•ç¯‡å¼•ç”¨æ¯”ä¾‹
    if not status.get("single_ok", True):
        single_pct = dist.get("single_cite_pct", 0)
        if single_pct < 65:
            recommendations.append(
                "å•ç¯‡å¼•ç”¨æ¯”ä¾‹è¿‡ä½ï¼ˆå½“å‰ {:.1f}%ï¼‰ã€‚å»ºè®®å°†å¤šç¯‡å¼•ç”¨æ‹†åˆ†ä¸ºå¤šä¸ªç‹¬ç«‹çš„å¼•ç”¨é™ˆè¿°ã€‚".format(single_pct)
            )
        elif single_pct > 75:
            recommendations.append(
                "å•ç¯‡å¼•ç”¨æ¯”ä¾‹è¿‡é«˜ï¼ˆå½“å‰ {:.1f}%ï¼‰ã€‚å»ºè®®é€‚å½“å¢åŠ å¯¹æ¯”æ–‡çŒ®çš„å¼•ç”¨ã€‚".format(single_pct)
            )

    # æ£€æŸ¥å¤§ç»„å¼•ç”¨
    if not status.get("large_group_ok", True):
        large_pct = dist.get("large_group_pct", 0)
        recommendations.append(
            "å¤§ç»„å¼•ç”¨ï¼ˆ>4ç¯‡ï¼‰æ¯”ä¾‹è¿‡é«˜ï¼ˆå½“å‰ {:.1f}%ï¼‰ã€‚å»ºè®®å°†æ–‡çŒ®æŒ‰è§‚ç‚¹æ‹†åˆ†ï¼Œé‡‡ç”¨'å¼•ç”¨+é˜è¿°+å†å¼•ç”¨'çš„æ¨¡å¼ã€‚".format(large_pct)
        )

    # æ£€æŸ¥ä¸¥é‡è¿è§„
    if violations:
        max_count = max(v["count"] for v in violations)
        if max_count > 10:
            recommendations.append(
                "å­˜åœ¨å•æ¬¡å¼•ç”¨ {} ç¯‡æ–‡çŒ®çš„ä¸¥é‡è¿è§„æƒ…å†µã€‚è¿™æ˜¯'å¼•ç”¨å †ç Œ'çš„å…¸å‹ç‰¹å¾ï¼Œå¿…é¡»ç«‹å³ä¿®æ­£ã€‚".format(max_count)
            )

    if not recommendations:
        recommendations.append("å¼•ç”¨åˆ†å¸ƒç¬¦åˆç›®æ ‡ï¼Œç»§ç»­ä¿æŒã€‚")

    return recommendations


# ===================================================================
# å¼•ç”¨å¤šæ ·æ€§æ£€æµ‹ï¼ˆCitation Diversityï¼‰åŠŸèƒ½
# ===================================================================

def parse_paragraphs(tex_content: str) -> List[Dict]:
    """
    è§£æ LaTeX å†…å®¹ä¸ºæ®µè½åˆ—è¡¨ï¼Œç»Ÿè®¡æ¯æ®µçš„å¼•ç”¨æ•°

    Args:
        tex_content: LaTeX æ–‡ä»¶å†…å®¹

    Returns:
        æ®µè½åˆ—è¡¨ï¼Œæ¯ä¸ªæ®µè½åŒ…å« text, cite_count, line_start, line_end
    """
    paragraphs = []
    lines = tex_content.split('\n')

    i = 0
    while i < len(lines):
        line = lines[i].strip()

        # è·³è¿‡æ³¨é‡Šè¡Œã€ç©ºè¡Œã€LaTeX å‘½ä»¤è¡Œ
        if not line or line.startswith('%') or line.startswith('\\'):
            i += 1
            continue

        # æ”¶é›†æ®µè½å†…å®¹ï¼ˆç›´åˆ°ç©ºè¡Œæˆ–æ–°å‘½ä»¤ï¼‰
        paragraph_lines = []
        start_line = i + 1
        while i < len(lines):
            current = lines[i].strip()
            if not current or current.startswith('\\') and current.startswith('%'):
                break
            paragraph_lines.append(lines[i])
            i += 1

        if paragraph_lines:
            paragraph_text = '\n'.join(paragraph_lines)
            cite_count = len(re.findall(r'\\cite\{[^}]+\}', paragraph_text))
            paragraphs.append({
                'text': paragraph_text[:100] + '...' if len(paragraph_text) > 100 else paragraph_text,
                'cite_count': cite_count,
                'line_start': start_line,
                'line_end': i
            })

        i += 1

    return paragraphs


def extract_bib_keys(bib_content: str) -> set:
    """
    ä» BibTeX æ–‡ä»¶å†…å®¹ä¸­æå–æ‰€æœ‰æ¡ç›®çš„ key

    Args:
        bib_content: BibTeX æ–‡ä»¶å†…å®¹

    Returns:
        æ‰€æœ‰æ–‡çŒ® key çš„é›†åˆ
    """
    pattern = r'@+\w+\s*\{([^,]+),'
    keys = re.findall(pattern, bib_content)
    return set(keys)


def check_citation_diversity(
    tex_content: str,
    citations: List[Tuple[str, int, int, List[str]]],
    bib_keys: Optional[set] = None,
    *,
    min_ref_util: Optional[float] = None,
) -> Dict:
    """
    æ£€æŸ¥å¼•ç”¨å¤šæ ·æ€§ï¼ŒåŒ…å« 4 ä¸ªç»´åº¦ï¼š
    1. é›¶å¼•ç”¨æ®µè½ç‡
    2. æ®µè½å¼•ç”¨å¯†åº¦æ–¹å·®
    3. æ–‡çŒ®åˆ©ç”¨ç‡
    4. é«˜é¢‘æ–‡çŒ®å æ¯”

    Args:
        tex_content: LaTeX æ–‡ä»¶å†…å®¹
        citations: å¼•ç”¨åˆ—è¡¨
        bib_keys: BibTeX æ–‡çŒ® key é›†åˆï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æä¾›åˆ™è·³è¿‡æ–‡çŒ®åˆ©ç”¨ç‡æ£€æµ‹ï¼‰

    Returns:
        åŒ…å« 4 ä¸ªæŒ‡æ ‡åŠé€šè¿‡çŠ¶æ€çš„å­—å…¸
    """
    # è§£ææ®µè½
    paragraphs = parse_paragraphs(tex_content)
    total_paragraphs = len(paragraphs)

    if total_paragraphs == 0:
        return {
            "error": "No content paragraphs found",
            "diversity_metrics": {}
        }

    # æŒ‡æ ‡ 1ï¼šé›¶å¼•ç”¨æ®µè½ç‡
    zero_cite_paragraphs = [p for p in paragraphs if p['cite_count'] == 0]
    zero_cite_rate = round(len(zero_cite_paragraphs) / total_paragraphs * 100, 1)

    # æŒ‡æ ‡ 2ï¼šæ®µè½å¼•ç”¨å¯†åº¦æ–¹å·®
    cite_counts = [p['cite_count'] for p in paragraphs]
    cite_variance = round(stdev(cite_counts), 2) if len(cite_counts) > 1 else 0.0

    # æŒ‡æ ‡ 3ï¼šæ–‡çŒ®åˆ©ç”¨ç‡ï¼ˆéœ€è¦æä¾› bib_keysï¼‰
    reference_utilization = None
    if bib_keys:
        used_keys = set()
        for _, _, _, keys in citations:
            used_keys.update(keys)
        reference_utilization = round(len(used_keys) / len(bib_keys) * 100, 1)

    # æŒ‡æ ‡ 4ï¼šé«˜é¢‘æ–‡çŒ®å æ¯”ï¼ˆè¢«å¼•ç”¨ >=5 æ¬¡ï¼‰
    key_freq = defaultdict(int)
    for _, _, _, keys in citations:
        for key in keys:
            key_freq[key] += 1

    if key_freq:
        high_freq_count = sum(1 for f in key_freq.values() if f >= 5)
        high_freq_rate = round(high_freq_count / len(key_freq) * 100, 1)
    else:
        high_freq_rate = 0.0

    # æ±‡æ€»ç»“æœ
    diversity_metrics = {
        "zero_cite_rate": zero_cite_rate,
        "zero_cite_count": len(zero_cite_paragraphs),
        "total_paragraphs": total_paragraphs,
        "cite_variance": cite_variance,
        "avg_cites_per_paragraph": round(sum(cite_counts) / total_paragraphs, 1),
        "reference_utilization": reference_utilization,
        "high_freq_rate": high_freq_rate,
        "high_freq_count": high_freq_count if key_freq else 0,
        "total_unique_references": len(key_freq) if key_freq else 0,
    }

    # ç›®æ ‡é˜ˆå€¼
    # æ³¨æ„ï¼šæ–‡çŒ®åˆ©ç”¨ç‡é»˜è®¤ä»…æç¤ºï¼Œä¸ä½œä¸ºç¡¬æ€§é—¨æ§›ï¼›éœ€è¦æ—¶å¯ç”¨ --min-ref-util å¯ç”¨ç¡¬é—¨æ§›ã€‚
    target = {
        "zero_cite_max": 10.0,  # é›¶å¼•ç”¨æ®µè½ç‡ <10%
        "cite_variance_max": 3.0,  # æ–¹å·® <3
        "ref_util_min": float(min_ref_util) if min_ref_util is not None else None,
        "high_freq_max": 15.0,  # é«˜é¢‘å æ¯” <15%
    }

    # æ£€æŸ¥é€šè¿‡çŠ¶æ€
    ref_util_ok = True
    if target["ref_util_min"] is not None and reference_utilization is not None:
        ref_util_ok = reference_utilization >= float(target["ref_util_min"])

    status = {
        "zero_cite_ok": zero_cite_rate < target["zero_cite_max"],
        "cite_variance_ok": cite_variance < target["cite_variance_max"],
        "ref_util_ok": ref_util_ok,
        "high_freq_ok": high_freq_rate < target["high_freq_max"],
        "overall_pass": (
            zero_cite_rate < target["zero_cite_max"] and
            cite_variance < target["cite_variance_max"] and
            ref_util_ok and
            high_freq_rate < target["high_freq_max"]
        )
    }

    return {
        "diversity_metrics": diversity_metrics,
        "target": target,
        "status": status,
        "zero_cite_paragraphs": zero_cite_paragraphs[:10],  # æœ€å¤šè¿”å›å‰10ä¸ª
        "cite_distribution": cite_counts
    }


def find_zero_cite_paragraphs(tex_content: str) -> List[Dict]:
    """
    æ‰¾å‡ºæ‰€æœ‰é›¶å¼•ç”¨æ®µè½

    Args:
        tex_content: LaTeX æ–‡ä»¶å†…å®¹

    Returns:
        é›¶å¼•ç”¨æ®µè½åˆ—è¡¨
    """
    paragraphs = parse_paragraphs(tex_content)
    return [p for p in paragraphs if p['cite_count'] == 0]


def generate_diversity_recommendations(diversity_result: Dict) -> List[str]:
    """
    æ ¹æ®å¼•ç”¨å¤šæ ·æ€§æ£€æµ‹ç»“æœç”Ÿæˆæ”¹è¿›å»ºè®®

    Args:
        diversity_result: check_citation_diversity() è¿”å›çš„ç»“æœ

    Returns:
        å»ºè®®åˆ—è¡¨
    """
    recommendations = []
    metrics = diversity_result.get("diversity_metrics", {})
    status = diversity_result.get("status", {})
    target = diversity_result.get("target", {})

    # æ£€æŸ¥é›¶å¼•ç”¨æ®µè½
    if not status.get("zero_cite_ok", True):
        zero_rate = metrics.get("zero_cite_rate", 0)
        zero_count = metrics.get("zero_cite_count", 0)
        recommendations.append(
            f"é›¶å¼•ç”¨æ®µè½æ¯”ä¾‹è¿‡é«˜ï¼ˆå½“å‰ {zero_rate}%ï¼Œå…± {zero_count} æ®µï¼‰ã€‚"
            f"å»ºè®®ï¼šæ¯ä¸ªæ®µè½è‡³å°‘å¼•ç”¨ 1-2 ç¯‡æ–‡çŒ®ä»¥æä¾›è¯æ®æ”¯æ’‘ã€‚"
        )

    # æ£€æŸ¥å¼•ç”¨å¯†åº¦æ–¹å·®
    if not status.get("cite_variance_ok", True):
        variance = metrics.get("cite_variance", 0)
        recommendations.append(
            f"æ®µè½å¼•ç”¨å¯†åº¦åˆ†å¸ƒä¸å‡ï¼ˆæ–¹å·® {variance}ï¼Œç›®æ ‡ <3ï¼‰ã€‚"
            f"å»ºè®®ï¼šå¹³è¡¡å„æ®µè½çš„å¼•ç”¨æ•°é‡ï¼Œé¿å…æŸæ®µè¿‡åº¦å¼•ç”¨è€Œå…¶ä»–æ®µè½å¼•ç”¨ä¸è¶³ã€‚"
        )

    # æ£€æŸ¥æ–‡çŒ®åˆ©ç”¨ç‡
    if target.get("ref_util_min") is not None and not status.get("ref_util_ok", True):
        util = metrics.get("reference_utilization", 0)
        total_refs = metrics.get("total_unique_references", 0)
        recommendations.append(
            f"æ–‡çŒ®åˆ©ç”¨ç‡åä½ï¼ˆå½“å‰ {util}%ï¼Œä»… {total_refs} ç¯‡è¢«å¼•ç”¨ï¼‰ã€‚"
            f"å»ºè®®ï¼šä¸è¦ä¸ºâ€œç”¨å®Œæ–‡çŒ®â€è€Œå¼ºè¡ŒåŠ å¼•ç”¨ï¼›ä¼˜å…ˆå›åˆ°é€‰æ–‡é˜¶æ®µå‡å°‘å™ªå£°ï¼Œæˆ–æŠŠé‡è¦æ–‡çŒ®å¯¹åº”çš„è§‚ç‚¹å†™å‡ºæ¥å†è‡ªç„¶å¼•ç”¨ã€‚"
        )

    # æ£€æŸ¥é«˜é¢‘æ–‡çŒ®
    if not status.get("high_freq_ok", True):
        high_freq_rate = metrics.get("high_freq_rate", 0)
        recommendations.append(
            f"é«˜é¢‘æ–‡çŒ®å æ¯”è¿‡é«˜ï¼ˆå½“å‰ {high_freq_rate}%ï¼‰ã€‚"
            f"å»ºè®®ï¼šé¿å…è¿‡åº¦ä¾èµ–å°‘æ•°å‡ ç¯‡æ–‡çŒ®ï¼Œåº”å¢åŠ å¼•ç”¨çš„å¤šæ ·æ€§ä»¥ä½“ç°å…¨é¢è°ƒç ”ã€‚"
        )

    if not recommendations:
        recommendations.append("å¼•ç”¨å¤šæ ·æ€§ç¬¦åˆç›®æ ‡ï¼Œç»§ç»­ä¿æŒã€‚")

    return recommendations


def main():
    parser = argparse.ArgumentParser(
        description='éªŒè¯ LaTeX æ–‡ä»¶ä¸­çš„å¼•ç”¨åˆ†å¸ƒæ˜¯å¦ç¬¦åˆäººç±»å­¦æœ¯å†™ä½œä¹ æƒ¯',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç›®æ ‡åˆ†å¸ƒï¼ˆåŸºäºäººç±»å­¦æœ¯å†™ä½œä¹ æƒ¯ï¼‰ï¼š
  - å•ç¯‡å¼•ç”¨ï¼ˆ1ç¯‡ï¼‰ï¼šçº¦ 70%%
  - å°ç»„å¼•ç”¨ï¼ˆ2-4ç¯‡ï¼‰ï¼šçº¦ 25%%
  - å¤§ç»„å¼•ç”¨ï¼ˆ>4ç¯‡ï¼‰ï¼š<5%%

å¼•ç”¨å¤šæ ·æ€§æŒ‡æ ‡ï¼š
  - é›¶å¼•ç”¨æ®µè½ç‡ï¼š<10%%
  - æ®µè½å¼•ç”¨å¯†åº¦æ–¹å·®ï¼š<3
  - æ–‡çŒ®åˆ©ç”¨ç‡ï¼šé»˜è®¤ä»…æç¤ºå±•ç¤ºï¼ˆå¯ç”¨ --min-ref-util å¯ç”¨ç¡¬é—¨æ§›ï¼‰
  - é«˜é¢‘æ–‡çŒ®å æ¯”ï¼š<15%%

ç¤ºä¾‹ï¼š
  %(prog)s review.tex
  %(prog)s review.tex --output report.json
  %(prog)s review.tex --threshold 4
  %(prog)s review.tex --check-diversity --bib references.bib
        """
    )

    parser.add_argument('tex_file', help='LaTeX æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', '-o', help='è¾“å‡º JSON ç»“æœåˆ°æ–‡ä»¶')
    parser.add_argument('--threshold', '-t', type=int, default=5,
                        help='è¿è§„é˜ˆå€¼ï¼ˆå•æ¬¡å¼•ç”¨è¶…è¿‡æ­¤æ•°é‡å°†è¢«æ ‡è®°ï¼Œé»˜è®¤ï¼š5ï¼‰')
    parser.add_argument('--verbose', '-v', action='store_true',
                        help='æ˜¾ç¤ºè¯¦ç»†è¾“å‡º')
    parser.add_argument('--check-diversity', '-d', action='store_true',
                        help='å¯ç”¨å¼•ç”¨å¤šæ ·æ€§æ£€æµ‹ï¼ˆéœ€è¦ --bib å‚æ•°ï¼‰')
    parser.add_argument('--bib', '-b', help='BibTeX æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºæ–‡çŒ®åˆ©ç”¨ç‡æ£€æµ‹ï¼‰')
    parser.add_argument('--min-ref-util', type=float, default=None,
                        help='å¯é€‰ï¼šå¯ç”¨æ–‡çŒ®åˆ©ç”¨ç‡ç¡¬é—¨æ§›ï¼ˆä¾‹å¦‚ 60/70/85ï¼‰ï¼›é»˜è®¤ä»…å±•ç¤ºæŒ‡æ ‡ï¼Œä¸åšç¡¬æ€§é—¨æ§›')

    args = parser.parse_args()

    tex_path = Path(args.tex_file)
    if not tex_path.exists():
        print(f"âŒ é”™è¯¯ï¼šæ–‡ä»¶ä¸å­˜åœ¨ {tex_path}")
        return 1

    # è¯»å– LaTeX æ–‡ä»¶
    try:
        tex_content = tex_path.read_text(encoding='utf-8')
    except Exception as e:
        print(f"âŒ é”™è¯¯ï¼šæ— æ³•è¯»å–æ–‡ä»¶ {e}")
        return 1

    # æå–å¼•ç”¨
    citations = extract_citations(tex_content)

    if not citations:
        print(f"âš ï¸  è­¦å‘Šï¼šæœªæ‰¾åˆ°ä»»ä½• \\cite{{}} å‘½ä»¤")
        return 0

    # åˆ†æå¼•ç”¨åˆ†å¸ƒ
    result = analyze_distribution(citations)

    # æ‰¾å‡ºè¿è§„
    violations = find_violations(citations, args.threshold)

    # ç”Ÿæˆå»ºè®®
    recommendations = generate_recommendations(result, violations)

    # å¼•ç”¨å¤šæ ·æ€§æ£€æµ‹ï¼ˆå¯é€‰ï¼‰
    diversity_result = None
    diversity_recommendations = []
    if args.check_diversity:
        bib_keys = None
        if args.bib:
            bib_path = Path(args.bib)
            if bib_path.exists():
                try:
                    bib_content = bib_path.read_text(encoding='utf-8')
                    bib_keys = extract_bib_keys(bib_content)
                except Exception as e:
                    print(f"âš ï¸  è­¦å‘Šï¼šæ— æ³•è¯»å– BibTeX æ–‡ä»¶ {e}")
            else:
                print(f"âš ï¸  è­¦å‘Šï¼šBibTeX æ–‡ä»¶ä¸å­˜åœ¨ {args.bib}")
        else:
            print("â„¹ï¸  æç¤ºï¼šæœªæä¾› --bib å‚æ•°ï¼Œæ–‡çŒ®åˆ©ç”¨ç‡æ£€æµ‹å°†è¢«è·³è¿‡")

        diversity_result = check_citation_diversity(
            tex_content,
            citations,
            bib_keys,
            min_ref_util=args.min_ref_util,
        )
        diversity_recommendations = generate_diversity_recommendations(diversity_result)

    # è¾“å‡ºæŠ¥å‘Š
    print("=" * 70)
    print("ğŸ“Š å¼•ç”¨åˆ†å¸ƒéªŒè¯æŠ¥å‘Š")
    print("=" * 70)
    print(f"æ–‡ä»¶: {tex_path}")
    print(f"æ€»å¼•ç”¨æ¬¡æ•°: {result['distribution']['total_citations']}")
    print()

    print("ğŸ“ˆ åˆ†å¸ƒç»Ÿè®¡:")
    print(f"  å•ç¯‡å¼•ç”¨ (1ç¯‡):     {result['distribution']['single_cite_count']:4d} æ¬¡ ({result['distribution']['single_cite_pct']:5.1f}%)  [ç›®æ ‡: 70% Â±5%]")
    print(f"  å°ç»„å¼•ç”¨ (2-4ç¯‡):   {result['distribution']['small_group_count']:4d} æ¬¡ ({result['distribution']['small_group_pct']:5.1f}%)  [ç›®æ ‡: 25% Â±5%]")
    print(f"  å¤§ç»„å¼•ç”¨ (>4ç¯‡):    {result['distribution']['large_group_count']:4d} æ¬¡ ({result['distribution']['large_group_pct']:5.1f}%)  [ç›®æ ‡: <5% Â±5%]")
    print()
    print(f"ğŸ“Š å•æ¬¡æœ€å¤§å¼•ç”¨æ•°: {result['distribution']['max_keys_in_one_cite']} ç¯‡")
    print()

    print("âœ… çŠ¶æ€æ£€æŸ¥:")
    print(f"  å•ç¯‡å¼•ç”¨:   {'âœ“ é€šè¿‡' if result['status']['single_ok'] else 'âœ— å¤±è´¥'}")
    print(f"  å°ç»„å¼•ç”¨:   {'âœ“ é€šè¿‡' if result['status']['small_group_ok'] else 'âœ— å¤±è´¥'}")
    print(f"  å¤§ç»„å¼•ç”¨:   {'âœ“ é€šè¿‡' if result['status']['large_group_ok'] else 'âœ— å¤±è´¥'}")
    print()
    print(f"{'ğŸ‰ åˆ†å¸ƒæ€»ä½“ç»“æœ: âœ“ é€šè¿‡' if result['status']['overall_pass'] else 'âŒ åˆ†å¸ƒæ€»ä½“ç»“æœ: âœ— å¤±è´¥'}")
    print()

    # æ˜¾ç¤ºè¿è§„
    if violations:
        print(f"âš ï¸  è¿è§„å¼•ç”¨ (>{args.threshold}ç¯‡) å…± {len(violations)} å¤„:")
        for v in violations[:20]:
            print(f"  è¡Œ {v['line']:4d}: {v['citation'][:60]}{'...' if len(v['citation'])>60 else ''} ({v['count']}ç¯‡)")
        if len(violations) > 20:
            print(f"  ... è¿˜æœ‰ {len(violations)-20} å¤„æœªæ˜¾ç¤º")
        print()

    # æ˜¾ç¤ºå¼•ç”¨å¤šæ ·æ€§æŠ¥å‘Š
    if diversity_result:
        print("ğŸŒ å¼•ç”¨å¤šæ ·æ€§æ£€æµ‹:")
        print("-" * 70)

        if "error" in diversity_result:
            print(f"âš ï¸  {diversity_result['error']}")
        else:
            metrics = diversity_result['diversity_metrics']
            status = diversity_result['status']
            target = diversity_result.get('target', {})

            print(f"  é›¶å¼•ç”¨æ®µè½ç‡:     {metrics['zero_cite_rate']:5.1f}% ({metrics['zero_cite_count']}/{metrics['total_paragraphs']})  [ç›®æ ‡: <10%]  {'âœ“' if status['zero_cite_ok'] else 'âœ—'}")
            print(f"  æ®µè½å¼•ç”¨å¯†åº¦æ–¹å·®: {metrics['cite_variance']:5.2f}  [ç›®æ ‡: <3]  {'âœ“' if status['cite_variance_ok'] else 'âœ—'}")
            print(f"  å¹³å‡æ¯æ®µå¼•ç”¨æ•°:   {metrics['avg_cites_per_paragraph']:5.1f}")

            if metrics['reference_utilization'] is not None:
                if target.get("ref_util_min") is None:
                    print(f"  æ–‡çŒ®åˆ©ç”¨ç‡:       {metrics['reference_utilization']:5.1f}% ({metrics['total_unique_references']} ç¯‡è¢«å¼•ç”¨)  [æç¤ºé¡¹ï¼šä¸åšç¡¬æ€§é—¨æ§›]")
                else:
                    print(f"  æ–‡çŒ®åˆ©ç”¨ç‡:       {metrics['reference_utilization']:5.1f}% ({metrics['total_unique_references']} ç¯‡è¢«å¼•ç”¨)  [ç›®æ ‡: >{target['ref_util_min']:.0f}%]  {'âœ“' if status['ref_util_ok'] else 'âœ—'}")
            else:
                print(f"  æ–‡çŒ®åˆ©ç”¨ç‡:       (æœªæä¾› BibTeX æ–‡ä»¶)")

            print(f"  é«˜é¢‘æ–‡çŒ®å æ¯”:     {metrics['high_freq_rate']:5.1f}% ({metrics['high_freq_count']} ç¯‡è¢«å¼•ç”¨â‰¥5æ¬¡)  [ç›®æ ‡: <15%]  {'âœ“' if status['high_freq_ok'] else 'âœ—'}")
            print()
            print(f"{'ğŸ‰ å¤šæ ·æ€§æ€»ä½“ç»“æœ: âœ“ é€šè¿‡' if status['overall_pass'] else 'âŒ å¤šæ ·æ€§æ€»ä½“ç»“æœ: âœ— å¤±è´¥'}")
            print()

            # æ˜¾ç¤ºé›¶å¼•ç”¨æ®µè½
            if diversity_result.get('zero_cite_paragraphs'):
                print(f"ğŸ“Œ é›¶å¼•ç”¨æ®µè½ (å…± {metrics['zero_cite_count']} æ®µ):")
                for p in diversity_result['zero_cite_paragraphs'][:5]:
                    print(f"  è¡Œ {p['line_start']:4d}: {p['text'][:60]}...")
                if metrics['zero_cite_count'] > 5:
                    print(f"  ... è¿˜æœ‰ {metrics['zero_cite_count']-5} æ®µæœªæ˜¾ç¤º")
                print()
        print()

    # æ˜¾ç¤ºå»ºè®®
    all_recommendations = recommendations + diversity_recommendations
    if args.verbose or not result['status']['overall_pass'] or (diversity_result and not diversity_result['status']['overall_pass']):
        print("ğŸ’¡ æ”¹è¿›å»ºè®®:")
        for i, rec in enumerate(all_recommendations, 1):
            print(f"  {i}. {rec}")
        print()

    # è¾“å‡º JSON
    if args.output:
        output_data = {
            "file": str(tex_path),
            "result": result,
            "violations": violations,
            "recommendations": recommendations,
            "diversity_result": diversity_result,
            "diversity_recommendations": diversity_recommendations
        }
        try:
            with open(args.output, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, ensure_ascii=False, indent=2)
            print(f"ğŸ“ ç»“æœå·²ä¿å­˜è‡³: {args.output}")
        except Exception as e:
            print(f"âš ï¸  æ— æ³•ä¿å­˜è¾“å‡ºæ–‡ä»¶: {e}")

    # è¿”å›çŠ¶æ€ï¼šä»»ä¸€æ£€æµ‹å¤±è´¥åˆ™è¿”å› 1
    pass_dist = result['status']['overall_pass']
    pass_div = diversity_result['status']['overall_pass'] if diversity_result else True
    return 0 if (pass_dist and pass_div) else 1


if __name__ == '__main__':
    exit(main())
