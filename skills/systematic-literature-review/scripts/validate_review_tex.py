#!/usr/bin/env python3
"""
validate_review_tex.py - è½»é‡æ ¡éªŒï¼šå¿…éœ€ç« èŠ‚ + cite/bib å¯¹é½ + å¼•ç”¨æ•°é‡ä¸Šä¸‹é™
"""

from __future__ import annotations

import argparse
import re
import sys
from pathlib import Path


def _read(p: Path) -> str:
    return p.read_text(encoding="utf-8", errors="replace")


def _extract_cite_keys(tex: str) -> set[str]:
    keys: set[str] = set()
    cite_pattern = re.compile(r"\\cite[a-zA-Z*]*\s*(?:\[[^\]]*\]\s*)*\{([^}]*)\}", re.MULTILINE)
    for m in cite_pattern.finditer(tex):
        for part in m.group(1).split(","):
            k = part.strip()
            if k:
                keys.add(k)
    return keys


def _extract_bib_keys(bib: str) -> set[str]:
    keys: set[str] = set()
    # Match BibTeX entries like "@article{key," and capture the key
    for m in re.finditer(r"@\w+\s*\{\s*([^,\s]+)\s*,", bib):
        keys.add(m.group(1).strip())
    return keys


def _has_keyword(text: str, keywords: list[str]) -> bool:
    lowered = text.lower()
    return any(k.lower() in lowered for k in keywords)


def _check_citation_distribution(tex: str, verbose: bool = False) -> dict:
    """
    æ£€æŸ¥å¼•ç”¨åˆ†å¸ƒæ˜¯å¦ç¬¦åˆç›®æ ‡æ ‡å‡†
    ç›®æ ‡ï¼š70% å•ç¯‡å¼•ç”¨ï¼Œ25% å¼•ç”¨ 2-4 ç¯‡ï¼Œ<5% å¼•ç”¨ >4 ç¯‡

    Returns:
        åŒ…å«é€šè¿‡çŠ¶æ€å’Œè¯¦ç»†ä¿¡æ¯çš„å­—å…¸
    """
    import json

    # æå–æ‰€æœ‰ \cite{} å‘½ä»¤
    cite_pattern = re.compile(r"\\cite\{([^}]+)\}", re.MULTILINE)
    citations = []

    lines = tex.split('\n')
    for line_num, line in enumerate(lines, 1):
        # è·³è¿‡æ³¨é‡Šè¡Œ
        stripped = line.strip()
        if stripped.startswith('%'):
            continue

        matches = cite_pattern.finditer(line)
        for match in matches:
            keys = match.group(1).split(',')
            n_keys = len([k.strip() for k in keys if k.strip()])
            citations.append({
                "command": match.group(0),
                "count": n_keys,
                "line": line_num
            })

    if not citations:
        return {
            "passed": False,
            "error": "No citations found",
            "details": {}
        }

    # ç»Ÿè®¡åˆ†å¸ƒ
    total = len(citations)
    single = sum(1 for c in citations if c["count"] == 1)
    small_group = sum(1 for c in citations if 2 <= c["count"] <= 4)
    large_group = sum(1 for c in citations if c["count"] > 4)

    details = {
        "total_citations": total,
        "single_cite_count": single,
        "single_cite_pct": round(single / total * 100, 1),
        "small_group_count": small_group,
        "small_group_pct": round(small_group / total * 100, 1),
        "large_group_count": large_group,
        "large_group_pct": round(large_group / total * 100, 1),
        "max_keys_in_one_cite": max(c["count"] for c in citations),
    }

    # æ£€æŸ¥æ˜¯å¦ç¬¦åˆç›®æ ‡ï¼ˆå…è®¸ä¸€å®šå®¹å·®ï¼‰
    single_ok = 65 <= details["single_cite_pct"] <= 75
    small_group_ok = 20 <= details["small_group_pct"] <= 30
    large_group_ok = details["large_group_pct"] <= 10

    passed = single_ok and small_group_ok and large_group_ok

    # æ‰¾å‡ºè¿è§„å¼•ç”¨ï¼ˆ>5ç¯‡ï¼‰
    violations = [c for c in citations if c["count"] > 5]

    if verbose:
        print("\n" + "=" * 60)
        print("ğŸ“Š å¼•ç”¨åˆ†å¸ƒéªŒè¯", file=sys.stderr)
        print("=" * 60, file=sys.stderr)
        print(f"  å•ç¯‡å¼•ç”¨ (1ç¯‡):     {single:4d} æ¬¡ ({details['single_cite_pct']:5.1f}%)  [ç›®æ ‡: 70% Â±5%] {'âœ“' if single_ok else 'âœ—'}", file=sys.stderr)
        print(f"  å°ç»„å¼•ç”¨ (2-4ç¯‡):   {small_group:4d} æ¬¡ ({details['small_group_pct']:5.1f}%)  [ç›®æ ‡: 25% Â±5%] {'âœ“' if small_group_ok else 'âœ—'}", file=sys.stderr)
        print(f"  å¤§ç»„å¼•ç”¨ (>4ç¯‡):    {large_group:4d} æ¬¡ ({details['large_group_pct']:5.1f}%)  [ç›®æ ‡: <5% Â±5%] {'âœ“' if large_group_ok else 'âœ—'}", file=sys.stderr)
        print(f"\n  å•æ¬¡æœ€å¤§å¼•ç”¨æ•°: {details['max_keys_in_one_cite']} ç¯‡", file=sys.stderr)

        if violations:
            print(f"\nâš ï¸  è¿è§„å¼•ç”¨ (>5ç¯‡) å…± {len(violations)} å¤„:", file=sys.stderr)
            for v in violations[:10]:
                print(f"  è¡Œ {v['line']:4d}: {v['command'][:50]}{'...' if len(v['command'])>50 else ''} ({v['count']}ç¯‡)", file=sys.stderr)
            if len(violations) > 10:
                print(f"  ... è¿˜æœ‰ {len(violations)-10} å¤„", file=sys.stderr)

        print(f"\n{'ğŸ‰ å¼•ç”¨åˆ†å¸ƒ: âœ“ é€šè¿‡' if passed else 'âŒ å¼•ç”¨åˆ†å¸ƒ: âœ— å¤±è´¥'}", file=sys.stderr)
        print("=" * 60 + "\n", file=sys.stderr)

    return {
        "passed": passed,
        "details": details,
        "violations_count": len(violations),
        "worst_violation": max(v["count"] for v in violations) if violations else 0
    }


def main() -> int:
    parser = argparse.ArgumentParser(description="Validate review.tex + references.bib (required sections + citations).")
    parser.add_argument("--tex", required=True, type=Path, help="Path to review.tex")
    parser.add_argument("--bib", required=True, type=Path, help="Path to references.bib")
    parser.add_argument("--min-refs", type=int, default=0, help="Minimum unique citation keys")
    parser.add_argument("--max-refs", type=int, default=0, help="Maximum unique citation keys (0 = no limit)")
    parser.add_argument("--check-citation-dist", action="store_true",
                        # argparse ä¼šå¯¹ help æ–‡æœ¬åš %-formattingï¼›è¿™é‡Œéœ€è¦å¯¹å­—é¢é‡ % è¿›è¡Œè½¬ä¹‰
                        help="æ£€æŸ¥å¼•ç”¨åˆ†å¸ƒæ˜¯å¦ç¬¦åˆç›®æ ‡ï¼ˆ70%% å•ç¯‡ï¼Œ25%% 2-4ç¯‡ï¼Œ<5%% >4ç¯‡ï¼‰")
    parser.add_argument("--verbose", "-v", action="store_true",
                        help="æ˜¾ç¤ºè¯¦ç»†çš„å¼•ç”¨åˆ†å¸ƒæŠ¥å‘Š")
    args = parser.parse_args()

    errors: list[str] = []
    if not args.tex.exists():
        errors.append(f"missing tex: {args.tex}")
    if not args.bib.exists():
        errors.append(f"missing bib: {args.bib}")
    if errors:
        for e in errors:
            print(f"âœ— {e}", file=sys.stderr)
        return 1

    tex = _read(args.tex)
    bib = _read(args.bib)

    # å¿…éœ€ç« èŠ‚å…³é”®å­—ï¼ˆè½»é‡æ£€æŸ¥ï¼‰
    section_titles_list = re.findall(r"\\section\*?\s*\{([^}]+)\}", tex, flags=re.IGNORECASE)
    section_titles = "\n".join(section_titles_list)
    musts = {
        "abstract": ["\\begin{abstract}", "æ‘˜è¦", "Abstract", "Summary"],
        "intro": ["å¼•è¨€", "Introduction"],
        "body": [],  # è‡³å°‘ä¸€ä¸ªé¢å¤– section
        "discussion": ["è®¨è®º", "Discussion"],
        "outlook": ["å±•æœ›", "Outlook", "Perspectives", "Conclusion", "ç»“è®º"],
    }
    if not _has_keyword(tex, musts["abstract"]) and not _has_keyword(section_titles, musts["abstract"]):
        errors.append("ç¼ºå°‘æ‘˜è¦ï¼ˆabstract ç¯å¢ƒæˆ–æ‘˜è¦/Abstract æ ‡é¢˜ï¼‰")
    if not _has_keyword(section_titles, musts["intro"]):
        errors.append("ç¼ºå°‘å¼•è¨€ï¼ˆå¼•è¨€/Introductionï¼‰")

    body_titles = [
        t
        for t in section_titles_list
        if not _has_keyword(t, musts["intro"])
        and not _has_keyword(t, musts["discussion"])
        and not _has_keyword(t, musts["outlook"])
        and not _has_keyword(t, musts["abstract"])
        and t.lower() not in {"references", "å‚è€ƒæ–‡çŒ®"}
    ]
    if len(body_titles) < 1:
        errors.append("ç¼ºå°‘è‡³å°‘ 1 ä¸ªå­ä¸»é¢˜æ®µè½")

    if not _has_keyword(section_titles, musts["discussion"]):
        errors.append("ç¼ºå°‘è®¨è®ºï¼ˆè®¨è®º/Discussionï¼‰")
    if not (_has_keyword(section_titles, musts["outlook"]) or _has_keyword(tex, musts["outlook"])):
        errors.append("ç¼ºå°‘å±•æœ›/ç»“è®ºï¼ˆå±•æœ›/Outlook/Perspectives/ç»“è®ºï¼‰")

    # cite ä¸ bib å¯¹é½ + æ•°é‡
    cite_keys = _extract_cite_keys(tex)
    bib_keys = _extract_bib_keys(bib)
    if not cite_keys:
        errors.append("æ­£æ–‡æœªåŒ…å«ä»»ä½• \\cite å¼•ç”¨")
    else:
        if args.min_refs and len(cite_keys) < args.min_refs:
            errors.append(f"å”¯ä¸€å¼•ç”¨æ•°ä¸è¶³: {len(cite_keys)} < {args.min_refs}")
        if args.max_refs and len(cite_keys) > args.max_refs:
            errors.append(f"å”¯ä¸€å¼•ç”¨æ•°è¶…å‡º: {len(cite_keys)} > {args.max_refs}")
    missing = sorted([k for k in cite_keys if k not in bib_keys])
    if missing:
        errors.append("Bib ç¼ºå°‘å¯¹åº” key: " + ", ".join(missing[:20]) + (" ..." if len(missing) > 20 else ""))

    if errors:
        print("LaTeX review validation failed:", file=sys.stderr)
        for e in errors:
            print(f"  - {e}", file=sys.stderr)
        return 1

    # å¼•ç”¨åˆ†å¸ƒæ£€æŸ¥ï¼ˆå¯é€‰ï¼‰
    if args.check_citation_dist:
        dist_result = _check_citation_distribution(tex, verbose=args.verbose)
        if not dist_result["passed"]:
            if dist_result.get("error"):
                print(f"âš ï¸  å¼•ç”¨åˆ†å¸ƒæ£€æŸ¥é”™è¯¯: {dist_result['error']}", file=sys.stderr)
            else:
                errors.append(f"å¼•ç”¨åˆ†å¸ƒä¸ç¬¦åˆç›®æ ‡")
                if args.verbose:
                    print(f"  - å¼•ç”¨åˆ†å¸ƒä¸ç¬¦åˆç›®æ ‡ï¼ˆè¯¦è§ä¸Šæ–¹æŠ¥å‘Šï¼‰", file=sys.stderr)

    # æ”¶é›†ç« èŠ‚éªŒè¯è¯¦æƒ…ï¼ˆç”¨äº generate_validation_report.py è§£æï¼‰
    import json
    sections_info = {
        "abstract": _has_keyword(tex, musts["abstract"]) or _has_keyword(section_titles, musts["abstract"]),
        "intro": _has_keyword(section_titles, musts["intro"]),
        "body_count": len(body_titles),
        "body_titles": body_titles[:10],  # æœ€å¤šè®°å½•å‰10ä¸ªï¼Œé¿å…è¾“å‡ºè¿‡é•¿
        "discussion": _has_keyword(section_titles, musts["discussion"]),
        "outlook": _has_keyword(section_titles, musts["outlook"]) or _has_keyword(tex, musts["outlook"]),
    }
    sections_json = json.dumps(sections_info, ensure_ascii=False)

    print(f"âœ“ LaTeX review validation passed (cites={len(cite_keys)}, bib_keys={len(bib_keys)}) SECTIONS:{sections_json}")
    return 0


if __name__ == "__main__":
    sys.exit(main())
