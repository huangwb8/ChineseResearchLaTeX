#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from __future__ import annotations

import asyncio
import argparse
import json
import logging
import os
import subprocess
import sys
import traceback
import webbrowser
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, Optional

sys.dont_write_bytecode = True

# core/ å®ç°ç»Ÿä¸€æ‰˜ç®¡åœ¨ scripts/core/ ä¸‹ï¼š
# - è¿è¡Œè„šæœ¬æ—¶ï¼Œscripts/ ç›®å½•å¤©ç„¶åœ¨ sys.path[0]
# - è¿™é‡Œæ˜¾å¼æ’å…¥ scripts/ ç›®å½•ï¼Œé¿å…å¤–éƒ¨ç¯å¢ƒæŠŠ skill_root æ”¾åˆ°æ›´å‰å¯¼è‡´ import core å¤±æ•ˆ
scripts_root_for_import = Path(__file__).resolve().parent
sys.path.insert(0, str(scripts_root_for_import))

from core.config_loader import load_config, get_runs_dir, validate_config
from core.config_access import get_bool, get_mapping, get_seq_str, get_str
from core.bib_manager_integration import BibFixSuggestion
from core.errors import BackupNotFoundError, MissingCitationKeysError, SectionNotFoundError, SkillError
from core.html_report import render_diagnostic_html
from core.hybrid_coordinator import HybridCoordinator
from core.info_form import copy_info_form_template, interactive_collect_info_form, write_info_form_file
from core.latex_parser import parse_subsubsections
from core.logging_utils import configure_logging
from core.observability import make_run_id
from core.quality_gate import check_new_body_quality
from core.versioning import find_backup_for_run_v2, list_runs, rollback_from_backup, unified_diff

logger = logging.getLogger(__name__)

@dataclass(frozen=True)
class _CmdResult:
    cmd: list[str]
    returncode: int
    stdout: str
    stderr: str


def _now_ts() -> str:
    import datetime as _dt

    return _dt.datetime.now().strftime("%Y%m%d%H%M%S")


def _make_test_session_dir(skill_root: Path, *, round_label: str, session_id: Optional[str]) -> Path:
    """
    æ¯æ¬¡æµ‹è¯•åˆ›å»ºä¸€ä¸ªç‹¬ç«‹ç›®å½•ï¼ˆå¯è¿½æº¯ã€å¯å½’æ¡£ï¼‰ã€‚é»˜è®¤æŒ‰ç§’çº§æ—¶é—´æˆ³ï¼Œé¿å…åŒåˆ†é’Ÿå†²çªã€‚
    """
    tests_root = (Path(skill_root) / "tests").resolve()
    tests_root.mkdir(parents=True, exist_ok=True)

    sid = (session_id or f"v{_now_ts()}").strip()
    if not sid:
        sid = f"v{_now_ts()}"
    name = sid if round_label == "A" else f"{round_label}-{sid}"

    out = (tests_root / name).resolve()
    if out.exists():
        # æå°æ¦‚ç‡å†²çªï¼šå†åŠ ä¸€æ¬¡æ—¶é—´æˆ³å…œåº•
        out = (tests_root / f"{name}-{_now_ts()}").resolve()
    out.mkdir(parents=True, exist_ok=True)
    return out


def _run_capture(cmd: list[str], *, cwd: Path, env: dict[str, str]) -> _CmdResult:
    p = subprocess.run(cmd, cwd=str(cwd), env=env, capture_output=True, text=True)
    return _CmdResult(cmd=list(cmd), returncode=int(p.returncode), stdout=p.stdout or "", stderr=p.stderr or "")

def _pick_pytest_cmd(*, cwd: Path, env: dict[str, str]) -> list[str]:
    """
    ä¼˜å…ˆç”¨ `python -m pytest`ï¼ˆä¸å½“å‰è§£é‡Šå™¨ä¸€è‡´ï¼‰ï¼Œè‹¥å½“å‰è§£é‡Šå™¨æœªå®‰è£… pytestï¼Œ
    åˆ™å›é€€åˆ° PATH é‡Œçš„ `pytest` å¯æ‰§è¡Œæ–‡ä»¶ï¼ˆå¾ˆå¤šç¯å¢ƒåªè£…äº†å‘½ä»¤è€Œéç³»ç»Ÿ python æ¨¡å—ï¼‰ã€‚
    """
    probe = subprocess.run(
        [sys.executable, "-c", "import pytest"],
        cwd=str(cwd),
        env=env,
        capture_output=True,
        text=True,
    )
    if int(probe.returncode) == 0:
        return [sys.executable, "-m", "pytest"]
    return ["pytest"]


def _write_cmd_artifacts(session_dir: Path, name: str, r: _CmdResult) -> None:
    out_dir = (session_dir / "_artifacts" / "cmd").resolve()
    out_dir.mkdir(parents=True, exist_ok=True)
    (out_dir / f"{name}.cmd.txt").write_text(" ".join(r.cmd) + "\n", encoding="utf-8")
    (out_dir / f"{name}.stdout.txt").write_text(r.stdout, encoding="utf-8")
    (out_dir / f"{name}.stderr.txt").write_text(r.stderr, encoding="utf-8")


def _write_test_plan(session_dir: Path, *, skill_root: Path, round_label: str, session_id: str) -> None:
    plan = (
        "# è½»é‡æµ‹è¯•è®¡åˆ’ï¼ˆTEST_PLANï¼‰\n\n"
        f"**æµ‹è¯•ID**: {session_id}\n"
        f"**ç›®æ ‡æŠ€èƒ½**: nsfc-justification-writer\n"
        f"**ç›®æ ‡æŠ€èƒ½è·¯å¾„**: {skill_root}\n"
        f"**è½®æ¬¡ç±»å‹**: {round_label}\n"
        f"**è®¡åˆ’æ—¶é—´**: {session_id[1:] if session_id.startswith('v') else session_id}\n\n"
        "---\n\n"
        "## éªŒè¯ç‚¹ï¼ˆé»˜è®¤ï¼‰\n\n"
        "- [ ] `python3 scripts/run.py validate-config`\n"
        "- [ ] `pytest -q tests/pytest`\n\n"
        "è¯´æ˜ï¼š\n"
        "- æœ¬æ¬¡ä¼šè¯çš„å‘½ä»¤è¾“å‡ºå°†å†™å…¥ `tests/<session>/_artifacts/cmd/`ï¼ˆå·²è¢« gitignoreï¼‰ã€‚\n"
        "- å¦‚éœ€è¡¥å……è¯Šæ–­ç±»éªŒè¯ï¼Œå¯åœ¨æœ¬ä¼šè¯ç›®å½•è®°å½•é¢å¤–å‘½ä»¤ä¸ç»“æœã€‚\n"
    )
    (session_dir / "TEST_PLAN.md").write_text(plan, encoding="utf-8")


def _write_test_report(
    session_dir: Path,
    *,
    skill_root: Path,
    round_label: str,
    session_id: str,
    results: list[tuple[str, _CmdResult]],
) -> None:
    ok = all(r.returncode == 0 for _, r in results)
    lines = [
        f"# æµ‹è¯•æŠ¥å‘Šï¼ˆ{session_dir.name}ï¼‰",
        "",
        f"**æµ‹è¯•ID**: {session_id}  ",
        f"**ç›®æ ‡æŠ€èƒ½**: nsfc-justification-writer  ",
        f"**ç›®æ ‡æŠ€èƒ½è·¯å¾„**: {skill_root}  ",
        f"**è½®æ¬¡ç±»å‹**: {round_label}  ",
        "",
        "---",
        "",
        "## ç»“è®º",
        "",
        f"- çŠ¶æ€ï¼š{'âœ… é€šè¿‡' if ok else 'âŒ å¤±è´¥'}",
        "",
        "---",
        "",
        "## æ‰§è¡Œå‘½ä»¤ä¸ç»“æœ",
        "",
    ]
    for name, r in results:
        lines.append(f"### {name}")
        lines.append("")
        lines.append(f"- å‘½ä»¤ï¼š`{' '.join(r.cmd)}`")
        lines.append(f"- returncodeï¼š{r.returncode}")
        lines.append(f"- è¾“å‡ºï¼šè§ `tests/{session_dir.name}/_artifacts/cmd/{name}.stdout.txt` / `{name}.stderr.txt`")
        lines.append("")
    (session_dir / "TEST_REPORT.md").write_text("\n".join(lines).rstrip() + "\n", encoding="utf-8")


def _write_json(path: Path, data: Dict[str, Any]) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")


def _read_body_file(body_file: Optional[str]) -> str:
    if body_file is None or body_file == "-":
        return sys.stdin.read()
    return Path(body_file).read_text(encoding="utf-8", errors="ignore")


def _load_config_for_args(skill_root: Path, args: argparse.Namespace) -> Dict[str, Any]:
    preset = getattr(args, "preset", None)
    override = getattr(args, "override", None)
    no_user_override = bool(getattr(args, "no_user_override", False))
    cfg = load_config(
        skill_root,
        preset=str(preset) if preset else None,
        override_path=str(override) if override else None,
        load_user_override=(not no_user_override),
    )
    meta = get_mapping(cfg, "_config_loader")
    warnings = list(meta.get("warnings", []) or [])
    for w in warnings[:10]:
        logger.warning("âš ï¸ é…ç½®åŠ è½½è­¦å‘Šï¼š%s", w)
    if len(warnings) > 10:
        logger.warning("âš ï¸ é…ç½®åŠ è½½è­¦å‘Šï¼šæ›´å¤š %s æ¡å·²çœç•¥", str(len(warnings) - 10))
    return cfg


def cmd_diagnose(args: argparse.Namespace) -> int:
    skill_root = Path(__file__).resolve().parent.parent
    config = _load_config_for_args(skill_root, args)
    coord = HybridCoordinator(skill_root=skill_root, config=config)

    if args.tier2 and getattr(args, "verbose", False):
        logger.info("â³ æ­£åœ¨è¿è¡Œè¯Šæ–­ï¼ˆå« Tier2ï¼‰...")
    report = coord.diagnose(
        project_root=Path(args.project_root),
        include_tier2=bool(args.tier2),
        tier2_chunk_size=int(args.chunk_size) if args.chunk_size is not None else None,
        tier2_max_chunks=int(args.max_chunks) if args.max_chunks is not None else None,
        tier2_fresh=bool(getattr(args, "fresh", False)),
    )
    text = coord.format_diagnose(report)
    print(text, end="")

    if args.json_out:
        _write_json(Path(args.json_out), report.to_dict())

    if args.html_report:
        if getattr(args, "verbose", False):
            logger.info("â³ æ­£åœ¨ç”Ÿæˆ HTML æŠ¥å‘Š...")
        run_id = args.run_id or make_run_id("diagnose")
        runs_root = get_runs_dir(skill_root, config)
        out_path = Path(args.html_report)
        if str(args.html_report).strip().lower() == "auto":
            out_path = (runs_root / run_id / "reports" / "diagnose.html").resolve()

        targets = get_mapping(config, "targets")
        target_relpath = get_str(targets, "justification_tex", "extraTex/1.1.ç«‹é¡¹ä¾æ®.tex")
        target = coord.target_path(project_root=Path(args.project_root))
        tex = target.read_text(encoding="utf-8", errors="ignore") if target.exists() else ""
        include_terms = not bool(getattr(args, "no_terms", False))
        term_md = coord.term_consistency_report(project_root=Path(args.project_root)) if include_terms else ""
        html_text = render_diagnostic_html(
            skill_root=skill_root,
            project_root=Path(args.project_root),
            target_relpath=target_relpath,
            tex_text=tex,
            report=report,
            term_matrix_md=term_md,
        )
        out_path.parent.mkdir(parents=True, exist_ok=True)
        out_path.write_text(html_text, encoding="utf-8")
        print(f"ğŸ§© HTML æŠ¥å‘Šï¼š{out_path}")
        if bool(getattr(args, "open", False)):
            try:
                webbrowser.open(out_path.resolve().as_uri())
            except (OSError, ValueError, webbrowser.Error) as e:
                if bool(getattr(args, "verbose", False)):
                    logger.warning("âš ï¸ æ‰“å¼€æµè§ˆå™¨å¤±è´¥ï¼š%s: %s", type(e).__name__, str(e))
    return 0


def cmd_wordcount(args: argparse.Namespace) -> int:
    skill_root = Path(__file__).resolve().parent.parent
    config = _load_config_for_args(skill_root, args)
    coord = HybridCoordinator(skill_root=skill_root, config=config)
    status = coord.word_count_status(project_root=Path(args.project_root), mode=getattr(args, "mode", None))
    print(json.dumps(status, ensure_ascii=False, indent=2))
    return 0


def cmd_refs(args: argparse.Namespace) -> int:
    skill_root = Path(__file__).resolve().parent.parent
    config = _load_config_for_args(skill_root, args)
    coord = HybridCoordinator(skill_root=skill_root, config=config)

    report = coord.diagnose(project_root=Path(args.project_root), include_tier2=False)
    sug = BibFixSuggestion(
        missing_bibkeys=list(report.tier1.missing_citation_keys or []),
        missing_doi_keys=list(getattr(report.tier1, "missing_doi_keys", []) or []),
        invalid_doi_keys=list(getattr(report.tier1, "invalid_doi_keys", []) or []),
    )
    md = sug.to_markdown(project_root=str(Path(args.project_root)))
    if str(getattr(args, "verify_doi", "none")).strip().lower() == "crossref":
        logger.warning("âš ï¸ å°†è”ç½‘è¯·æ±‚ Crossref API æ ¡éªŒ DOIï¼ˆå¯ç”¨ --doi-timeout è°ƒæ•´è¶…æ—¶ï¼›å¤±è´¥/è¶…æ—¶ä¸ä¼šæ–­è¨€ä¸å­˜åœ¨ï¼‰")
        from core.reference_validator import load_project_bib_doi_map, parse_cite_keys, verify_doi_via_crossref

        target = coord.target_path(project_root=Path(args.project_root))
        tex = target.read_text(encoding="utf-8", errors="ignore") if target.exists() else ""
        cite_keys = parse_cite_keys(tex)
        targets = get_mapping(config, "targets")
        bib_globs = list(get_seq_str(targets, "bib_globs")) or ["references/*.bib"]
        doi_map = load_project_bib_doi_map(Path(args.project_root), bib_globs)
        pairs = [(k, doi_map.get(k, "")) for k in cite_keys if doi_map.get(k)]

        failed = []
        timeout_s = float(getattr(args, "doi_timeout", 5.0))
        for k, doi in pairs[:200]:
            ok = verify_doi_via_crossref(doi=doi, timeout_s=timeout_s)
            if not ok:
                failed.append(f"- {k}: {doi}")
        if failed:
            md = md.rstrip() + "\n\n## Crossrefï¼ˆå¯é€‰è”ç½‘ï¼‰æ ¡éªŒå¤±è´¥/è¶…æ—¶çš„ DOIï¼ˆéœ€äººå·¥æ ¸éªŒï¼‰\n\n" + "\n".join(failed) + "\n"
        else:
            md = md.rstrip() + "\n\n## Crossrefï¼ˆå¯é€‰è”ç½‘ï¼‰æ ¡éªŒ\n\n- âœ… æœªå‘ç°æ˜æ˜¾å¤±è´¥ï¼ˆä»å»ºè®®æŠ½æŸ¥å…³é”®å¼•ç”¨ï¼‰\n"
    if args.out:
        Path(args.out).write_text(md, encoding="utf-8")
        print(f"å·²è¾“å‡ºï¼š{args.out}")
        return 0
    print(md, end="")
    return 0


def cmd_terms(args: argparse.Namespace) -> int:
    skill_root = Path(__file__).resolve().parent.parent
    config = _load_config_for_args(skill_root, args)
    coord = HybridCoordinator(skill_root=skill_root, config=config)
    md = coord.term_consistency_report(project_root=Path(args.project_root))
    targets = get_mapping(config, "targets")
    related = get_mapping(targets, "related_tex")
    if related:
        md = (
            md.rstrip()
            + "\n\n## å»ºè®®åŒæ­¥åˆ°ä»¥ä¸‹ç« èŠ‚\n\n"
            + "\n".join([f"- {k}: `{v}`" for k, v in related.items()])
            + "\n"
        )
    if args.out:
        Path(args.out).write_text(md, encoding="utf-8")
        print(f"å·²è¾“å‡ºï¼š{args.out}")
        return 0
    print(md, end="")
    return 0


def cmd_validate_config(args: argparse.Namespace) -> int:
    skill_root = Path(__file__).resolve().parent.parent
    config = _load_config_for_args(skill_root, args)
    meta = get_mapping(config, "_config_loader")
    if not bool(meta.get("yaml_available", True)):
        print("âš ï¸ æœªå®‰è£… PyYAMLï¼šæ— æ³•åŠ è½½/æ ¡éªŒ YAML é…ç½®æ–‡ä»¶ã€‚")
        print("   - å½“å‰ä»…ä¿è¯ guardrails ç­‰å®‰å…¨å…œåº•ç”Ÿæ•ˆã€‚")
        print("   - å»ºè®®ï¼šå®‰è£… PyYAML åå†è¿è¡Œ validate-configï¼ˆ`pip install pyyaml`ï¼‰ã€‚")
        return 0
    errs = validate_config(skill_root=skill_root, config=config)
    if errs:
        logger.error("âŒ é…ç½®æ ¡éªŒå¤±è´¥ï¼š")
        for e in errs:
            logger.error("- %s", e)
        return 2
    print("âœ… é…ç½®æœ‰æ•ˆ")
    return 0


def cmd_test_session(args: argparse.Namespace) -> int:
    skill_root = Path(__file__).resolve().parent.parent
    round_label = str(getattr(args, "round", "A")).strip() or "A"
    if round_label not in {"A", "Bè½®"}:
        round_label = "A"

    sid = str(getattr(args, "session_id", "") or "").strip()
    if not sid:
        sid = f"v{_now_ts()}"
    if not sid.startswith("v"):
        sid = "v" + sid

    session_dir = _make_test_session_dir(skill_root, round_label=round_label, session_id=sid)
    _write_test_plan(session_dir, skill_root=skill_root, round_label=round_label, session_id=sid)

    env = os.environ.copy()
    # æµ‹è¯•ç¯å¢ƒé¿å…å—ç”¨æˆ·å…¨å±€ override.yaml å½±å“ï¼›å¹¶æŠŠ runs/cache éš”ç¦»åˆ°æœ¬æ¬¡ä¼šè¯ç›®å½•
    env.setdefault("NSFC_JUSTIFICATION_WRITER_DISABLE_USER_OVERRIDE", "1")
    env["NSFC_JUSTIFICATION_WRITER_RUNS_DIR"] = str((session_dir / "_artifacts" / "runs").resolve())

    results: list[tuple[str, _CmdResult]] = []

    r1 = _run_capture([sys.executable, str(Path(__file__).resolve()), "validate-config"], cwd=skill_root, env=env)
    _write_cmd_artifacts(session_dir, "validate-config", r1)
    results.append(("validate-config", r1))

    pytest_cmd = _pick_pytest_cmd(cwd=skill_root, env=env)
    r2 = _run_capture(
        pytest_cmd + ["-q", str((skill_root / "tests" / "pytest").resolve())],
        cwd=skill_root,
        env=env,
    )
    _write_cmd_artifacts(session_dir, "pytest", r2)
    results.append(("pytest", r2))

    _write_test_report(session_dir, skill_root=skill_root, round_label=round_label, session_id=sid, results=results)

    if all(r.returncode == 0 for _, r in results):
        print(f"âœ… æµ‹è¯•é€šè¿‡ï¼š{session_dir}")
        return 0
    print(f"âŒ æµ‹è¯•å¤±è´¥ï¼š{session_dir}")
    return 2


def cmd_check_ai(args: argparse.Namespace) -> int:
    skill_root = Path(__file__).resolve().parent.parent
    config = _load_config_for_args(skill_root, args)
    coord = HybridCoordinator(skill_root=skill_root, config=config)

    ai_cfg = get_mapping(config, "ai")
    enabled = bool(get_bool(ai_cfg, "enabled", True))

    print("AI å¯ç”¨æ€§è‡ªæ£€ï¼š")
    print(f"- {'âœ…' if enabled else 'âš ï¸'} ai.enabled = {enabled}")

    if not enabled:
        print("- âš ï¸ AI å·²åœ¨é…ç½®ä¸­å…³é—­ï¼šæ‰€æœ‰ AI åŠŸèƒ½å°†è‡ªåŠ¨å›é€€åˆ°ç¡¬ç¼–ç èƒ½åŠ›")
        return 0

    if coord.ai.responder is None:
        print("- âš ï¸ responder æœªæ³¨å…¥ï¼šå½“å‰è¿è¡Œåœ¨â€œä¼˜é›…é™çº§æ¨¡å¼â€ï¼ˆAI åŠŸèƒ½ä¼šå›é€€ï¼‰")
        print("- ğŸ’¡ æç¤ºï¼šæœ¬ä»“åº“è„šæœ¬ä¸ä¼šä¸»åŠ¨ç›´è¿å¤–éƒ¨å¤§æ¨¡å‹ï¼›éœ€ç”±è¿è¡Œç¯å¢ƒ/ä¸Šå±‚å·¥å…·æ³¨å…¥ responder")
        return 0

    print("- âœ… responder å·²æ³¨å…¥")

    async def _run() -> Any:
        def _fallback() -> Dict[str, Any]:
            return {"ok": False, "reason": "fallback"}

        return await coord.ai.process_request(
            task="check_ai_echo",
            prompt='è¯·åªè¾“å‡º JSONï¼š{"ok": true}',
            fallback=_fallback,
            output_format="json",
            cache_dir=None,
            fresh=True,
        )

    try:
        obj = asyncio.run(_run())
    except RuntimeError:
        obj = None

    stats = coord.ai.get_stats()
    if isinstance(obj, dict) and (not bool(stats.get("fallback_mode", False))) and int(stats.get("success_count", 0)) > 0:
        print("- âœ… AI æµ‹è¯•è¯·æ±‚æˆåŠŸ")
    else:
        print("- âš ï¸ AI æµ‹è¯•è¯·æ±‚æœªæˆåŠŸï¼ˆå·²å›é€€æˆ–å“åº”ä¸å¯ç”¨ï¼‰")

    print(
        "- stats:",
        f"fallback_mode={bool(stats.get('fallback_mode', False))},",
        f"request_count={int(stats.get('request_count', 0))},",
        f"success_count={int(stats.get('success_count', 0))}",
    )
    return 0


def cmd_apply_section(args: argparse.Namespace) -> int:
    skill_root = Path(__file__).resolve().parent.parent
    config = _load_config_for_args(skill_root, args)
    coord = HybridCoordinator(skill_root=skill_root, config=config)

    body = _read_body_file(args.body_file).strip()
    if not body:
        logger.error("âŒ body ä¸ºç©ºï¼šè¯·é€šè¿‡ --body-file æˆ– stdin æä¾›æ–°æ­£æ–‡")
        return 2

    run_id = args.run_id or make_run_id("apply")
    # è‹¥ç”¨æˆ·é€‰æ‹©æ”¾å®½å¼•ç”¨çº¦æŸï¼Œå»ºè®®è‡³å°‘å¯ç”¨â€œæ–°æ­£æ–‡è´¨é‡é—¸é—¨â€ï¼ˆå¯é€‰é˜»æ–­ï¼‰ã€‚
    if bool(getattr(args, "allow_missing_citations", False)) and (not bool(getattr(args, "strict_quality", False))):
        strict_cfg = get_bool(get_mapping(config, "quality"), "strict_on_apply", False)
        if not strict_cfg:
            qr = check_new_body_quality(new_body=body, config=config)
            if not qr.ok:
                if qr.forbidden_phrases_hits:
                    logger.warning(
                        "âš ï¸ æ–°æ­£æ–‡åŒ…å«ä¸å¯æ ¸éªŒè¡¨è¿°ï¼ˆå»ºè®®æ”¹å†™æˆ–å¯ç”¨ --strict-quality é˜»æ–­å†™å…¥ï¼‰ï¼š%s",
                        "ã€".join(qr.forbidden_phrases_hits[:10]),
                    )
                if qr.avoid_commands_hits:
                    logger.warning(
                        "âš ï¸ æ–°æ­£æ–‡åŒ…å«å¯èƒ½ç ´åæ¨¡æ¿çš„å‘½ä»¤ï¼ˆå»ºè®®ç§»é™¤æˆ–å¯ç”¨ --strict-quality é˜»æ–­å†™å…¥ï¼‰ï¼š%s",
                        "ã€".join(qr.avoid_commands_hits[:10]),
                    )
    try:
        result = coord.apply_section_body(
            project_root=Path(args.project_root),
            title=args.title,
            new_body=body,
            backup=not bool(args.no_backup),
            run_id=run_id,
            allow_missing_citations=bool(args.allow_missing_citations),
            strict_quality=bool(getattr(args, "strict_quality", False)),
        )
    except MissingCitationKeysError as e:
        logger.error("âŒ %s", str(e))
        if e.missing_keys:
            logger.error("\nç¼ºå¤±çš„ bibkeyï¼š")
            for k in e.missing_keys[:50]:
                logger.error("- %s", k)
        if getattr(e, "fix_suggestion", ""):
            logger.error("\nğŸ’¡ ä¿®å¤å»ºè®®ï¼š")
            logger.error("%s", getattr(e, "fix_suggestion", ""))
        return 2
    except SectionNotFoundError as e:
        logger.error("âŒ %s", str(e))
        if getattr(e, "fix_suggestion", ""):
            logger.error("\nğŸ’¡ ä¿®å¤å»ºè®®ï¼š")
            logger.error("%s", getattr(e, "fix_suggestion", ""))
        if bool(getattr(args, "suggest_alias", False)):
            target = coord.target_path(project_root=Path(args.project_root))
            if target.exists():
                tex = target.read_text(encoding="utf-8", errors="ignore")
                titles = [s.title for s in parse_subsubsections(tex)]
                if titles:
                    logger.error("\nå¯ç”¨çš„å°æ ‡é¢˜ï¼ˆå…¨éƒ¨ï¼‰ï¼š")
                    for t in titles[:80]:
                        logger.error("- %s", t)
        return 2

    print(f"âœ… å·²å†™å…¥ï¼š{result.target_path}")
    if result.backup_path:
        print(f"ğŸ“¦ å¤‡ä»½ï¼š{result.backup_path}")

    if args.log_json:
        runs_root = get_runs_dir(skill_root, config)
        log_path = (runs_root / run_id / "logs" / "apply_result.json").resolve()
        targets = get_mapping(config, "targets")
        target_relpath = get_str(targets, "justification_tex", "extraTex/1.1.ç«‹é¡¹ä¾æ®.tex")
        _write_json(
            log_path,
            {
                "run_id": run_id,
                "target": str(result.target_path),
                "target_relpath": str(target_relpath),
                "backup": str(result.backup_path) if result.backup_path else None,
            },
        )
        print(f"ğŸ§¾ è®°å½•ï¼š{log_path}")
    return 0


def cmd_init(args: argparse.Namespace) -> int:
    skill_root = Path(__file__).resolve().parent.parent
    config = _load_config_for_args(skill_root, args)
    version = get_str(get_mapping(config, "skill_info"), "version", "")
    runs_root = get_runs_dir(skill_root, config)
    run_id = args.run_id or make_run_id("init")

    out_path = Path(args.out) if args.out else (runs_root / run_id / "inputs" / "info_form.md")
    out_path = out_path.resolve()

    template_path = (skill_root / "references" / "info_form.md").resolve()
    if not args.interactive:
        ok = copy_info_form_template(template_path=template_path, out_path=out_path)
        if not ok:
            logger.error("âŒ æœªæ‰¾åˆ° info_form æ¨¡æ¿ã€‚")
            return 2
        print(f"âœ… å·²ç”Ÿæˆä¿¡æ¯è¡¨æ¨¡æ¿ï¼š{out_path}")
        return 0

    print("è¿›å…¥äº¤äº’å¼ä¿¡æ¯è¡¨æ”¶é›†ï¼ˆä»…æœ¬åœ°ç”Ÿæˆï¼Œä¸ä¼šä¿®æ”¹æ ‡ä¹¦é¡¹ç›®ç›®å½•ï¼‰ã€‚")
    answers = interactive_collect_info_form()
    write_info_form_file(out_path=out_path, answers=answers, version=version or "v0.0.0")
    print(f"âœ… å·²ç”Ÿæˆä¿¡æ¯è¡¨ï¼š{out_path}")
    return 0


def cmd_review(args: argparse.Namespace) -> int:
    skill_root = Path(__file__).resolve().parent.parent
    config = _load_config_for_args(skill_root, args)
    coord = HybridCoordinator(skill_root=skill_root, config=config)
    md = coord.reviewer_advice(
        project_root=Path(args.project_root),
        include_tier2=bool(args.tier2),
        tier2_chunk_size=int(args.chunk_size) if args.chunk_size is not None else None,
        tier2_max_chunks=int(args.max_chunks) if args.max_chunks is not None else None,
        tier2_fresh=bool(getattr(args, "fresh", False)),
    )
    if args.out:
        Path(args.out).write_text(md, encoding="utf-8")
        print(f"å·²è¾“å‡ºï¼š{args.out}")
        return 0
    print(md, end="")
    return 0


def cmd_coach(args: argparse.Namespace) -> int:
    skill_root = Path(__file__).resolve().parent.parent
    config = _load_config_for_args(skill_root, args)
    coord = HybridCoordinator(skill_root=skill_root, config=config)
    info_form_text = ""
    if args.info_form:
        info_form_text = Path(args.info_form).read_text(encoding="utf-8", errors="ignore")
    md = coord.coach(project_root=Path(args.project_root), stage=str(args.stage), info_form_text=info_form_text)
    if args.topic:
        md = coord.recommend_examples(query=str(args.topic), top_k=int(args.top_k)) + "\n" + md
    if args.out:
        Path(args.out).write_text(md, encoding="utf-8")
        print(f"å·²è¾“å‡ºï¼š{args.out}")
        return 0
    print(md, end="")
    return 0


def cmd_examples(args: argparse.Namespace) -> int:
    skill_root = Path(__file__).resolve().parent.parent
    config = _load_config_for_args(skill_root, args)
    coord = HybridCoordinator(skill_root=skill_root, config=config)
    print(coord.recommend_examples(query=str(args.query), top_k=int(args.top_k)), end="")
    return 0


def cmd_list_runs(args: argparse.Namespace) -> int:
    skill_root = Path(__file__).resolve().parent.parent
    config = _load_config_for_args(skill_root, args)
    runs_root = get_runs_dir(skill_root, config)
    runs = list_runs(runs_root=runs_root)
    if not runs:
        print("ï¼ˆæš‚æ—  runs è®°å½•ï¼‰")
        return 0
    for r in runs[: int(args.limit)]:
        print(r.run_id)
    return 0


def cmd_diff(args: argparse.Namespace) -> int:
    skill_root = Path(__file__).resolve().parent.parent
    config = _load_config_for_args(skill_root, args)
    coord = HybridCoordinator(skill_root=skill_root, config=config)
    runs_root = get_runs_dir(skill_root, config)
    target = coord.target_path(project_root=Path(args.project_root))
    targets = get_mapping(config, "targets")
    target_relpath = get_str(targets, "justification_tex", "extraTex/1.1.ç«‹é¡¹ä¾æ®.tex")
    try:
        backup = find_backup_for_run_v2(
            runs_root=runs_root,
            run_id=str(args.run_id),
            target_relpath=target_relpath,
            filename_fallback=target.name,
        )
    except BackupNotFoundError:
        logger.error("âŒ æœªæ‰¾åˆ° run_id=%s çš„å¤‡ä»½æ–‡ä»¶ã€‚", str(args.run_id))
        return 2
    old = backup.read_text(encoding="utf-8", errors="ignore")
    new = target.read_text(encoding="utf-8", errors="ignore") if target.exists() else ""
    diff_text = unified_diff(
        old_text=old,
        new_text=new,
        fromfile=str(backup),
        tofile=str(target),
        context_lines=int(args.context),
    )
    print(diff_text, end="")
    return 0


def cmd_rollback(args: argparse.Namespace) -> int:
    if not args.yes:
        logger.error("âŒ å›æ»šéœ€è¦æ˜¾å¼ç¡®è®¤ï¼šè¯·åŠ  --yes")
        return 2
    skill_root = Path(__file__).resolve().parent.parent
    config = _load_config_for_args(skill_root, args)
    coord = HybridCoordinator(skill_root=skill_root, config=config)
    runs_root = get_runs_dir(skill_root, config)
    target = coord.target_path(project_root=Path(args.project_root))
    targets = get_mapping(config, "targets")
    target_relpath = get_str(targets, "justification_tex", "extraTex/1.1.ç«‹é¡¹ä¾æ®.tex")
    try:
        used = rollback_from_backup(
            runs_root=runs_root,
            run_id=str(args.run_id),
            target_path=target,
            target_relpath=target_relpath,
            backup_current=not bool(args.no_backup),
            rollback_run_id=args.new_run_id,
        )
    except BackupNotFoundError:
        logger.error("âŒ æœªæ‰¾åˆ° run_id=%s çš„å¤‡ä»½æ–‡ä»¶ã€‚", str(args.run_id))
        return 2
    print(f"âœ… å·²å›æ»šï¼š{target}")
    print(f"ğŸ“¦ ä½¿ç”¨å¤‡ä»½ï¼š{used}")
    return 0


def build_parser() -> argparse.ArgumentParser:
    p = argparse.ArgumentParser(prog="nsfc-justification-writer", add_help=True)
    p.add_argument("--verbose", action="store_true", help="è¾“å‡ºæ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯ï¼ˆåŒ…å«å †æ ˆï¼‰")
    p.add_argument("--preset", help="åŠ è½½å­¦ç§‘é¢„è®¾ assets/presets/<name>.yamlï¼ˆå…¼å®¹æ—§è·¯å¾„ config/presets/ï¼Œå¯é€‰ï¼‰")
    p.add_argument("--override", help="é¢å¤–é…ç½®è¦†ç›–æ–‡ä»¶ï¼ˆyamlï¼Œå¯é€‰ï¼Œä¼˜å…ˆçº§æœ€é«˜ï¼‰")
    p.add_argument("--no-user-override", action="store_true", help="ä¸åŠ è½½ ~/.config/nsfc-justification-writer/override.yaml")
    sub = p.add_subparsers(dest="cmd", required=True)

    p_diag = sub.add_parser("diagnose", help="Tier1/Tier2 è¯Šæ–­ï¼ˆç»“æ„/å¼•ç”¨/å­—æ•°/è¡¨è¿°ï¼‰")
    p_diag.add_argument("--project-root", required=True)
    p_diag.add_argument("--tier2", action="store_true", help="å¯ç”¨ AI Tier2ï¼ˆéœ€è¦ responder ç¯å¢ƒï¼‰")
    p_diag.add_argument("--chunk-size", type=int, default=12000, help="Tier2 åˆ†å—å¤§å°ï¼ˆå­—ç¬¦æ•°ï¼‰ï¼Œç”¨äºå¤§æ–‡ä»¶ï¼›<=0 è¡¨ç¤ºä¸åˆ†å—")
    p_diag.add_argument("--max-chunks", type=int, default=20, help="Tier2 æœ€å¤šå¤„ç†çš„åˆ†å—æ•°ï¼ˆé˜²æ­¢è¶…é•¿æ–‡ä»¶è¿‡æ…¢ï¼‰")
    p_diag.add_argument("--fresh", action="store_true", help="å¿½ç•¥ AI ç¼“å­˜ï¼Œå¼ºåˆ¶é‡æ–°è®¡ç®— Tier2")
    p_diag.add_argument("--json-out", help="å¯é€‰ï¼šè¾“å‡º JSON æŠ¥å‘Šåˆ°æ–‡ä»¶")
    p_diag.add_argument(
        "--html-report",
        help="å¯é€‰ï¼šè¾“å‡º HTML æŠ¥å‘Šåˆ°æ–‡ä»¶ï¼›ç”¨ auto è¾“å‡ºåˆ° runs_dirï¼ˆé»˜è®¤ tests/_artifacts/runs/ï¼‰...",
    )
    p_diag.add_argument("--open", action="store_true", help="è‹¥ç”Ÿæˆ HTML æŠ¥å‘Šåˆ™å°è¯•è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨")
    p_diag.add_argument("--no-terms", action="store_true", help="HTML æŠ¥å‘Šä¸é™„å¸¦æœ¯è¯­ä¸€è‡´æ€§çŸ©é˜µ")
    p_diag.add_argument("--run-id", help="å¯é€‰ï¼šdiagnose çš„ run_idï¼ˆç”¨äº html-report=autoï¼‰")
    p_diag.set_defaults(func=cmd_diagnose)

    p_wc = sub.add_parser("wordcount", help="ç»Ÿè®¡ 1.1 ç«‹é¡¹ä¾æ®å­—æ•°å¹¶ç»™å‡ºåå·®")
    p_wc.add_argument("--project-root", required=True)
    p_wc.add_argument(
        "--mode",
        default=None,
        choices=["cjk_only", "cjk_strip_commands"],
        help="ç»Ÿè®¡å£å¾„ï¼šcjk_onlyï¼ˆé»˜è®¤ï¼‰æˆ– cjk_strip_commandsï¼ˆæ›´æ¥è¿‘æ­£æ–‡ä¼°è®¡ï¼‰",
    )
    p_wc.set_defaults(func=cmd_wordcount)

    p_refs = sub.add_parser("refs", help="å¼•ç”¨æ ¸éªŒæ‘˜è¦ + ç”Ÿæˆ nsfc-bib-manager å¯å¤åˆ¶æç¤ºè¯")
    p_refs.add_argument("--project-root", required=True)
    p_refs.add_argument("--verify-doi", default="none", choices=["none", "crossref"], help="å¯é€‰ï¼šè”ç½‘ç”¨ Crossref æ ¡éªŒ DOI")
    p_refs.add_argument("--doi-timeout", default=5.0, type=float, help="Crossref æ ¡éªŒè¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰")
    p_refs.add_argument("--out", help="å¯é€‰ï¼šè¾“å‡ºåˆ°æ–‡ä»¶ï¼ˆmarkdownï¼‰")
    p_refs.set_defaults(func=cmd_refs)

    p_terms = sub.add_parser("terms", help="æœ¯è¯­ä¸€è‡´æ€§ï¼ˆç¡¬ç¼–ç  alias_groupsï¼‰")
    p_terms.add_argument("--project-root", required=True)
    p_terms.add_argument("--out", help="å¯é€‰ï¼šè¾“å‡ºåˆ°æ–‡ä»¶ï¼ˆmarkdownï¼‰")
    p_terms.set_defaults(func=cmd_terms)

    p_init = sub.add_parser("init", help="ç”Ÿæˆï¼ˆæˆ–äº¤äº’å¼å¡«å†™ï¼‰ä¿¡æ¯è¡¨ info_form.md")
    p_init.add_argument("--interactive", action="store_true", help="é—®ç­”å¼æ”¶é›†å¹¶ç”Ÿæˆå·²å¡«å†™çš„ä¿¡æ¯è¡¨")
    p_init.add_argument("--out", help="è¾“å‡ºè·¯å¾„ï¼ˆé»˜è®¤å†™åˆ° runs_dir/<run_id>/inputs/info_form.mdï¼‰")
    p_init.add_argument("--run-id", help="å¯é€‰ï¼šæŒ‡å®š run_idï¼ˆé»˜è®¤æŒ‰æ—¶é—´ç”Ÿæˆï¼‰")
    p_init.set_defaults(func=cmd_init)

    p_review = sub.add_parser("review", help="è¯„å®¡äººè§†è§’è´¨ç–‘ä¸å»ºè®®ï¼ˆå¯é€‰ Tier2ï¼‰")
    p_review.add_argument("--project-root", required=True)
    p_review.add_argument("--tier2", action="store_true", help="å¯ç”¨ AI Tier2ï¼ˆéœ€è¦ responder ç¯å¢ƒï¼‰")
    p_review.add_argument("--chunk-size", type=int, default=12000, help="Tier2 åˆ†å—å¤§å°ï¼ˆå­—ç¬¦æ•°ï¼‰ï¼Œç”¨äºå¤§æ–‡ä»¶ï¼›<=0 è¡¨ç¤ºä¸åˆ†å—")
    p_review.add_argument("--max-chunks", type=int, default=20, help="Tier2 æœ€å¤šå¤„ç†çš„åˆ†å—æ•°ï¼ˆé˜²æ­¢è¶…é•¿æ–‡ä»¶è¿‡æ…¢ï¼‰")
    p_review.add_argument("--fresh", action="store_true", help="å¿½ç•¥ AI ç¼“å­˜ï¼Œå¼ºåˆ¶é‡æ–°è®¡ç®— Tier2")
    p_review.add_argument("--out", help="å¯é€‰ï¼šè¾“å‡ºåˆ°æ–‡ä»¶ï¼ˆmarkdownï¼‰")
    p_review.set_defaults(func=cmd_review)

    p_coach = sub.add_parser("coach", help="æ¸è¿›å¼å†™ä½œå¼•å¯¼ï¼ˆéª¨æ¶â†’æ®µè½â†’ä¿®è®¢â†’æ¶¦è‰²â†’éªŒæ”¶ï¼‰")
    p_coach.add_argument("--project-root", required=True)
    p_coach.add_argument("--stage", default="auto", choices=["auto", "skeleton", "draft", "revise", "polish", "final"])
    p_coach.add_argument("--info-form", help="å¯é€‰ï¼šå·²å¡«å†™çš„ä¿¡æ¯è¡¨æ–‡ä»¶ï¼ˆmarkdownï¼‰")
    p_coach.add_argument("--topic", help="å¯é€‰ï¼šä¸€å¥è¯ä¸»é¢˜ï¼Œç”¨äºæ¨è assets/examples/ ç¤ºä¾‹")
    p_coach.add_argument("--top-k", default=3, type=int)
    p_coach.add_argument("--out", help="å¯é€‰ï¼šè¾“å‡ºåˆ°æ–‡ä»¶ï¼ˆmarkdownï¼‰")
    p_coach.set_defaults(func=cmd_coach)

    p_ex = sub.add_parser("examples", help="æ ¹æ®ä¸»é¢˜æ¨è assets/examples/ ä¸­çš„å‚è€ƒéª¨æ¶")
    p_ex.add_argument("--query", required=True, help="ä¸»é¢˜/æ–¹å‘/å…³é”®è¯")
    p_ex.add_argument("--top-k", default=3, type=int)
    p_ex.set_defaults(func=cmd_examples)

    p_runs = sub.add_parser("list-runs", help="åˆ—å‡º runs_dir ä¸‹çš„ run_idï¼ˆç”¨äº diff/rollbackï¼‰")
    p_runs.add_argument("--limit", default=20, type=int)
    p_runs.set_defaults(func=cmd_list_runs)

    p_diff = sub.add_parser("diff", help="æŸ¥çœ‹æŸæ¬¡ run çš„å¤‡ä»½ä¸å½“å‰æ–‡ä»¶çš„ diff")
    p_diff.add_argument("--project-root", required=True)
    p_diff.add_argument("--run-id", required=True)
    p_diff.add_argument("--context", default=3, type=int)
    p_diff.set_defaults(func=cmd_diff)

    p_rb = sub.add_parser("rollback", help="ä»æŸæ¬¡ run çš„å¤‡ä»½å›æ»šå½“å‰æ–‡ä»¶ï¼ˆé»˜è®¤ä¼šå¤‡ä»½å½“å‰ç‰ˆæœ¬ï¼‰")
    p_rb.add_argument("--project-root", required=True)
    p_rb.add_argument("--run-id", required=True)
    p_rb.add_argument("--yes", action="store_true", help="ç¡®è®¤å›æ»šï¼ˆå¿…é¡»æ˜¾å¼æŒ‡å®šï¼‰")
    p_rb.add_argument("--no-backup", action="store_true", help="ä¸å¤‡ä»½å½“å‰ç‰ˆæœ¬ï¼ˆé»˜è®¤å¤‡ä»½åˆ°æ–°çš„ runs_dir/ï¼‰")
    p_rb.add_argument("--new-run-id", help="å¯é€‰ï¼šå›æ»šå¤‡ä»½çš„ run_idï¼ˆé»˜è®¤æŒ‰æ—¶é—´ç”Ÿæˆï¼‰")
    p_rb.set_defaults(func=cmd_rollback)

    p_apply = sub.add_parser("apply-section", help="æ›¿æ¢æŒ‡å®š \\subsubsection çš„æ­£æ–‡ï¼ˆå®‰å…¨å†™å…¥+å¤‡ä»½ï¼‰")
    p_apply.add_argument("--project-root", required=True)
    p_apply.add_argument("--title", required=True, help="ç²¾ç¡®åŒ¹é… \\subsubsection{title}")
    p_apply.add_argument("--body-file", help="æ–°æ­£æ–‡æ¥æºæ–‡ä»¶ï¼›ç”¨ - è¡¨ç¤ºä» stdin è¯»")
    p_apply.add_argument("--no-backup", action="store_true", help="ä¸åšå¤‡ä»½ï¼ˆé»˜è®¤å¤‡ä»½ï¼‰")
    p_apply.add_argument("--run-id", help="å¯é€‰ï¼šæŒ‡å®š run_idï¼ˆé»˜è®¤æŒ‰æ—¶é—´ç”Ÿæˆï¼‰")
    p_apply.add_argument("--log-json", action="store_true", help="å†™å…¥ runs_dir/.../logs/apply_result.json")
    p_apply.add_argument("--allow-missing-citations", action="store_true", help="å…è®¸å­˜åœ¨ç¼ºå¤± bibkey çš„ \\cite{...}ï¼ˆä¸æ¨èï¼‰")
    p_apply.add_argument("--strict-quality", action="store_true", help="å¯ç”¨â€œæ–°æ­£æ–‡è´¨é‡é—¸é—¨â€ï¼šå‘½ä¸­ç»å¯¹åŒ–è¡¨è¿°/å±é™©å‘½ä»¤åˆ™æ‹’ç»å†™å…¥")
    p_apply.add_argument("--suggest-alias", action="store_true", help="å½“æ ‡é¢˜æœªå‘½ä¸­æ—¶ï¼Œè¾“å‡ºå¯ç”¨æ ‡é¢˜å€™é€‰ï¼ˆä¾¿äºæ”¹ titleï¼‰")
    p_apply.set_defaults(func=cmd_apply_section)

    p_cfg = sub.add_parser("validate-config", help="æ ¡éªŒå½“å‰é…ç½®ï¼ˆé»˜è®¤é…ç½® + preset + overrideï¼‰")
    p_cfg.set_defaults(func=cmd_validate_config)

    p_ts = sub.add_parser("test-session", help="åˆ›å»ºä¸€æ¬¡å¯è¿½æº¯æµ‹è¯•ä¼šè¯ç›®å½•ï¼Œå¹¶è¿è¡Œæœ€å°è‡ªæ£€ï¼ˆvalidate-config + pytestï¼‰")
    p_ts.add_argument("--round", default="A", choices=["A", "Bè½®"], help="ä¼šè¯ç›®å½•å‰ç¼€ï¼ˆA æˆ– Bè½®ï¼‰")
    p_ts.add_argument("--session-id", help="å¯é€‰ï¼šæŒ‡å®šä¼šè¯ IDï¼ˆé»˜è®¤ vYYYYMMDDHHMMSSï¼‰")
    p_ts.set_defaults(func=cmd_test_session)

    p_check_ai = sub.add_parser("check-ai", help="AI å¯ç”¨æ€§è‡ªæ£€ï¼ˆresponder æ³¨å…¥/é™çº§æ¨¡å¼ï¼‰")
    p_check_ai.set_defaults(func=cmd_check_ai)

    return p


def main(argv: Optional[list[str]] = None) -> int:
    args = build_parser().parse_args(argv)
    configure_logging(verbose=bool(getattr(args, "verbose", False)))
    try:
        return int(args.func(args))
    except SystemExit:
        raise
    except SkillError as e:
        logger.error("âŒ %s", str(e))
        if getattr(e, "fix_suggestion", ""):
            logger.error("\nğŸ’¡ ä¿®å¤å»ºè®®ï¼š")
            logger.error("%s", getattr(e, "fix_suggestion", ""))
        return 2
    except Exception as e:
        if bool(getattr(args, "verbose", False)):
            traceback.print_exc()
            raise
        logger.error("âŒ %s: %s", type(e).__name__, str(e))
        logger.error("å»ºè®®ï¼šåŠ  --verbose æŸ¥çœ‹è¯¦ç»†å †æ ˆï¼›æˆ–å…ˆè¿è¡Œ validate-config æ£€æŸ¥é…ç½®ã€‚")
        return 2


if __name__ == "__main__":
    raise SystemExit(main())
