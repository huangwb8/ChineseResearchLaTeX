# æ ¸å¿ƒåŠŸèƒ½æ¨¡å—

æœ¬ç›®å½•åŒ…å« `transfer_old_latex_to_new` æŠ€èƒ½çš„ä¸‰å¤§æ ¸å¿ƒåŠŸèƒ½æ¨¡å—ã€‚

## ğŸ“Š WordCountAdapter - å­—æ•°è‡ªåŠ¨é€‚é…å™¨

è‡ªåŠ¨é€‚é…æ—§ç‰ˆæœ¬å†…å®¹åˆ°æ–°ç‰ˆæœ¬å­—æ•°è¦æ±‚ã€‚

### åŠŸèƒ½ç‰¹ç‚¹

- **ç‰ˆæœ¬æ”¯æŒ**ï¼š2024â†’2025ã€2025â†’2026 çš„å­—æ•°è¦æ±‚æ˜ å°„
- **æ™ºèƒ½é€‚é…**ï¼šè‡ªåŠ¨æ‰©å±•æˆ–ç²¾ç®€å†…å®¹åˆ°ç›®æ ‡å­—æ•°èŒƒå›´
- **AI é›†æˆ**ï¼šä½¿ç”¨å½“å‰ AI ç¯å¢ƒï¼ˆClaude Code/Codexï¼‰è¿›è¡Œå†…å®¹æ‰©å±•/ç²¾ç®€
- **ä¸­æ–‡å­—æ•°ç»Ÿè®¡**ï¼šå‡†ç¡®ç»Ÿè®¡ä¸­æ–‡å­—ç¬¦ï¼Œæ’é™¤ LaTeX å‘½ä»¤

### ä½¿ç”¨ç¤ºä¾‹

```python
from core.word_count_adapter import WordCountAdapter

adapter = WordCountAdapter(config, ".")

# è·å–å­—æ•°æŠ¥å‘Š
report = adapter.generate_word_count_report(content, "ç«‹é¡¹ä¾æ®", "2025_to_2026")
print(f"å½“å‰å­—æ•°: {report['current_count']}")
print(f"æ–°ç‰ˆæœ¬è¦æ±‚: {report['new_requirement']}")
print(f"æ˜¯å¦éœ€è¦é€‚é…: {report['needs_adaptation']}")

# æ‰§è¡Œé€‚é…ï¼ˆasyncï¼‰
result = await adapter.adapt_content(content, "ç«‹é¡¹ä¾æ®", "2025_to_2026")
if result['status'] == 'expanded':
    print(f"æ‰©å±•äº† {result['expansion']} å­—")
elif result['status'] == 'compressed':
    print(f"ç²¾ç®€äº† {result['reduction']} å­—")
```

### ç‰ˆæœ¬å­—æ•°è¦æ±‚

| ç« èŠ‚ | 2024â†’2025 | 2025â†’2026 |
|------|-----------|-----------|
| ç«‹é¡¹ä¾æ® | 1500-2000 | 2000-2500 |
| ç ”ç©¶å†…å®¹ | 800-1000 | 1000-1200 |
| ç ”ç©¶ç›®æ ‡ | 500-800 | 600-900 |
| ç ”ç©¶æ–¹æ¡ˆ | 1000-1500 | 1200-1500 |
| ç ”ç©¶åŸºç¡€ | 1000-1500 | 1500-2000 |

---

## ğŸ”’ ReferenceGuardian - å¼•ç”¨å¼ºåˆ¶å®ˆæŠ¤è€…

ä¿æŠ¤ LaTeX å¼•ç”¨ä¸è¢« AI ç ´åã€‚

### åŠŸèƒ½ç‰¹ç‚¹

- **å…¨é¢ä¿æŠ¤**ï¼šæ”¯æŒ `\ref{}`ã€`\cite{}`ã€`\includegraphics{}` ç­‰ 8 ç§å¼•ç”¨ç±»å‹
- **å ä½ç¬¦æœºåˆ¶**ï¼šAI å¤„ç†å‰æ›¿æ¢ä¸ºå”¯ä¸€å ä½ç¬¦ï¼Œå¤„ç†åæ¢å¤åŸå§‹å¼•ç”¨
- **å®Œæ•´æ€§éªŒè¯**ï¼šè‡ªåŠ¨æ£€æŸ¥å¼•ç”¨æ˜¯å¦ä¸¢å¤±æˆ–è¢«ç ´å
- **ä¿®å¤åŠŸèƒ½**ï¼šå°è¯•ä¿®å¤è¢«éƒ¨åˆ†ç ´åçš„å¼•ç”¨

### ä½¿ç”¨ç¤ºä¾‹

```python
from core.reference_guardian import ReferenceGuardian

guardian = ReferenceGuardian({"reference_protection": {"enabled": True}})

content = r"å‚è§\ref{fig1}å’Œ\cite{author2024}çš„ç ”ç©¶ã€‚"

# ç¬¬ä¸€æ­¥ï¼šä¿æŠ¤å¼•ç”¨
protected, ref_map = guardian.protect_references(content)
# protected: "å‚è§__REF_REF_xxx__å’Œ__REF_CITE_xxx__çš„ç ”ç©¶ã€‚"
# ref_map: {"__REF_REF_xxx__": r"\ref{fig1}", ...}

# ç¬¬äºŒæ­¥ï¼šAI å¤„ç† protected å†…å®¹
processed_by_ai = await ai_process(protected)

# ç¬¬ä¸‰æ­¥ï¼šæ¢å¤å¼•ç”¨
restored = guardian.restore_references(processed_by_ai, ref_map)

# ç¬¬å››æ­¥ï¼šéªŒè¯å¼•ç”¨å®Œæ•´æ€§
original_refs = guardian._extract_all_references(content)
validation = guardian.validate_references(restored, original_refs)
if not validation["valid"]:
    print(f"ç¼ºå¤±å¼•ç”¨: {validation['missing']}")
```

### æ”¯æŒçš„å¼•ç”¨ç±»å‹

| ç±»å‹ | å‘½ä»¤ | ç¤ºä¾‹ |
|------|------|------|
| äº¤å‰å¼•ç”¨ | `\ref{}` | `\ref{fig:results}` |
| æ–‡çŒ®å¼•ç”¨ | `\cite{}` | `\cite{author2024}` |
| æ–‡çŒ®å¼•ç”¨ | `\citep{}` | `\citep{author2023}` |
| æ–‡çŒ®å¼•ç”¨ | `\citet{}` | `\citet{author2023}` |
| å…¬å¼å¼•ç”¨ | `\eqref{}` | `\eqref{eq:method}` |
| æ ‡ç­¾å®šä¹‰ | `\label{}` | `\label{sec:intro}` |
| å›¾ç‰‡æ’å…¥ | `\includegraphics{}` | `\includegraphics{fig.pdf}` |
| ä»£ç å¼•ç”¨ | `\lstinputlisting{}` | `\lstinputlisting{code.py}` |

---

## âœ¨ ContentOptimizer - AI å†…å®¹æ™ºèƒ½ä¼˜åŒ–å™¨

è‡ªåŠ¨è¯†åˆ«å¹¶ä¼˜åŒ–å†…å®¹è´¨é‡é—®é¢˜ã€‚

### åŠŸèƒ½ç‰¹ç‚¹

- **AI åˆ†æ**ï¼šæ™ºèƒ½è¯†åˆ«å†—ä½™ã€é€»è¾‘ã€è¯æ®ã€æ¸…æ™°åº¦ã€ç»“æ„ç­‰é—®é¢˜
- **ç±»å‹åŒ–ä¼˜åŒ–**ï¼šé’ˆå¯¹ä¸åŒé—®é¢˜ç±»å‹ä½¿ç”¨ä¸“é—¨çš„ä¼˜åŒ–ç­–ç•¥
- **å¼•ç”¨ä¿æŠ¤**ï¼šä¼˜åŒ–è¿‡ç¨‹è‡ªåŠ¨ä¿æŠ¤ LaTeX å¼•ç”¨
- **å¯å‘å¼å›é€€**ï¼šAI è°ƒç”¨å¤±è´¥æ—¶ä½¿ç”¨è§„åˆ™å¼•æ“

### ä½¿ç”¨ç¤ºä¾‹

```python
from core.content_optimizer import ContentOptimizer

optimizer = ContentOptimizer(config, ".")

# ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Šï¼ˆä¸æ‰§è¡Œä¼˜åŒ–ï¼‰
report = optimizer.generate_optimization_report(content, "ç«‹é¡¹ä¾æ®")
print(f"å‘ç°é—®é¢˜: {report['total_issues']} ä¸ª")
for issue in report['issues']:
    print(f"- [{issue['type']}] {issue['description']}")

# æ‰§è¡Œä¼˜åŒ–ï¼ˆasyncï¼‰
goals = {
    "remove_redundancy": True,
    "improve_logic": True,
    "add_evidence": False
}

result = await optimizer.optimize_content(content, "ç«‹é¡¹ä¾æ®", goals)
print(f"æ”¹è¿›è¯„åˆ†: {result['improvement_score']}")
print(f"å¼•ç”¨ä¿æŠ¤: {result['reference_validation']['valid']}")

# æŸ¥çœ‹ä¼˜åŒ–æ—¥å¿—
for log in result['optimization_log']:
    print(f"- {log['action']}: {log['description']}")
```

### ä¼˜åŒ–ç±»å‹

| ç±»å‹ | è¯´æ˜ | ç¤ºä¾‹é—®é¢˜ |
|------|------|----------|
| `redundancy` | åˆ é™¤å†—ä½™è¡¨è¿° | è¯è¯­é‡å¤ã€è¯­ä¹‰é‡å¤ |
| `logic` | æ”¹è¿›é€»è¾‘è¿è´¯æ€§ | æ®µè½é—´ç¼ºä¹è¿‡æ¸¡ |
| `evidence` | è¡¥å……è¯æ®æ”¯æŒ | ç¼ºä¹æ•°æ®/æ¡ˆä¾‹æ”¯æ’‘ |
| `clarity` | æé«˜è¡¨è¿°æ¸…æ™°åº¦ | å¤æ‚å¥å¼ã€æ¨¡ç³Šè¡¨è¿° |
| `structure` | é‡ç»„æ®µè½ç»“æ„ | æ®µè½é¡ºåºä¸åˆç† |

---

## ğŸ”§ é›†æˆæ–¹å¼

### å®Œæ•´å·¥ä½œæµ

```python
import asyncio
from core.word_count_adapter import WordCountAdapter
from core.reference_guardian import ReferenceGuardian
from core.content_optimizer import ContentOptimizer

async def migrate_section(content: str, section_title: str) -> str:
    """è¿ç§»å•ä¸ªç« èŠ‚åˆ°æ–°ç‰ˆæœ¬"""

    # 1. å­—æ•°é€‚é…
    adapter = WordCountAdapter(config, ".")
    adapt_result = await adapter.adapt_content(content, section_title, "2025_to_2026")
    adapted_content = adapt_result.get("content", content)

    # 2. å†…å®¹ä¼˜åŒ–
    optimizer = ContentOptimizer(config, ".")
    goals = {"remove_redundancy": True, "improve_logic": True}
    opt_result = await optimizer.optimize_content(adapted_content, section_title, goals)

    # 3. éªŒè¯å¼•ç”¨å®Œæ•´æ€§
    if not opt_result['reference_validation']['valid']:
        print("âš ï¸ å¼•ç”¨å¯èƒ½è¢«ç ´åï¼Œè¯·æ£€æŸ¥")

    return opt_result['optimized_content']

# ä½¿ç”¨
new_content = asyncio.run(migrate_section(old_content, "ç«‹é¡¹ä¾æ®"))
```

---

## âš™ï¸ é…ç½®é€‰é¡¹

### config.yaml

```yaml
word_count_adaptation:
  enabled: true
  auto_expand: true        # è‡ªåŠ¨æ‰©å±•å­—æ•°ä¸è¶³çš„å†…å®¹
  auto_compress: true      # è‡ªåŠ¨ç²¾ç®€å­—æ•°è¿‡å¤šçš„å†…å®¹
  target_tolerance: 50     # ç›®æ ‡å­—æ•°å®¹å·®ï¼ˆå­—ï¼‰

reference_protection:
  enabled: true
  validation_mode: "strict"  # strict | loose
  auto_repair: true         # è‡ªåŠ¨å°è¯•ä¿®å¤è¢«ç ´åçš„å¼•ç”¨
  log_violations: true      # è®°å½•å¼•ç”¨è¿è§„

content_optimization:
  enabled: true
  auto_apply: true
  min_improvement_threshold: 0.1  # æœ€ä½æ”¹è¿›é˜ˆå€¼
  optimization_types:
    - redundancy
    - logic
    - evidence
    - clarity
    - structure
  preserve_references: true
  max_optimization_passes: 3
```

---

## ğŸ§ª æµ‹è¯•

```bash
# è¿è¡Œæ¼”ç¤º
python demo_core_features.py

# è¿è¡Œæµ‹è¯•
python run_tests.py
```

---

## ğŸ“ æ³¨æ„äº‹é¡¹

### AI é›†æˆ

- æ‰€æœ‰ AI è°ƒç”¨é€šè¿‡ `from skill_core import call_ai` å®ç°
- åœ¨ Claude Code/Codex ç¯å¢ƒä¸­è‡ªåŠ¨ä½¿ç”¨å½“å‰ AI
- AI è°ƒç”¨å¤±è´¥æ—¶ä¼šå›é€€åˆ°å¯å‘å¼ç®—æ³•

### Async API

- `WordCountAdapter.adapt_content()` æ˜¯ async æ–¹æ³•
- `ContentOptimizer.optimize_content()` æ˜¯ async æ–¹æ³•
- `ReferenceGuardian` æ‰€æœ‰æ–¹æ³•éƒ½æ˜¯åŒæ­¥çš„

### æ€§èƒ½è€ƒè™‘

- å­—æ•°ç»Ÿè®¡ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ï¼Œå¯¹é•¿æ–‡æœ¬å¯èƒ½æœ‰æ€§èƒ½å½±å“
- AI è°ƒç”¨æœ‰ `max_tokens` é™åˆ¶ï¼Œè¶…é•¿å†…å®¹ä¼šè¢«æˆªæ–­
- å»ºè®®å¯¹å¤§æ–‡æ¡£åˆ†ç« èŠ‚å¤„ç†
