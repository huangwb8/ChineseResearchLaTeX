# å¸¸è§è¿ç§»æ¨¡å¼åº“

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2026-01-05
**é€‚ç”¨èŒƒå›´**: NSFC æ ‡ä¹¦ç‰ˆæœ¬è¿ç§»

---

## ğŸ“‹ ç›®å½•

1. [æ¨¡å¼æ¦‚è§ˆ](#æ¨¡å¼æ¦‚è§ˆ)
2. [æ ‡å‡†è¿ç§»æ¨¡å¼](#æ ‡å‡†è¿ç§»æ¨¡å¼)
3. [å¤æ‚è¿ç§»æ¨¡å¼](#å¤æ‚è¿ç§»æ¨¡å¼)
4. [ç‰¹æ®Šåœºæ™¯æ¨¡å¼](#ç‰¹æ®Šåœºæ™¯æ¨¡å¼)
5. [æ¨¡å¼åº”ç”¨æŒ‡å—](#æ¨¡å¼åº”ç”¨æŒ‡å—)

---

## æ¨¡å¼æ¦‚è§ˆ

### æ¨¡å¼åˆ†ç±»çŸ©é˜µ

| æ¨¡å¼ID | åç§° | å¤æ‚åº¦ | é€‚ç”¨åœºæ™¯ | é¢‘ç‡ |
|--------|------|--------|----------|------|
| P01 | ç›´æ¥å¤åˆ¶æ¨¡å¼ | â­ | æ ‡é¢˜å‡ ä¹ç›¸åŒï¼Œå†…å®¹å®Œå…¨ä¸€è‡´ | 40% |
| P02 | ç¼–å·è°ƒæ•´æ¨¡å¼ | â­ | ä»…ç« èŠ‚ç¼–å·å˜åŒ– | 25% |
| P03 | è¯­ä¹‰æ‹†åˆ†æ¨¡å¼ | â­â­â­ | ä¸€ç« æ‹†åˆ†ä¸ºå¤šç«  | 15% |
| P04 | æ™ºèƒ½åˆå¹¶æ¨¡å¼ | â­â­ | å¤šç« åˆå¹¶ä¸ºä¸€ç«  | 8% |
| P05 | ä¸Šä¸‹æ–‡ç”Ÿæˆæ¨¡å¼ | â­â­â­ | æ–°å¢ç« èŠ‚éœ€è¦ç”Ÿæˆ | 7% |
| P06 | è·¨æ¿å—è¿ç§»æ¨¡å¼ | â­â­â­ | ç« èŠ‚æ‰€å±æ¿å—å˜åŒ– | 3% |
| P07 | åˆ é™¤å¿½ç•¥æ¨¡å¼ | â­ | æ—§ç« èŠ‚åœ¨æ–°æ¨¡æ¿ä¸­ä¸å­˜åœ¨ | 2% |

---

## æ ‡å‡†è¿ç§»æ¨¡å¼

### P01: ç›´æ¥å¤åˆ¶æ¨¡å¼

**åœºæ™¯**: ç« èŠ‚æ ‡é¢˜å’Œå†…å®¹åŸºæœ¬ä¸å˜ï¼Œä»…éœ€å¤åˆ¶

**ç‰¹å¾**:
- æ ‡é¢˜ç›¸ä¼¼åº¦ â‰¥ 0.9
- å†…å®¹ç»“æ„å®Œå…¨ç›¸åŒ
- æ— éœ€è°ƒæ•´å±‚çº§

**ç¤ºä¾‹**:
```
æ—§: extraTex/1.3.ç ”ç©¶ç›®æ ‡.tex
æ–°: extraTex/2.2.ç ”ç©¶ç›®æ ‡.tex
```

**å®ç°**:
```python
def pattern_p01_direct_copy(old_file, new_file):
    """
    P01: ç›´æ¥å¤åˆ¶æ¨¡å¼
    """
    # è¯»å–æºæ–‡ä»¶
    with open(old_file, 'r', encoding='utf-8') as f:
        content = f.read()

    # åŸºç¡€æ¸…ç†
    content = clean_latex_comments(content)
    content = normalize_whitespace(content)

    # å†™å…¥ç›®æ ‡æ–‡ä»¶
    with open(new_file, 'w', encoding='utf-8') as f:
        f.write(content)

    return {
        'pattern': 'P01',
        'status': 'success',
        'word_count': count_chinese_words(content)
    }
```

**æ£€æŸ¥æ¸…å•**:
- [ ] æºæ–‡ä»¶å­˜åœ¨
- [ ] æºæ–‡ä»¶éç©º
- [ ] LaTeXè¯­æ³•æœ‰æ•ˆ
- [ ] ç¼–è¯‘æ— é”™è¯¯

---

### P02: ç¼–å·è°ƒæ•´æ¨¡å¼

**åœºæ™¯**: ä»…ç« èŠ‚ç¼–å·æ ¼å¼å˜åŒ–ï¼Œå†…å®¹ä¸å˜

**ç‰¹å¾**:
- æ ‡é¢˜å†…å®¹ç›¸åŒï¼Œç¼–å·æ ¼å¼ä¸åŒ
- å¦‚ "1.1" â†’ "1." æˆ– "ï¼ˆä¸€ï¼‰"
- æ­£æ–‡å†…å®¹å®Œå…¨ç›¸åŒ

**ç¤ºä¾‹**:
```
æ—§: \subsection{1.1 é¡¹ç›®çš„ç«‹é¡¹ä¾æ®}
æ–°: \subsection{1. é¡¹ç›®çš„ç«‹é¡¹ä¾æ®}
```

**å®ç°**:
```python
def pattern_p02_number_adjust(old_file, new_file, old_number, new_number):
    """
    P02: ç¼–å·è°ƒæ•´æ¨¡å¼
    """
    with open(old_file, 'r', encoding='utf-8') as f:
        content = f.read()

    # æ›´æ–°æ ‡é¢˜ä¸­çš„ç¼–å·ï¼ˆå¦‚æœæœ‰ï¼‰
    # æ³¨æ„ï¼šé€šå¸¸æ¨¡æ¿ä¼šè‡ªåŠ¨å¤„ç†æ ‡é¢˜ç¼–å·ï¼Œè¿™é‡Œä¸»è¦æ˜¯æ›´æ–°æ­£æ–‡ä¸­çš„å¼•ç”¨

    # æ›´æ–°æ­£æ–‡ä¸­çš„ç« èŠ‚ç¼–å·å¼•ç”¨
    content = re.sub(
        rf'ç¬¬{old_number}èŠ‚',
        f'ç¬¬{new_number}èŠ‚',
        content
    )

    with open(new_file, 'w', encoding='utf-8') as f:
        f.write(content)

    return {
        'pattern': 'P02',
        'status': 'success',
        'number_changed': f'{old_number} â†’ {new_number}'
    }
```

**æ³¨æ„äº‹é¡¹**:
- âš ï¸ ä¸è¦ä¿®æ”¹ `\section{}` æˆ– `\subsection{}` æ ‡é¢˜æœ¬èº«
- âš ï¸ åªä¿®æ”¹æ­£æ–‡ä¸­çš„ç¼–å·å¼•ç”¨
- âš ï¸ æ¨¡æ¿ä¼šè‡ªåŠ¨å¤„ç†æ ‡é¢˜ç¼–å·

---

## å¤æ‚è¿ç§»æ¨¡å¼

### P03: è¯­ä¹‰æ‹†åˆ†æ¨¡å¼

**åœºæ™¯**: ä¸€ä¸ªç« èŠ‚æ‹†åˆ†ä¸ºå¤šä¸ªç« èŠ‚

**ç‰¹å¾**:
- æ—§ç« èŠ‚åŒ…å«å¤šä¸ªå­ä¸»é¢˜
- æ–°æ¨¡æ¿å°†å­ä¸»é¢˜ç‹¬ç«‹æˆç« 
- éœ€è¦è¯†åˆ«è¯­ä¹‰è¾¹ç•Œ

**å­æ¨¡å¼**:

#### P03-A: æŒ‰ `\subsection{}` è¾¹ç•Œæ‹†åˆ†

**ç¤ºä¾‹**:
```latex
% æ—§æ–‡ä»¶: extraTex/1.5.ç ”ç©¶æ–¹æ¡ˆ.tex
\subsection{ç ”ç©¶æ–¹æ³•}
...
\subsection{æŠ€æœ¯è·¯çº¿}
...
\subsection{å¯è¡Œæ€§åˆ†æ}
...
```

**æ‹†åˆ†ä¸º**:
```latex
% æ–°æ–‡ä»¶1: extraTex/3.1.ç ”ç©¶æ–¹æ¡ˆ.tex
\subsection{ç ”ç©¶æ–¹æ³•}
...
\subsection{æŠ€æœ¯è·¯çº¿}
...

% æ–°æ–‡ä»¶2: extraTex/3.2.å¯è¡Œæ€§åˆ†æ.tex
\subsection{å¯è¡Œæ€§åˆ†æ}
...
```

**å®ç°**:
```python
def pattern_p03a_split_by_subsection(old_file, new_files, split_points):
    """
    P03-A: æŒ‰\subsection{}è¾¹ç•Œæ‹†åˆ†
    """
    with open(old_file, 'r', encoding='utf-8') as f:
        content = f.read()

    # æŒ‰æ‹†åˆ†ç‚¹åˆ‡åˆ†
    parts = []
    for i, point in enumerate(split_points):
        if i == 0:
            part = content[:content.find(point)]
        elif i == len(split_points) - 1:
            part = content[content.find(split_points[i-1]):]
        else:
            part = content[content.find(split_points[i-1]):content.find(point)]
        parts.append(part)

    # å†™å…¥æ–°æ–‡ä»¶
    for new_file, part in zip(new_files, parts):
        # æ·»åŠ å¿…è¦çš„æ–‡ä»¶å¤´
        part = add_file_header(part, new_file)

        with open(new_file, 'w', encoding='utf-8') as f:
            f.write(part)

    return {
        'pattern': 'P03-A',
        'status': 'success',
        'split_count': len(new_files)
    }
```

#### P03-B: æŒ‰å…³é”®è¯æ‹†åˆ†

**ç¤ºä¾‹**:
```python
# åœ¨"ç ”ç©¶æ–¹æ¡ˆ"ä¸­æ‰¾åˆ°"å¯è¡Œæ€§åˆ†æ"å…³é”®è¯ï¼Œä»è¿™é‡Œæ‹†åˆ†
split_marker = "å¯è¡Œæ€§åˆ†æ"
split_point = content.find(split_marker)
scheme_part = content[:split_point]
feasibility_part = content[split_point:]
```

**å®ç°**:
```python
def pattern_p03b_split_by_keyword(old_file, new_files, keywords):
    """
    P03-B: æŒ‰å…³é”®è¯æ‹†åˆ†
    """
    with open(old_file, 'r', encoding='utf-8') as f:
        content = f.read()

    # æ‰¾åˆ°å…³é”®è¯ä½ç½®
    split_positions = []
    for keyword in keywords:
        pos = content.find(keyword)
        if pos != -1:
            split_positions.append((pos, keyword))

    # æŒ‰ä½ç½®æ’åº
    split_positions.sort()

    # åˆ‡åˆ†å†…å®¹
    parts = []
    for i, (pos, keyword) in enumerate(split_positions):
        if i == 0:
            part = content[:pos]
        elif i == len(split_positions) - 1:
            part = content[split_positions[i-1][0]:]
        else:
            part = content[split_positions[i-1][0]:pos]
        parts.append(part)

    # å†™å…¥æ–°æ–‡ä»¶
    for new_file, part in zip(new_files, parts):
        with open(new_file, 'w', encoding='utf-8') as f:
            f.write(part)

    return {
        'pattern': 'P03-B',
        'status': 'success',
        'split_keywords': [kw for _, kw in split_positions]
    }
```

#### P03-C: AIè¯­ä¹‰æ‹†åˆ†

**åœºæ™¯**: æ— æ³•ç”¨ç®€å•è§„åˆ™æ‹†åˆ†ï¼Œéœ€è¦AIç†è§£è¯­ä¹‰

**å®ç°**:
```python
def pattern_p03c_ai_semantic_split(old_file, new_files):
    """
    P03-C: AIè¯­ä¹‰æ‹†åˆ†
    """
    with open(old_file, 'r', encoding='utf-8') as f:
        content = f.read()

    # è°ƒç”¨AIåˆ†æè¯­ä¹‰ç»“æ„
    structure_analysis = ai_analyze_structure(content)

    # æ ¹æ®è¯­ä¹‰ç»“æ„åˆ‡åˆ†
    parts = ai_split_by_semantics(content, structure_analysis)

    # å†™å…¥æ–°æ–‡ä»¶
    for new_file, part in zip(new_files, parts):
        # AIç”Ÿæˆè¿‡æ¸¡æ®µ
        if part != parts[0]:  # ç¬¬ä¸€éƒ¨åˆ†ä¸éœ€è¦è¿‡æ¸¡æ®µ
            transition = ai_generate_transition(
                previous_part=parts[parts.index(part)-1],
                current_part=part
            )
            part = transition + "\n\n" + part

        with open(new_file, 'w', encoding='utf-8') as f:
            f.write(part)

    return {
        'pattern': 'P03-C',
        'status': 'success',
        'ai_model': 'claude-opus-4-5',
        'split_count': len(new_files)
    }
```

---

### P04: æ™ºèƒ½åˆå¹¶æ¨¡å¼

**åœºæ™¯**: å¤šä¸ªç« èŠ‚åˆå¹¶ä¸ºä¸€ä¸ªç« èŠ‚

**ç‰¹å¾**:
- å¤šä¸ªæ—§ç« èŠ‚ä¸»é¢˜ç›¸å…³
- æ–°æ¨¡æ¿å°†å…¶åˆå¹¶
- éœ€è¦æ·»åŠ è¿‡æ¸¡æ®µ

**å­æ¨¡å¼**:

#### P04-A: é¡ºåºæ‹¼æ¥

**ç¤ºä¾‹**:
```
æ—§: 1.1 ç«‹é¡¹ä¾æ® + 1.2 ç ”ç©¶æ„ä¹‰
æ–°: 1. é¡¹ç›®çš„ç«‹é¡¹ä¾æ®
```

**å®ç°**:
```python
def pattern_p04a_sequential_merge(old_files, new_file):
    """
    P04-A: é¡ºåºæ‹¼æ¥
    """
    contents = []
    for old_file in old_files:
        with open(old_file, 'r', encoding='utf-8') as f:
            contents.append(f.read())

    # é¡ºåºæ‹¼æ¥
    merged = contents[0]
    for i, content in enumerate(contents[1:], start=1):
        # ç”Ÿæˆè¿‡æ¸¡æ®µ
        transition = generate_transition(
            from_section=extract_title(old_files[i-1]),
            to_section=extract_title(old_files[i])
        )
        merged += "\n\n" + transition + "\n\n" + content

    # å†™å…¥æ–°æ–‡ä»¶
    with open(new_file, 'w', encoding='utf-8') as f:
        f.write(merged)

    return {
        'pattern': 'P04-A',
        'status': 'success',
        'merged_count': len(old_files)
    }
```

**è¿‡æ¸¡æ®µç”Ÿæˆ**:
```python
def generate_transition(from_section, to_section):
    """
    ç”Ÿæˆè¿‡æ¸¡æ®µ
    """
    templates = [
        f"åœ¨ä¸Šè¿°{from_section}çš„åŸºç¡€ä¸Šï¼Œ",
        f"é™¤{from_section}å¤–ï¼Œ",
        f"ç»“åˆ{from_section}çš„å†…å®¹ï¼Œ"
    ]

    # ç®€å•æ¨¡æ¿é€‰æ‹©ï¼ˆå®é™…å¯ä»¥ç”¨AIç”Ÿæˆï¼‰
    return templates[0] + f"ä¸‹é¢å¯¹{to_section}è¿›è¡Œé˜è¿°ã€‚"
```

#### P04-B: è¯­ä¹‰é‡ç»„

**åœºæ™¯**: ä¸æŒ‰é¡ºåºï¼Œè€Œæ˜¯æŒ‰é€»è¾‘é‡æ–°ç»„ç»‡å†…å®¹

**å®ç°**:
```python
def pattern_p04b_semantic_reorder(old_files, new_file):
    """
    P04-B: è¯­ä¹‰é‡ç»„
    """
    # è¯»å–æ‰€æœ‰å†…å®¹
    contents = []
    for old_file in old_files:
        with open(old_file, 'r', encoding='utf-8') as f:
            contents.append({
                'file': old_file,
                'content': f.read()
            })

    # AIåˆ†æè¯­ä¹‰ç»“æ„
    structure = ai_analyze_semantic_structure(contents)

    # æŒ‰è¯­ä¹‰é‡ç»„
    reordered = ai_reorder_by_semantics(contents, structure)

    # åˆå¹¶å†…å®¹
    merged = merge_with_smart_transitions(reordered)

    # å†™å…¥æ–°æ–‡ä»¶
    with open(new_file, 'w', encoding='utf-8') as f:
        f.write(merged)

    return {
        'pattern': 'P04-B',
        'status': 'success',
        'reordered': True
    }
```

---

### P05: ä¸Šä¸‹æ–‡ç”Ÿæˆæ¨¡å¼

**åœºæ™¯**: æ–°å¢ç« èŠ‚ï¼Œéœ€è¦åŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆå†…å®¹

**å­æ¨¡å¼**:

#### P05-A: è°ƒç”¨å†™ä½œæŠ€èƒ½

**ç¤ºä¾‹**:
```
æ–°å¢: 3.3 ç ”ç©¶é£é™©åº”å¯¹
æ–¹æ³•: è°ƒç”¨ nsfc-methods-feasibility-writer
```

**å®ç°**:
```python
def pattern_p05a_call_skill(new_file, skill_name, context_sources):
    """
    P05-A: è°ƒç”¨å†™ä½œæŠ€èƒ½
    """
    # æå–ä¸Šä¸‹æ–‡
    context = extract_context_from_files(context_sources)

    # è°ƒç”¨æŠ€èƒ½
    generated_content = invoke_skill(
        skill_name,
        prompt=f"åŸºäºä»¥ä¸‹ç ”ç©¶æ–¹æ¡ˆï¼Œæ’°å†™é£é™©åº”å¯¹éƒ¨åˆ†ï¼š{context}"
    )

    # å†™å…¥æ–°æ–‡ä»¶
    with open(new_file, 'w', encoding='utf-8') as f:
        f.write(generated_content)

    return {
        'pattern': 'P05-A',
        'status': 'success',
        'skill_used': skill_name,
        'word_count': count_chinese_words(generated_content)
    }
```

#### P05-B: åŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆ

**ç¤ºä¾‹**:
```
æ–°å¢: 1.6 æœ¬ç ”ç©¶çš„ç‰¹è‰²ä¸åˆ›æ–°
æ–¹æ³•: ä»ç«‹é¡¹ä¾æ®ã€ç ”ç©¶å†…å®¹ä¸­æå–åˆ›æ–°ç‚¹
```

**å®ç°**:
```python
def pattern_p05b_generate_from_context(new_file, context_sources):
    """
    P05-B: åŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆ
    """
    # æå–ä¸Šä¸‹æ–‡
    context = extract_context_from_files(context_sources)

    # AIç”Ÿæˆå†…å®¹
    generated_content = ai_generate_content(
        context=context,
        section_title=extract_section_title(new_file),
        requirements=[
            "çªå‡ºåˆ›æ–°æ€§",
            "çªå‡ºç§‘å­¦ä»·å€¼",
            "çªå‡ºç ”ç©¶ç‰¹è‰²"
        ]
    )

    # å†™å…¥æ–°æ–‡ä»¶
    with open(new_file, 'w', encoding='utf-8') as f:
        f.write(generated_content)

    return {
        'pattern': 'P05-B',
        'status': 'success',
        'context_sources': context_sources
    }
```

#### P05-C: å ä½ç¬¦æ¨¡å¼

**åœºæ™¯**: æ— æ³•ç”Ÿæˆå†…å®¹ï¼Œç•™ç©ºä¾›ç”¨æˆ·è¡¥å……

**å®ç°**:
```python
def pattern_p05c_placeholder(new_file, section_title):
    """
    P05-C: å ä½ç¬¦æ¨¡å¼
    """
    placeholder = f"""% {section_title}

\\textbf{{[æ­¤éƒ¨åˆ†å†…å®¹éœ€è¦æ‰‹åŠ¨è¡¥å……]}}

% å»ºè®®ï¼š
% 1. å‚è€ƒç›¸å…³NSFCæ ‡ä¹¦èŒƒä¾‹
% 2. å’¨è¯¢å¯¼å¸ˆæˆ–åˆä½œè€…
% 3. è°ƒç”¨ç›¸å…³å†™ä½œæŠ€èƒ½ç”Ÿæˆå†…å®¹
"""

    with open(new_file, 'w', encoding='utf-8') as f:
        f.write(placeholder)

    return {
        'pattern': 'P05-C',
        'status': 'success',
        'is_placeholder': True
    }
```

---

### P06: è·¨æ¿å—è¿ç§»æ¨¡å¼

**åœºæ™¯**: ç« èŠ‚ä»æ—§æ¿å—è¿ç§»åˆ°æ–°æ¿å—

**ç¤ºä¾‹**:
```
æ—§: (ä¸€)ç ”ç©¶å†…å®¹ä¸‹çš„"ç ”ç©¶åŸºç¡€"
æ–°: (äºŒ)ç ”ç©¶åŸºç¡€ä¸å·¥ä½œæ¡ä»¶ï¼ˆç‹¬ç«‹æ¿å—ï¼‰
```

**å®ç°**:
```python
def pattern_p06_cross_section_migration(old_file, new_file, old_section, new_section):
    """
    P06: è·¨æ¿å—è¿ç§»æ¨¡å¼
    """
    # è¯»å–æºæ–‡ä»¶
    with open(old_file, 'r', encoding='utf-8') as f:
        content = f.read()

    # æ›´æ–°æ¿å—å¼•ç”¨ï¼ˆå¦‚"åœ¨ç ”ç©¶å†…å®¹éƒ¨åˆ†" â†’ "åœ¨ç ”ç©¶åŸºç¡€éƒ¨åˆ†"ï¼‰
    content = update_section_references(content, old_section, new_section)

    # æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒæ•´ç»“æ„ï¼ˆå¦‚å­ç« èŠ‚å±‚çº§ï¼‰
    content = adjust_hierarchy(content, new_section)

    # å†™å…¥æ–°æ–‡ä»¶
    with open(new_file, 'w', encoding='utf-8') as f:
        f.write(content)

    return {
        'pattern': 'P06',
        'status': 'success',
        'section_changed': f'{old_section} â†’ {new_section}'
    }
```

---

## ç‰¹æ®Šåœºæ™¯æ¨¡å¼

### P07: åˆ é™¤å¿½ç•¥æ¨¡å¼

**åœºæ™¯**: æ—§ç« èŠ‚åœ¨æ–°æ¨¡æ¿ä¸­ä¸å­˜åœ¨

**å®ç°**:
```python
def pattern_p07_ignore(old_file):
    """
    P07: åˆ é™¤å¿½ç•¥æ¨¡å¼
    """
    # è®°å½•è¢«å¿½ç•¥çš„ç« èŠ‚
    log_info(f"ç« èŠ‚ {old_file} åœ¨æ–°æ¨¡æ¿ä¸­ä¸å­˜åœ¨ï¼Œå·²å¿½ç•¥")

    return {
        'pattern': 'P07',
        'status': 'ignored',
        'file': old_file
    }
```

---

### P08: å¾ªç¯å¼•ç”¨å¤„ç†æ¨¡å¼

**åœºæ™¯**: ç« èŠ‚ä¹‹é—´äº’ç›¸å¼•ç”¨ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†

**å®ç°**:
```python
def pattern_p08_circular_reference(files_map):
    """
    P08: å¾ªç¯å¼•ç”¨å¤„ç†æ¨¡å¼
    """
    # ç¬¬ä¸€æ­¥ï¼šæå–æ‰€æœ‰å¼•ç”¨
    all_refs = {}
    for old_file, new_file in files_map.items():
        with open(old_file, 'r', encoding='utf-8') as f:
            content = f.read()
        refs = extract_references(content)
        all_refs[new_file] = refs

    # ç¬¬äºŒæ­¥ï¼šç”Ÿæˆå¼•ç”¨æ˜ å°„è¡¨
    ref_mapping = generate_reference_mapping(all_refs)

    # ç¬¬ä¸‰æ­¥ï¼šæ‰¹é‡æ›´æ–°å¼•ç”¨
    for new_file in files_map.values():
        with open(new_file, 'r', encoding='utf-8') as f:
            content = f.read()

        # æ›´æ–°å¼•ç”¨
        for old_ref, new_ref in ref_mapping.items():
            content = content.replace(f'\\ref{{{old_ref}}}', f'\\ref{{{new_ref}}}')

        # å†™å›æ–‡ä»¶
        with open(new_file, 'w', encoding='utf-8') as f:
            f.write(content)

    return {
        'pattern': 'P08',
        'status': 'success',
        'refs_updated': len(ref_mapping)
    }
```

---

### P09: å›¾è¡¨å¼•ç”¨å¤„ç†æ¨¡å¼

**åœºæ™¯**: æ–‡ä»¶ä¸­åŒ…å«å¤§é‡å›¾è¡¨å¼•ç”¨ï¼Œéœ€è¦éªŒè¯æ–‡ä»¶å­˜åœ¨

**å®ç°**:
```python
def pattern_p09_figure_references(file, figures_dir):
    """
    P09: å›¾è¡¨å¼•ç”¨å¤„ç†æ¨¡å¼
    """
    with open(file, 'r', encoding='utf-8') as f:
        content = f.read()

    # æå–æ‰€æœ‰å›¾è¡¨å¼•ç”¨
    figure_refs = extract_figure_references(content)

    # æ£€æŸ¥å›¾è¡¨æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    missing_figures = []
    for ref in figure_refs:
        figure_path = Path(figures_dir) / ref
        if not figure_path.exists():
            missing_figures.append(ref)
            # ç”Ÿæˆå ä½ç¬¦
            content = content.replace(
                f'\\ref{{{ref}}}',
                f'\\textbf{{[å›¾è¡¨ç¼ºå¤±: {ref}]}}'
            )

    # å†™å›æ–‡ä»¶
    with open(file, 'w', encoding='utf-8') as f:
        f.write(content)

    return {
        'pattern': 'P09',
        'status': 'success',
        'total_refs': len(figure_refs),
        'missing_refs': len(missing_figures),
        'missing_list': missing_figures
    }
```

---

## æ¨¡å¼åº”ç”¨æŒ‡å—

### æ¨¡å¼é€‰æ‹©å†³ç­–æ ‘

```mermaid
graph TD
    A[å¼€å§‹: æ—§ç« èŠ‚ vs æ–°ç« èŠ‚] --> B{è®¡ç®—ç›¸ä¼¼åº¦}
    B --> C{ç›¸ä¼¼åº¦ >= 0.9?}
    C -->|æ˜¯| D[P01: ç›´æ¥å¤åˆ¶]
    C -->|å¦| E{ä»…ç¼–å·å˜åŒ–?}
    E -->|æ˜¯| F[P02: ç¼–å·è°ƒæ•´]
    E -->|å¦| G{ä¸€å¯¹å¤š?}
    G -->|æ˜¯| H{æ‹†åˆ†è§„åˆ™æ˜æ˜¾?}
    H -->|æŒ‰subsection| I[P03-A: æŒ‰subsectionæ‹†åˆ†]
    H -->|æŒ‰å…³é”®è¯| J[P03-B: æŒ‰å…³é”®è¯æ‹†åˆ†]
    H -->|è¯­ä¹‰å¤æ‚| K[P03-C: AIè¯­ä¹‰æ‹†åˆ†]
    G -->|å¦| L{å¤šå¯¹ä¸€?}
    L -->|æ˜¯| M{é¡ºåºæ‹¼æ¥?}
    M -->|æ˜¯| N[P04-A: é¡ºåºæ‹¼æ¥]
    M -->|å¦| O[P04-B: è¯­ä¹‰é‡ç»„]
    L -->|å¦| P{æ–°å¢ç« èŠ‚?}
    P -->|æ˜¯| Q{å¯è°ƒç”¨æŠ€èƒ½?}
    Q -->|æ˜¯| R[P05-A: è°ƒç”¨æŠ€èƒ½]
    Q -->|å¦| S{æœ‰ä¸Šä¸‹æ–‡?}
    S -->|æ˜¯| T[P05-B: ä¸Šä¸‹æ–‡ç”Ÿæˆ]
    S -->|å¦| U[P05-C: å ä½ç¬¦]
    P -->|å¦| V{æ¿å—å˜åŒ–?}
    V -->|æ˜¯| W[P06: è·¨æ¿å—è¿ç§»]
    V -->|å¦| X{ç« èŠ‚åˆ é™¤?}
    X -->|æ˜¯| Y[P07: åˆ é™¤å¿½ç•¥]
    X -->|å¦| Z[æ£€æŸ¥ç‰¹æ®Šå¼•ç”¨]
    Z --> AA[P08: å¾ªç¯å¼•ç”¨]
    Z --> AB[P09: å›¾è¡¨å¼•ç”¨]
```

### æ¨¡å¼ç»„åˆç¤ºä¾‹

**åœºæ™¯**: å¤æ‚è¿ç§»ï¼Œéœ€è¦ç»„åˆå¤šä¸ªæ¨¡å¼

```python
# ç¤ºä¾‹ï¼šç ”ç©¶æ–¹æ¡ˆç« èŠ‚è¿ç§»
def complex_migration_example():
    """
    å¤æ‚è¿ç§»ç¤ºä¾‹ï¼šç ”ç©¶æ–¹æ¡ˆ â†’ ç ”ç©¶æ–¹æ¡ˆ + å¯è¡Œæ€§åˆ†æ
    """
    # ç¬¬ä¸€æ­¥ï¼šP03-A æ‹†åˆ†ç« èŠ‚
    pattern_p03a_split_by_subsection(
        old_file='old/extraTex/1.5.ç ”ç©¶æ–¹æ¡ˆ.tex',
        new_files=[
            'new/extraTex/3.1.ç ”ç©¶æ–¹æ¡ˆ.tex',
            'new/extraTex/3.2.å¯è¡Œæ€§åˆ†æ.tex'
        ],
        split_points=['\\subsection{å¯è¡Œæ€§åˆ†æ}']
    )

    # ç¬¬äºŒæ­¥ï¼šP08 å¤„ç†äº¤å‰å¼•ç”¨
    pattern_p08_circular_reference({
        'old/extraTex/1.5.ç ”ç©¶æ–¹æ¡ˆ.tex': 'new/extraTex/3.1.ç ”ç©¶æ–¹æ¡ˆ.tex',
        ...
    })

    # ç¬¬ä¸‰æ­¥ï¼šP05-A ç”Ÿæˆæ–°å¢çš„"é£é™©åº”å¯¹"ç« èŠ‚
    pattern_p05a_call_skill(
        new_file='new/extraTex/3.3.ç ”ç©¶é£é™©åº”å¯¹.tex',
        skill_name='nsfc-methods-feasibility-writer',
        context_sources=['new/extraTex/3.2.å¯è¡Œæ€§åˆ†æ.tex']
    )

    return {
        'status': 'success',
        'patterns_used': ['P03-A', 'P08', 'P05-A']
    }
```

---

## é™„å½•: æ¨¡å¼é€ŸæŸ¥è¡¨

| æ¨¡å¼ID | åç§° | è¾“å…¥ | è¾“å‡º | å¤æ‚åº¦ |
|--------|------|------|------|--------|
| P01 | ç›´æ¥å¤åˆ¶ | 1æ–‡ä»¶ | 1æ–‡ä»¶ | â­ |
| P02 | ç¼–å·è°ƒæ•´ | 1æ–‡ä»¶ | 1æ–‡ä»¶ | â­ |
| P03-A | æŒ‰subsectionæ‹†åˆ† | 1æ–‡ä»¶ | Næ–‡ä»¶ | â­â­ |
| P03-B | æŒ‰å…³é”®è¯æ‹†åˆ† | 1æ–‡ä»¶ | Næ–‡ä»¶ | â­â­ |
| P03-C | AIè¯­ä¹‰æ‹†åˆ† | 1æ–‡ä»¶ | Næ–‡ä»¶ | â­â­â­ |
| P04-A | é¡ºåºæ‹¼æ¥ | Næ–‡ä»¶ | 1æ–‡ä»¶ | â­â­ |
| P04-B | è¯­ä¹‰é‡ç»„ | Næ–‡ä»¶ | 1æ–‡ä»¶ | â­â­â­ |
| P05-A | è°ƒç”¨æŠ€èƒ½ | ä¸Šä¸‹æ–‡ | 1æ–‡ä»¶ | â­â­â­ |
| P05-B | ä¸Šä¸‹æ–‡ç”Ÿæˆ | ä¸Šä¸‹æ–‡ | 1æ–‡ä»¶ | â­â­ |
| P05-C | å ä½ç¬¦ | æ—  | 1æ–‡ä»¶ | â­ |
| P06 | è·¨æ¿å—è¿ç§» | 1æ–‡ä»¶ | 1æ–‡ä»¶ | â­â­â­ |
| P07 | åˆ é™¤å¿½ç•¥ | 1æ–‡ä»¶ | æ—  | â­ |
| P08 | å¾ªç¯å¼•ç”¨ | Næ–‡ä»¶ | Næ–‡ä»¶ | â­â­ |
| P09 | å›¾è¡¨å¼•ç”¨ | 1æ–‡ä»¶ | 1æ–‡ä»¶ | â­â­ |

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2026-01-05
**ç»´æŠ¤è€…**: transfer-old-latex-to-new æŠ€èƒ½ç»„
