#!/usr/bin/env python3
"""
run_ai_alignment.py - check-review-alignment çš„ç¡®å®šæ€§å…¥å£ï¼ˆçº¯ AI æ¨¡å¼ï¼‰

è„šæœ¬èŒè´£ï¼ˆç¡®å®šæ€§ï¼‰ï¼š
- ä¾èµ–æ£€æŸ¥ï¼ˆsystematic-literature-reviewï¼‰
- å®šä½ tex/bib
- è§£ææ®µè½ä¸å¼•ç”¨ï¼ŒæŠ½å– bib å…ƒä¿¡æ¯ä¸ï¼ˆå¯é€‰ï¼‰PDF æ‘˜è¦æ®µ
- å¯é€‰ï¼šæ¸²æŸ“ PDF/Wordï¼ˆå¤ç”¨ä¾èµ– skill çš„è„šæœ¬ï¼‰

éèŒè´£ï¼ˆå¯å‘å¼/AIï¼‰ï¼š
- åˆ¤æ–­â€œå¼•ç”¨æ˜¯å¦åˆç†â€ã€ç”Ÿæˆæ”¹å†™å¥å­ä¸æ®µè½
- å†™ ai_alignment_report.md çš„â€œé—®é¢˜åŸå› /ä¼˜åŒ–ç‰ˆæœ¬â€ç­‰è¯­ä¹‰å†…å®¹

è¿™äº›ç”±å®¿ä¸» AIï¼ˆClaude/Codexï¼‰åœ¨æ‰§è¡Œæœ¬ skill æ—¶å®Œæˆã€‚
"""

from __future__ import annotations

import argparse
import datetime as dt
import json
import subprocess
from pathlib import Path
from typing import Any, Dict, List, Optional

from bib_utils import extract_pdf_text, find_pdf_for_entry, parse_bib_file
from paragraph_analyzer import parse_latex_document
from runtime_utils import find_tex_and_bib, load_config, python_executable

def _truncate(text: str, limit: int) -> str:
    if not text:
        return ""
    t = " ".join(str(text).split())
    if len(t) <= limit:
        return t
    return t[:limit].rstrip() + " â€¦(truncated)"

def _safe_int(value: Any, default: int, warnings: List[str], name: str) -> int:
    try:
        return int(value)
    except Exception:
        warnings.append(f"invalid int for {name}: {value!r} (fallback to {default})")
        return default


def build_ai_input(
    work_dir: Path,
    tex_path: Path,
    bib_path: Path,
    config: dict,
) -> Dict[str, Any]:
    """ç”Ÿæˆä¾›å®¿ä¸» AI ä½¿ç”¨çš„ç»“æ„åŒ–è¾“å…¥ï¼ˆai_alignment_input.jsonï¼‰ã€‚"""
    warnings: List[str] = []

    ai_cfg = config.get("ai", {}) or {}
    limits = ai_cfg.get("input_limits", {}) or {}
    max_abstract_chars = _safe_int(limits.get("max_abstract_chars", 2000), 2000, warnings, "ai.input_limits.max_abstract_chars")
    max_pdf_excerpt_chars = _safe_int(limits.get("max_pdf_excerpt_chars", 3000), 3000, warnings, "ai.input_limits.max_pdf_excerpt_chars")

    # å°†â€œä¿®æ”¹ç­–ç•¥â€æ‰“åŒ…è¿›è¾“å…¥ï¼Œç¡®ä¿å®¿ä¸» AI åœ¨åªè¯»å– ai_alignment_input.json æ—¶ä¹Ÿèƒ½
    # ä¸¥æ ¼éµå¾ªâ€œåªä¿®å¤è‡´å‘½æ€§é”™è¯¯ï¼Œä¸ä¸ºäº†æ”¹è€Œæ”¹â€çš„è¾¹ç•Œï¼ˆè„šæœ¬ä¸åšä»»ä½•è¯­ä¹‰åˆ¤æ–­ï¼‰ã€‚
    mod_cfg = ai_cfg.get("modification", {}) or {}
    para_cfg = ai_cfg.get("paragraph_optimization", {}) or {}
    policy: Dict[str, Any] = {
        "modification": {
            "auto_apply": bool(mod_cfg.get("auto_apply", False)),
            "preserve_citations": bool(mod_cfg.get("preserve_citations", True)),
            "max_edits_per_sentence": _safe_int(mod_cfg.get("max_edits_per_sentence", 3), 3, warnings, "ai.modification.max_edits_per_sentence"),
            "error_priority": list(mod_cfg.get("error_priority", []) or []),
            "non_fatal_handling": str(mod_cfg.get("non_fatal_handling", "skip")),
        },
        "paragraph_optimization": {
            "enabled": bool(para_cfg.get("enabled", False)),
            "after_all_citations": bool(para_cfg.get("after_all_citations", False)),
        },
    }

    doc = parse_latex_document(
        tex_path,
        citation_commands=config.get("citation_commands", []),
    )
    bib_entries = parse_bib_file(bib_path)

    raw_skill_info = (config.get("skill_info", {}) or {}) if isinstance(config, dict) else {}
    skill_info: Dict[str, Any] = {}
    for k in ("name", "version", "description", "category"):
        if k in raw_skill_info:
            skill_info[k] = raw_skill_info.get(k)

    cited_keys = sorted({c.bibkey for c in doc.citations})

    pdf_cfg = config.get("pdf", {}) or {}
    pdf_enabled = bool(pdf_cfg.get("enabled", True))
    max_pages = _safe_int(pdf_cfg.get("max_pages", 2), 2, warnings, "pdf.max_pages")

    papers: Dict[str, Dict[str, Any]] = {}
    missing_in_bib_keys: List[str] = []
    for key in cited_keys:
        entry = bib_entries.get(key)
        if not entry:
            papers[key] = {"bibkey": key, "missing_in_bib": True}
            missing_in_bib_keys.append(key)
            continue

        paper: Dict[str, Any] = {
            "bibkey": key,
            "missing_in_bib": False,
            "title": entry.get("title", ""),
            "author": entry.get("author", ""),
            "year": entry.get("year", ""),
            "journal": entry.get("journal", "") or entry.get("booktitle", ""),
            "doi": entry.get("doi", "") or "",
            "url": entry.get("url", "") or "",
            "abstract": _truncate(entry.get("abstract", ""), max_abstract_chars),
        }

        if pdf_enabled:
            pdf_path = find_pdf_for_entry(entry, base_dir=work_dir)
            if pdf_path is not None:
                try:
                    resolved_pdf = pdf_path.resolve()
                    resolved_work = work_dir.resolve()
                    # å¦‚æœ PDF è·¯å¾„ä¸åœ¨ work_dir å†…ï¼Œç»™å‡º warningï¼ˆä½†ä¸å¼ºåˆ¶ç¦æ­¢ï¼Œé¿å…ç ´åç”¨æˆ·å·¥ä½œæµï¼‰
                    try:
                        resolved_pdf.relative_to(resolved_work)
                    except Exception:
                        warnings.append(f"PDF è·¯å¾„ä¸åœ¨ work_dir å†…ï¼ˆä»ä¼šå°è¯•è¯»å–ï¼‰ï¼š{resolved_pdf}")
                except Exception:
                    # resolve å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
                    pass
                excerpt = extract_pdf_text(pdf_path, max_pages=max_pages, warnings=warnings)
                if excerpt:
                    paper["pdf_path"] = str(pdf_path)
                    paper["pdf_excerpt"] = _truncate(excerpt, max_pdf_excerpt_chars)
        papers[key] = paper

    paragraphs: List[Dict[str, Any]] = []
    for p in doc.paragraphs_with_citations:
        paragraphs.append(
            {
                "index": p.index,
                "start_line": p.start_line,
                "end_line": p.end_line,
                "citation_count": p.citation_count,
            }
        )

    citations: List[Dict[str, Any]] = []
    for c in doc.citations:
        citations.append(
            {
                "bibkey": c.bibkey,
                "line_number": c.line_number,
                "paragraph_index": c.paragraph_index,
                "citation_index_in_paragraph": c.citation_index_in_para,
                "citation_index_global": c.citation_index_global,
                "sentence": c.sentence,
                "cite_command": c.cite_command,
            }
        )

    citations.sort(
        key=lambda x: (
            int(x.get("line_number", 0)),
            int(x.get("paragraph_index", 0)),
            int(x.get("citation_index_in_paragraph", 0)),
            str(x.get("bibkey", "")),
        )
    )

    if missing_in_bib_keys:
        warnings.append("ä»¥ä¸‹ bibkey åœ¨ .bib ä¸­ç¼ºå¤±ï¼ˆå·²æ ‡è®° missing_in_bib=trueï¼‰: " + ", ".join(missing_in_bib_keys))

    return {
        "generated_at": dt.datetime.now().isoformat(timespec="seconds"),
        "skill_info": skill_info,
        "work_dir": str(work_dir),
        "tex": tex_path.name,
        "bib": bib_path.name,
        "policy": policy,
        "stats": {
            "total_paragraphs": doc.total_paragraphs,
            "paragraphs_with_citations": len(doc.paragraphs_with_citations),
            "total_citations": doc.total_citations,
            "unique_cited_bibkeys": len(cited_keys),
            "missing_in_bib_bibkeys": len(missing_in_bib_keys),
        },
        "warnings": warnings,
        "paragraphs": paragraphs,
        "citations": citations,
        "papers": papers,
    }


def render_outputs(tex_path: Path, bib_path: Path, config: dict) -> Dict[str, Any]:
    """æ¸²æŸ“ PDF/Wordï¼ˆå¤ç”¨ä¾èµ– skill çš„æ¸²æŸ“è„šæœ¬ï¼‰ã€‚"""
    render_cfg = config.get("render", {}) or {}
    overwrite = bool(render_cfg.get("overwrite", True))

    dep_skill = str(render_cfg.get("use_skill", "systematic-literature-review"))
    # ä»…åœ¨æ¸²æŸ“è·¯å¾„ä¸‹æ£€æŸ¥ä¾èµ–ï¼ˆprepare ä¸åº”è¢«æ¸²æŸ“ä¾èµ–é˜»å¡ï¼‰
    from runtime_utils import require_dependency_skill, resolve_render_scripts

    dep_root = require_dependency_skill(dep_skill, reason="PDF/Word æ¸²æŸ“")
    compile_script, word_script = resolve_render_scripts(dep_root, dep_skill_name=dep_skill)

    pdf_path = tex_path.with_suffix(".pdf")
    docx_path = tex_path.with_suffix(".docx")

    log: List[str] = []
    result: Dict[str, Any] = {"ok": True, "pdf": None, "word": None, "log": log}

    if overwrite or not pdf_path.exists():
        proc_pdf = subprocess.run(
            [python_executable(), str(compile_script), str(tex_path), str(pdf_path)],
            text=True,
            capture_output=True,
            cwd=tex_path.parent,
        )
        if proc_pdf.stdout:
            log.append(proc_pdf.stdout)
        if proc_pdf.returncode != 0:
            if proc_pdf.stderr:
                log.append(proc_pdf.stderr)
            result["ok"] = False
            return result
        result["pdf"] = str(pdf_path)
    else:
        log.append("skip PDF render: overwrite=false and target exists")
        result["pdf"] = str(pdf_path)

    if overwrite or not docx_path.exists():
        proc_docx = subprocess.run(
            [python_executable(), str(word_script), str(tex_path), str(bib_path), str(docx_path)],
            text=True,
            capture_output=True,
            cwd=tex_path.parent,
        )
        if proc_docx.stdout:
            log.append(proc_docx.stdout)
        if proc_docx.returncode != 0:
            if proc_docx.stderr:
                log.append(proc_docx.stderr)
            result["ok"] = False
            return result
        result["word"] = str(docx_path)
    else:
        log.append("skip Word render: overwrite=false and target exists")
        result["word"] = str(docx_path)

    return result


def main() -> int:
    parser = argparse.ArgumentParser(description="check-review-alignment (AI mode) helper runner")
    parser.add_argument("--work-dir", required=True, type=Path, help="ç»¼è¿°å·¥ä½œç›®å½•ï¼ˆåŒ…å« tex/bibï¼‰")
    parser.add_argument("--tex", type=str, default=None, help="å¯é€‰ï¼šæŒ‡å®š tex æ–‡ä»¶å")
    parser.add_argument("--prepare", action="store_true", help="ç”Ÿæˆ ai_alignment_input.json")
    parser.add_argument("--render", action="store_true", help="æ¸²æŸ“ PDF/Wordï¼ˆä¸åšä»»ä½• AI åˆ¤æ–­ï¼‰")
    args = parser.parse_args()

    work_dir = args.work_dir.resolve()
    skill_root = Path(__file__).resolve().parents[1]
    config, cfg_warnings = load_config(skill_root / "config.yaml")
    for w in cfg_warnings:
        # config è¯»å–è­¦å‘Šä»…ç”¨äºå‘ŠçŸ¥ï¼Œä¸å½±å“æ‰§è¡Œ
        print(f"âš ï¸  {w}")

    do_prepare = bool(args.prepare)
    do_render = bool(args.render)
    if not do_prepare and not do_render:
        do_prepare = True

    selection_warnings: List[str] = []
    try:
        tex_path, bib_path = find_tex_and_bib(work_dir, args.tex, warnings=selection_warnings)
    except FileNotFoundError as e:
        print(f"âŒ {e}")
        if args.tex:
            print("   æç¤ºï¼š--tex åªæ”¯æŒä¼ å…¥æ–‡ä»¶åï¼›å¹¶ç¡®ä¿è¯¥æ–‡ä»¶å­˜åœ¨äº work_dir æ ¹ç›®å½•ã€‚")
        return 2
    for w in selection_warnings:
        # è¿™é‡Œçš„ warning ä¸»è¦ç”¨äºå¯é¢„æœŸæ€§ï¼ˆä¾‹å¦‚åŒç›®å½•å¤š tex çš„é»˜è®¤é€‰æ‹©ï¼‰
        print(f"âš ï¸  {w}")
        if "é»˜è®¤é€‰æ‹©ç¬¬ä¸€ä¸ª" in w:
            print("   æç¤ºï¼šå¯ç”¨ --tex <file.tex> æŒ‡å®šç›®æ ‡ tex æ–‡ä»¶åã€‚")

    # åˆ›å»ºä¸­é—´æ–‡ä»¶ç›®å½•ï¼ˆéšè—æ–‡ä»¶å¤¹ï¼‰
    intermediate_dir = work_dir / ".check-review-alignment"
    intermediate_dir.mkdir(exist_ok=True)

    if do_prepare:
        payload = build_ai_input(work_dir, tex_path, bib_path, config=config)
        out_path = intermediate_dir / "ai_alignment_input.json"
        out_path.write_text(json.dumps(payload, ensure_ascii=False, indent=2) + "\n", encoding="utf-8")
        print(f"âœ… å·²ç”Ÿæˆ: {out_path}")

    if do_render:
        print("ğŸ–¨ï¸  å¼€å§‹æ¸²æŸ“ PDF/Wordï¼ˆå¤ç”¨ä¾èµ– skill è„šæœ¬ï¼‰...")
        result = render_outputs(tex_path, bib_path, config=config)
        if not result.get("ok"):
            print("âŒ æ¸²æŸ“å¤±è´¥ï¼ˆè¯·æ£€æŸ¥ logï¼‰")
            return 2
        print(f"âœ… PDF: {result.get('pdf')}")
        print(f"âœ… Word: {result.get('word')}")

    return 0


if __name__ == "__main__":
    raise SystemExit(main())
