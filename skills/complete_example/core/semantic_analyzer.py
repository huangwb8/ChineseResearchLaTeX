"""
SemanticAnalyzer - AI é©±åŠ¨è¯­ä¹‰åˆ†æå™¨
ğŸ§  AIï¼šç†è§£ç« èŠ‚ä¸»é¢˜ã€æ¨ç†èµ„æºç›¸å…³æ€§ã€è¯„ä¼°å†…å®¹è´¨é‡
"""

from typing import List, Dict, Any
from dataclasses import dataclass
from pathlib import Path


@dataclass
class SectionTheme:
    """ç« èŠ‚ä¸»é¢˜åˆ†æç»“æœ"""
    theme: str                      # ç« èŠ‚æ ¸å¿ƒä¸»é¢˜
    key_concepts: List[str]         # å…³é”®æ¦‚å¿µåˆ—è¡¨
    writing_style: str              # å†™ä½œé£æ ¼ï¼šå­¦æœ¯/æŠ€æœ¯/è¯´æ˜
    suggested_resources: List[str]  # å»ºè®®çš„èµ„æºç±»å‹
    tone: str                       # è¯­è°ƒï¼šæ­£å¼/é€šä¿—
    target_audience: str            # ç›®æ ‡è¯»è€…ï¼šä¸“å®¶/è¯„å®¡/å¤§ä¼—


@dataclass
class ResourceRelevance:
    """èµ„æºç›¸å…³æ€§è¯„ä¼°ç»“æœ"""
    resource_path: str
    relevance_score: float          # 0-1 ç›¸å…³æ€§åˆ†æ•°
    reason: str                     # AI ç»™å‡ºçš„ç†ç”±
    suggested_usage: str            # å»ºè®®çš„ä½¿ç”¨æ–¹å¼


class SemanticAnalyzer:
    """AI é©±åŠ¨çš„è¯­ä¹‰åˆ†æå™¨"""

    def __init__(self, llm_client):
        """
        Args:
            llm_client: LLM å®¢æˆ·ç«¯ï¼ˆClaude/OpenAI/æœ¬åœ°æ¨¡å‹ï¼‰
        """
        self.llm = llm_client

    def analyze_section_theme(self, tex_content: str) -> SectionTheme:
        """
        åˆ†æç« èŠ‚çš„æ ¸å¿ƒä¸»é¢˜å’Œå†™ä½œæ„å›¾

        Args:
            tex_content: LaTeX æ–‡ä»¶å†…å®¹ï¼ˆå‰ 2000 å­—ç¬¦ï¼‰

        Returns:
            SectionTheme: ç»“æ„åŒ–çš„ä¸»é¢˜åˆ†æç»“æœ
        """
        prompt = f"""
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å­¦æœ¯å†™ä½œåˆ†æä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹ LaTeX ç« èŠ‚çš„å†…å®¹ä¸»é¢˜ã€‚

ç« èŠ‚å†…å®¹ï¼ˆå‰ 2000 å­—ç¬¦ï¼‰ï¼š
{tex_content[:2000]}

è¯·è¿”å› JSON æ ¼å¼çš„åˆ†æç»“æœï¼š
{{
  "theme": "ç« èŠ‚çš„æ ¸å¿ƒä¸»é¢˜ï¼ˆä¸€å¥è¯æ¦‚æ‹¬ï¼‰",
  "key_concepts": ["å…³é”®æ¦‚å¿µ1", "å…³é”®æ¦‚å¿µ2", "å…³é”®æ¦‚å¿µ3"],
  "writing_style": "å­¦æœ¯/æŠ€æœ¯/è¯´æ˜/æ··åˆ",
  "suggested_resources": ["å»ºè®®çš„å›¾ç‰‡ç±»å‹", "å»ºè®®çš„æ–‡çŒ®é¢†åŸŸ"],
  "tone": "æ­£å¼/åŠæ­£å¼/é€šä¿—",
  "target_audience": "è¯„å®¡ä¸“å®¶/åŒè¡Œ/å­¦ç”Ÿ/å¤§ä¼—"
}}
"""

        response = self.llm.complete(
            prompt,
            response_format="json",
            temperature=0.3  # ä½æ¸©åº¦ä¿è¯ç¨³å®šæ€§
        )

        import json
        data = json.loads(response)
        return SectionTheme(**data)

    def reason_resource_relevance(
        self,
        resource_info: 'ResourceInfo',
        section_theme: SectionTheme
    ) -> ResourceRelevance:
        """
        æ¨ç†èµ„æºä¸ç« èŠ‚çš„ç›¸å…³æ€§

        Args:
            resource_info: èµ„æºä¿¡æ¯ï¼ˆå›¾ç‰‡/ä»£ç /æ–‡çŒ®ï¼‰
            section_theme: ç« èŠ‚ä¸»é¢˜

        Returns:
            ResourceRelevance: ç›¸å…³æ€§è¯„ä¼°ç»“æœ
        """
        prompt = f"""
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å­¦æœ¯å†™ä½œé¡¾é—®ã€‚è¯·è¯„ä¼°ä»¥ä¸‹èµ„æºæ˜¯å¦é€‚åˆç”¨äºæŒ‡å®šç« èŠ‚ã€‚

ç« èŠ‚ä¿¡æ¯ï¼š
- ä¸»é¢˜ï¼š{section_theme.theme}
- å…³é”®æ¦‚å¿µï¼š{', '.join(section_theme.key_concepts)}
- å†™ä½œé£æ ¼ï¼š{section_theme.writing_style}
- å»ºè®®èµ„æºï¼š{', '.join(section_theme.suggested_resources)}

èµ„æºä¿¡æ¯ï¼š
- è·¯å¾„ï¼š{resource_info.path}
- ç±»å‹ï¼š{resource_info.type}
- å…ƒæ•°æ®ï¼š{resource_info.metadata}

è¯·è¿”å› JSON æ ¼å¼çš„è¯„ä¼°ç»“æœï¼š
{{
  "relevance_score": 0.85,  // 0-1 ä¹‹é—´çš„åˆ†æ•°
  "reason": "è¯¦ç»†è¯´æ˜ä¸ºä»€ä¹ˆé€‚åˆæˆ–ä¸é€‚åˆï¼Œ100-200å­—",
  "suggested_usage": "å»ºè®®å¦‚ä½•ä½¿ç”¨è¿™ä¸ªèµ„æºï¼ˆå¦‚ï¼šä½œä¸ºæ–¹æ³•è®ºç¤ºæ„å›¾ï¼‰"
}}
"""

        response = self.llm.complete(
            prompt,
            response_format="json",
            temperature=0.3
        )

        import json
        data = json.loads(response)
        return ResourceRelevance(
            resource_path=resource_info.path,
            relevance_score=data['relevance_score'],
            reason=data['reason'],
            suggested_usage=data['suggested_usage']
        )

    def generate_contextual_description(
        self,
        resource: 'ResourceInfo',
        context: str,
        usage_hint: str = None
    ) -> str:
        """
        ä¸ºèµ„æºç”Ÿæˆç¬¦åˆä¸Šä¸‹æ–‡çš„æè¿°æ–‡å­—

        Args:
            resource: èµ„æºä¿¡æ¯
            context: ä¸Šä¸‹æ–‡å†…å®¹ï¼ˆç« èŠ‚ç‰‡æ®µï¼‰
            usage_hint: ä½¿ç”¨æç¤ºï¼ˆå¯é€‰ï¼‰

        Returns:
            str: è‡ªç„¶çš„æè¿°æ–‡å­—ï¼ˆ50-100 å­—ï¼‰
        """
        prompt = f"""
ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„å­¦æœ¯å†™ä½œè€…ã€‚è¯·ä¸ºä»¥ä¸‹èµ„æºç”Ÿæˆä¸€æ®µè‡ªç„¶çš„æè¿°æ–‡å­—ã€‚

ä¸Šä¸‹æ–‡ï¼ˆç« èŠ‚ç‰‡æ®µï¼‰ï¼š
{context[:500]}

èµ„æºä¿¡æ¯ï¼š
- æ–‡ä»¶åï¼š{resource.filename}
- ç±»å‹ï¼š{resource.type}
- å»ºè®®ç”¨é€”ï¼š{usage_hint or 'æœªæŒ‡å®š'}

è¦æ±‚ï¼š
1. ç”Ÿæˆ 50-100 å­—çš„æè¿°æ–‡å­—
2. ç¬¦åˆå­¦æœ¯å†™ä½œé£æ ¼
3. ä¸ä¸Šä¸‹æ–‡è‡ªç„¶è¡”æ¥
4. åŒ…å«é€‚å½“çš„å¼•å…¥è¯­ï¼ˆå¦‚"å¦‚å›¾ X æ‰€ç¤º"ã€"æ ¹æ®æ–‡çŒ® X"ç­‰ï¼‰

åªè¿”å›æè¿°æ–‡å­—ï¼Œä¸è¦è§£é‡Šã€‚
"""

        return self.llm.complete(prompt, temperature=0.7)

    def evaluate_content_quality(
        self,
        content: str,
        section_theme: SectionTheme = None
    ) -> Dict[str, Any]:
        """
        è¯„ä¼°ç”Ÿæˆå†…å®¹çš„è´¨é‡

        Args:
            content: ç”Ÿæˆçš„å†…å®¹
            section_theme: ç« èŠ‚ä¸»é¢˜ï¼ˆå¯é€‰ï¼Œç”¨äºå¯¹æ¯”ï¼‰

        Returns:
            Dict: è´¨é‡è¯„ä¼°æŠ¥å‘Š
        """
        prompt = f"""
ä½ æ˜¯ä¸€ä½ä¸¥è°¨çš„å­¦æœ¯å†™ä½œè¯„å®¡ä¸“å®¶ã€‚è¯·è¯„ä¼°ä»¥ä¸‹ç¤ºä¾‹å†…å®¹çš„è´¨é‡ã€‚

è¯„ä¼°å†…å®¹ï¼š
{content[:2000]}

ç« èŠ‚ä¸»é¢˜ï¼ˆä¾›å‚è€ƒï¼‰ï¼š
{section_theme.theme if section_theme else 'æœªæŒ‡å®š'}

è¯·è¿”å› JSON æ ¼å¼çš„è¯„ä¼°æŠ¥å‘Šï¼š
{{
  "coherence": 0.92,  // è¿è´¯æ€§è¯„åˆ† 0-1
  "academic_tone": 0.88,  // å­¦æœ¯é£æ ¼è¯„åˆ† 0-1
  "resource_integration": "è‡ªç„¶/ç”Ÿç¡¬/æ— ",  // èµ„æºæ•´åˆè¯„ä»·
  "strengths": ["ä¼˜ç‚¹1", "ä¼˜ç‚¹2"],
  "weaknesses": ["ä¸è¶³1", "ä¸è¶³2"],
  "suggestions": ["æ”¹è¿›å»ºè®®1", "æ”¹è¿›å»ºè®®2"],
  "overall_score": 0.90  // æ€»ä½“è¯„åˆ† 0-1
}}
"""

        response = self.llm.complete(
            prompt,
            response_format="json",
            temperature=0.3
        )

        import json
        return json.loads(response)
