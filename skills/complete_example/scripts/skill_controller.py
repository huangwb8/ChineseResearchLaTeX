"""
CompleteExampleSkill - ä¸»æ§åˆ¶å™¨
AI å¢å¼ºç‰ˆç¤ºä¾‹ç”Ÿæˆå™¨ä¸»æ§åˆ¶å™¨
"""

import uuid
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List
import dataclasses


class CompleteExampleSkill:
    """AI å¢å¼ºç‰ˆç¤ºä¾‹ç”Ÿæˆå™¨ä¸»æ§åˆ¶å™¨"""

    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.skill_root = Path(config.get("skill_root", "skills/complete_example"))
        self.runs_dir = self.skill_root / "runs"
        self.runs_dir.mkdir(parents=True, exist_ok=True)

        # åˆå§‹åŒ– LLM å®¢æˆ·ç«¯
        self.llm_client = self._init_llm_client()

        # åŠ è½½æ¨¡æ¿
        self.templates = self._load_templates()

    def _init_llm_client(self):
        """åˆå§‹åŒ– LLM å®¢æˆ·ç«¯"""
        llm_config = self.config.get("llm", {})

        # é»˜è®¤ä¼˜å…ˆçœŸå® LLMï¼›åœ¨ç¼ºå°‘ä¾èµ–/å¯†é’¥æ—¶è‡ªåŠ¨é™çº§åˆ° Mockï¼ˆä¾¿äºæœ¬åœ°éªŒè¯ä¸å•å…ƒæµ‹è¯•ï¼‰ã€‚
        try:
            from .llm_client import LLMClient
            return LLMClient(llm_config)
        except Exception:
            class MockLLMClient:
                def complete(self, prompt: str, **kwargs) -> str:
                    # ä¿å®ˆ mockï¼šå°½é‡è¿”å›å¯è¢«åç»­æµç¨‹å¤„ç†çš„ç»“æ„
                    if kwargs.get("response_format") == "json":
                        return "{}"
                    return "ï¼ˆMock LLMï¼‰\\n\\n\\subsubsection{ç¤ºä¾‹æ ‡é¢˜}\\n\\subsubsubsection{ç¤ºä¾‹å­æ ‡é¢˜}\\nè¿™é‡Œæ˜¯ç¤ºä¾‹æ­£æ–‡ã€‚"

            return MockLLMClient()

    def _load_templates(self) -> Dict[str, str]:
        """åŠ è½½ LaTeX æ¨¡æ¿"""
        generation_config = self.config.get("generation", {})
        templates_config = generation_config.get("templates", {})

        # å¦‚æœé…ç½®ä¸­æœ‰æ¨¡æ¿ï¼Œä½¿ç”¨é…ç½®çš„æ¨¡æ¿
        if templates_config:
            return templates_config

        # é»˜è®¤æ¨¡æ¿
        return {
            "figure_insertion": r"""\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.8\textwidth]{{{path}}}
  \caption{{{caption}}}
  \label{{{label}}}
\end{figure}}""",
            "code_listing": r"""\begin{lstlisting}[language={{lang}}, caption={{{caption}}}, firstline=1, lastline={{lastline}}]
{{code}}
\end{lstlisting}""",
            "reference_citation": r"\cite{{{citekey}}}",
        }

    def _create_run_directory(self) -> Path:
        """ğŸ†• åˆ›å»ºæ–°çš„è¿è¡Œç›®å½•"""
        # ç”Ÿæˆå”¯ä¸€è¿è¡Œ ID
        run_id = f"{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:8]}"
        run_dir = self.runs_dir / run_id

        # åˆ›å»ºå­ç›®å½•
        (run_dir / "backups").mkdir(parents=True, exist_ok=True)
        (run_dir / "logs").mkdir(parents=True, exist_ok=True)
        (run_dir / "analysis").mkdir(parents=True, exist_ok=True)
        (run_dir / "output" / "preview").mkdir(parents=True, exist_ok=True)
        (run_dir / "output" / "applied").mkdir(parents=True, exist_ok=True)
        (run_dir / "output" / "report").mkdir(parents=True, exist_ok=True)

        # æ›´æ–° latest è½¯é“¾æ¥
        latest_link = self.runs_dir / "latest"
        if latest_link.exists():
            latest_link.unlink()
        try:
            latest_link.symlink_to(run_id)
        except OSError:
            # Windows å¯èƒ½éœ€è¦ç®¡ç†å‘˜æƒé™åˆ›å»ºè½¯é“¾æ¥
            pass

        # å†™å…¥å…ƒæ•°æ®
        metadata = {
            "run_id": run_id,
            "timestamp": datetime.now().isoformat(),
            "config": self.config
        }
        (run_dir / "metadata.json").write_text(
            json.dumps(metadata, ensure_ascii=False, indent=2),
            encoding="utf-8"
        )

        return run_dir

    def execute(self, project_name: str, options: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®Œæ•´çš„ç¤ºä¾‹ç”Ÿæˆæµç¨‹

        Args:
            project_name: é¡¹ç›®åç§°
            options: é€‰é¡¹ {
                content_density: "minimal" | "moderate" | "comprehensive",
                output_mode: "preview" | "apply" | "report",
                target_files: ["1.2.å†…å®¹ç›®æ ‡é—®é¢˜.tex", ...],
                narrative_hint: "ç”¨æˆ·è‡ªå®šä¹‰çš„å™äº‹æç¤ºï¼ˆå¯é€‰ï¼‰"
            }

        Returns:
            Dict: æ‰§è¡Œç»“æœæŠ¥å‘Š
        """

        # ========== é˜¶æ®µ 0ï¼šåˆå§‹åŒ– ==========
        # ğŸ†• åˆ›å»ºè¿è¡Œç›®å½•ï¼ˆæ‰€æœ‰è¾“å‡ºéƒ½æ”¾åœ¨è¿™é‡Œï¼Œä¸æ±¡æŸ“é¡¹ç›®ï¼‰
        run_dir = self._create_run_directory()

        # å‡è®¾é¡¹ç›®åœ¨ projects/ ç›®å½•ä¸‹
        project_path = Path("projects") / project_name

        report = {
            "project": project_name,
            "run_id": run_dir.name,  # ğŸ†• è®°å½•è¿è¡Œ ID
            "run_dir": str(run_dir),  # ğŸ†• è®°å½•è¿è¡Œç›®å½•
            "stages": {},
            "final_result": None
        }

        try:
            # ========== é˜¶æ®µ 1ï¼šèµ„æºæ‰«æï¼ˆç¡¬ç¼–ç ï¼‰ ==========
            report["stages"]["scan"] = self._stage_scan_resources(project_path)

            # ========== é˜¶æ®µ 2ï¼šè¯­ä¹‰åˆ†æï¼ˆAIï¼‰ ==========
            report["stages"]["analyze"] = self._stage_analyze_sections(
                project_path, options.get("target_files"), run_dir  # ğŸ†• ä¼ é€’ run_dir
            )

            # ========== é˜¶æ®µ 3ï¼šå†…å®¹ç”Ÿæˆï¼ˆAI + ç¡¬ç¼–ç ï¼‰ ==========
            report["stages"]["generate"] = self._stage_generate_content(
                project_path,
                report["stages"]["scan"]["resources"],
                report["stages"]["analyze"]["themes"],
                options.get("content_density", "moderate"),
                options.get("narrative_hint"),  # ä¼ é€’ç”¨æˆ·æç¤º
                run_dir  # ğŸ†• ä¼ é€’ run_dir
            )

            # ========== é˜¶æ®µ 4ï¼šåº”ç”¨å˜æ›´ï¼ˆç¡¬ç¼–ç ä¿æŠ¤ + AI è§£é‡Šï¼‰ ==========
            if options.get("output_mode") == "apply":
                report["stages"]["apply"] = self._stage_apply_changes(
                    project_path,
                    report["stages"]["generate"]["contents"],
                    run_dir
                )

            # ========== é˜¶æ®µ 5ï¼šè´¨é‡è¯„ä¼°ï¼ˆAIï¼‰ ==========
            report["stages"]["quality"] = self._stage_evaluate_quality(
                report["stages"]["generate"]["contents"]
            )

            # ========== é˜¶æ®µ 6ï¼šç”Ÿæˆè¾“å‡º ==========
            self._stage_generate_output(
                run_dir,
                report,
                options.get("output_mode", "preview")
            )

            report["final_result"] = "success"

        except Exception as e:
            report["final_result"] = "failed"
            report["error"] = str(e)

            # è®°å½•é”™è¯¯åˆ°æ—¥å¿—
            error_log = run_dir / "logs" / "error.log"
            error_log.write_text(str(e), encoding="utf-8")

        return report

    def _stage_scan_resources(self, project_path: Path) -> Dict:
        """é˜¶æ®µ 1ï¼šæ‰«æèµ„æº"""
        from .resource_scanner import ResourceScanner

        scanner = ResourceScanner(project_path)
        resources = scanner.scan_all()

        return {
            "status": "completed",
            "resources": resources,
            "summary": {
                "figures": len(resources.figures),
                "code": len(resources.code),
                "references": len(resources.references)
            }
        }

    def _stage_analyze_sections(
        self,
        project_path: Path,
        target_files: List[str] = None,
        run_dir: Path = None
    ) -> Dict:
        """é˜¶æ®µ 2ï¼šåˆ†æç« èŠ‚ä¸»é¢˜"""
        from .semantic_analyzer import SemanticAnalyzer

        analyzer = SemanticAnalyzer(self.llm_client, prompts=self.config.get("prompts", {}))
        themes = {}

        # é»˜è®¤ç›®æ ‡æ–‡ä»¶
        if target_files is None:
            target_files = [
                "extraTex/1.2.å†…å®¹ç›®æ ‡é—®é¢˜.tex",
                "extraTex/1.4.ç‰¹è‰²ä¸åˆ›æ–°.tex",
                "extraTex/1.5.ç ”ç©¶è®¡åˆ’.tex"
            ]

        for file_path in target_files:
            full_path = project_path / file_path
            if not full_path.exists():
                continue

            content = full_path.read_text(encoding="utf-8")
            theme = analyzer.analyze_section_theme(content)
            themes[file_path] = theme

        # ğŸ†• ä¿å­˜åˆ†æç»“æœåˆ° runs/<run_id>/analysis/
        if run_dir:
            analysis_file = run_dir / "analysis" / "section_themes.json"
            analysis_file.parent.mkdir(parents=True, exist_ok=True)
            themes_dict = {
                k: {
                    "theme": v.theme,
                    "key_concepts": v.key_concepts,
                    "writing_style": v.writing_style
                }
                for k, v in themes.items()
            }
            analysis_file.write_text(
                json.dumps(themes_dict, ensure_ascii=False, indent=2),
                encoding="utf-8"
            )

        return {
            "status": "completed",
            "themes": themes
        }

    def _stage_generate_content(
        self,
        project_path: Path,
        resources: 'ResourceReport',
        themes: Dict[str, 'SectionTheme'],
        density: str,
        narrative_hint: str = None,
        run_dir: Path = None
    ) -> Dict:
        """é˜¶æ®µ 3ï¼šç”Ÿæˆå†…å®¹ï¼ˆä½¿ç”¨æ™ºèƒ½èµ„æºåˆ†é…å™¨ï¼‰"""
        from .ai_content_generator import AIContentGenerator
        from .format_guard import FormatGuard
        from .resource_allocator import ResourceAllocator, ResourcePool

        # ========== ğŸ†• é˜¶æ®µ 3.1ï¼šæ™ºèƒ½èµ„æºåˆ†é… ==========
        # åˆ›å»ºèµ„æºæ± 
        resource_pool = ResourcePool(
            figures=resources.figures,
            code=resources.code,
            references=resources.references
        )

        # åˆ›å»ºèµ„æºåˆ†é…å™¨ï¼ˆä½¿ç”¨é…ç½®ä¸­çš„ç¯‡å¹…æ§åˆ¶å‚æ•°ï¼‰
        allocator_config = self.config.get("page_control", {})
        allocator = ResourceAllocator(allocator_config)

        # ä¸ºæ¯ä¸ªç« èŠ‚åˆ†é…èµ„æº
        allocation_plans, allocation_summary = allocator.allocate_resources_for_project(
            resource_pool=resource_pool,
            section_themes=themes
        )

        # ä¿å­˜åˆ†é…æ–¹æ¡ˆåˆ° runs/<run_id>/analysis/
        if run_dir:
            allocation_file = run_dir / "analysis" / "resource_allocation.json"
            allocation_file.parent.mkdir(parents=True, exist_ok=True)
            allocation_data = {
                "summary": allocation_summary,
                "plans": [
                    {
                        "file_path": p.file_path,
                        "allocated_resources": [
                            {
                                "path": r.path,
                                "type": r.type,
                                "filename": r.filename
                            }
                            for r in p.allocated_resources
                        ],
                        "target_word_count": p.target_word_count,
                        "estimated_pages": p.estimated_pages
                    }
                    for p in allocation_plans
                ]
            }
            allocation_file.write_text(
                json.dumps(allocation_data, ensure_ascii=False, indent=2),
                encoding="utf-8"
            )

        # ========== é˜¶æ®µ 3.2ï¼šæ ¹æ®åˆ†é…æ–¹æ¡ˆç”Ÿæˆå†…å®¹ ==========
        generator = AIContentGenerator(
            self.llm_client,
            self.templates,
            FormatGuard(project_path, run_dir),
            config=self.config,
        )

        contents = {}

        # æ ¹æ® allocation_plans é€ä¸ªç”Ÿæˆå†…å®¹
        for plan in allocation_plans:
            file_path = plan.file_path
            theme = themes[file_path]

            full_path = project_path / file_path
            existing_content = full_path.read_text(encoding="utf-8")

            # ğŸ†• ä½¿ç”¨åˆ†é…çš„èµ„æºè€Œéå…¨å±€ Top-K
            new_content = generator.generate_section_content_with_allocation(
                allocated_resources=plan.allocated_resources,
                target_word_count=plan.target_word_count,
                section_theme=theme,
                existing_content=existing_content,
                narrative_hint=narrative_hint,
                file_path=file_path,
            )

            contents[file_path] = {
                "old_content": existing_content,
                "new_content": new_content,
                "theme": theme,
                "allocation_plan": plan  # ğŸ†• è®°å½•åˆ†é…æ–¹æ¡ˆ
            }

        return {
            "status": "completed",
            "contents": contents
        }

    def _stage_apply_changes(
        self,
        project_path: Path,
        contents: Dict,
        run_dir: Path
    ) -> Dict:
        """é˜¶æ®µ 4ï¼šåº”ç”¨å˜æ›´"""
        from .format_guard import FormatGuard

        guard = FormatGuard(project_path, run_dir)
        results = {}

        for file_path, content_data in contents.items():
            try:
                full_path = project_path / file_path
                success = guard.safe_modify_file(
                    file_path=full_path,
                    new_content=content_data["new_content"],
                    ai_explanation=f"æ ¹æ®ä¸»é¢˜ '{content_data['theme'].theme}' ç”Ÿæˆç¤ºä¾‹å†…å®¹"
                )
                results[file_path] = {"status": "applied" if success else "failed"}
            except Exception as e:
                results[file_path] = {"status": "failed", "error": str(e)}

        return {
            "status": "completed",
            "results": results
        }

    def _stage_evaluate_quality(self, contents: Dict) -> Dict:
        """é˜¶æ®µ 5ï¼šè´¨é‡è¯„ä¼°"""
        from .semantic_analyzer import SemanticAnalyzer

        analyzer = SemanticAnalyzer(self.llm_client, prompts=self.config.get("prompts", {}))
        evaluations = {}

        for file_path, content_data in contents.items():
            evaluation = analyzer.evaluate_content_quality(
                content_data["new_content"],
                content_data["theme"]
            )
            evaluations[file_path] = evaluation

        return {
            "status": "completed",
            "evaluations": evaluations
        }

    def _stage_generate_output(
        self,
        run_dir: Path,
        report: Dict,
        output_mode: str
    ):
        """é˜¶æ®µ 6ï¼šç”Ÿæˆè¾“å‡º"""
        def _json_default(obj):
            if dataclasses.is_dataclass(obj):
                return dataclasses.asdict(obj)
            if isinstance(obj, Path):
                return str(obj)
            # Fallback for odd container types
            if isinstance(obj, set):
                return list(obj)
            raise TypeError(f"Object of type {type(obj).__name__} is not JSON serializable")

        # ä¿å­˜å®Œæ•´æŠ¥å‘Š
        report_file = run_dir / "output" / "report" / "report.json"
        report_file.parent.mkdir(parents=True, exist_ok=True)
        report_file.write_text(
            json.dumps(report, ensure_ascii=False, indent=2, default=_json_default),
            encoding="utf-8"
        )

        # æ ¹æ® output_mode ç”Ÿæˆä¸åŒçš„è¾“å‡º
        if output_mode == "preview":
            # ç”Ÿæˆé¢„è§ˆæ–‡ä»¶
            self._generate_preview_output(run_dir, report)
        elif output_mode == "apply":
            # ç”Ÿæˆåº”ç”¨è¾“å‡º
            self._generate_apply_output(run_dir, report)
        elif output_mode == "report":
            # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
            self._generate_report_output(run_dir, report)

    def _generate_preview_output(self, run_dir: Path, report: Dict):
        """ç”Ÿæˆé¢„è§ˆè¾“å‡º"""
        preview_dir = run_dir / "output" / "preview"

        # ä¸ºæ¯ä¸ªæ–‡ä»¶ç”Ÿæˆé¢„è§ˆ
        for file_path, content_data in report["stages"]["generate"]["contents"].items():
            preview_file = preview_dir / f"{file_path.replace('/', '_')}.preview.tex"
            preview_file.parent.mkdir(parents=True, exist_ok=True)
            preview_file.write_text(
                content_data["new_content"],
                encoding="utf-8"
            )

    def _generate_apply_output(self, run_dir: Path, report: Dict):
        """ç”Ÿæˆåº”ç”¨è¾“å‡º"""
        apply_dir = run_dir / "output" / "applied"

        # è®°å½•å·²åº”ç”¨çš„æ–‡ä»¶
        applied_files = []
        if "apply" in report["stages"]:
            for file_path, result in report["stages"]["apply"]["results"].items():
                if result["status"] == "applied":
                    applied_files.append(file_path)

        applied_log = apply_dir / "applied_files.txt"
        applied_log.write_text("\n".join(applied_files), encoding="utf-8")

    def _generate_report_output(self, run_dir: Path, report: Dict):
        """ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š"""
        report_dir = run_dir / "output" / "report"

        # ç”Ÿæˆ Markdown æ ¼å¼çš„æŠ¥å‘Š
        md_lines = [
            f"# Complete Example Skill æ‰§è¡ŒæŠ¥å‘Š",
            f"",
            f"## åŸºæœ¬ä¿¡æ¯",
            f"- **é¡¹ç›®**: {report['project']}",
            f"- **è¿è¡Œ ID**: {report['run_id']}",
            f"- **æ—¶é—´**: {run_dir.name.split('_')[0]}",
            f"",
            f"## æ‰§è¡Œç»“æœ",
            f"- **çŠ¶æ€**: {report['final_result']}",
            f"",
        ]

        # æ·»åŠ å„é˜¶æ®µä¿¡æ¯
        for stage_name, stage_data in report.get("stages", {}).items():
            md_lines.append(f"## {stage_name.upper()} é˜¶æ®µ")
            md_lines.append(f"- **çŠ¶æ€**: {stage_data.get('status', 'unknown')}")

            # æ·»åŠ è¯¦ç»†ä¿¡æ¯
            if "summary" in stage_data:
                md_lines.append("- **æ‘˜è¦**:")
                for k, v in stage_data["summary"].items():
                    md_lines.append(f"  - {k}: {v}")

            md_lines.append("")

        # å†™å…¥ Markdown æŠ¥å‘Š
        md_file = report_dir / "report.md"
        md_file.write_text("\n".join(md_lines), encoding="utf-8")
