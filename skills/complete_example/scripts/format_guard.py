"""
FormatGuard - ç¡¬ç¼–ç æ ¼å¼å®ˆæŠ¤å™¨
ğŸ”§ ç¡¬ç¼–ç ï¼šä¸¥æ ¼ä¿æŠ¤æ ¼å¼è®¾ç½®ä¸è¢«ä¿®æ”¹
ğŸ”’ é›†æˆ SecurityManager å¢å¼ºå®‰å…¨ä¿æŠ¤
"""

import hashlib
import re
import shutil
import subprocess
import json
from pathlib import Path
from dataclasses import dataclass
from typing import List, Dict, Optional, Any
from datetime import datetime


class FormatProtectionError(Exception):
    """æ ¼å¼ä¿æŠ¤å¼‚å¸¸"""
    pass


class CompilationError(Exception):
    """ç¼–è¯‘å¼‚å¸¸"""
    pass


# å¯¼å…¥å®‰å…¨ç®¡ç†å™¨
try:
    from .security_manager import SecurityManager, SecurityError
    SECURITY_MANAGER_AVAILABLE = True
except ImportError:
    SECURITY_MANAGER_AVAILABLE = False


@dataclass
class ProtectedZone:
    """å—ä¿æŠ¤çš„æ ¼å¼åŒºåŸŸ"""
    name: str           # åŒºåŸŸåç§°
    start: int          # èµ·å§‹ä½ç½®
    end: int            # ç»“æŸä½ç½®
    content: str        # åŸå§‹å†…å®¹
    line_number: int    # è¡Œå·


class FormatGuard:
    """ç¡¬ç¼–ç ï¼šä¸¥æ ¼çš„æ ¼å¼ä¿æŠ¤æœºåˆ¶"""

    # å—ä¿æŠ¤çš„ LaTeX å‘½ä»¤ï¼ˆæ­£åˆ™æ¨¡å¼ï¼‰
    PROTECTED_PATTERNS = [
        r'\\setlength\{[^}]+\}\{[^}]+\}',           # \setlength{\parindent}{2em}
        r'\\geometry\{[^}]+\}',                      # \geometry{left=3cm,...}
        r'\\definecolor\{[^}]+\}\{[^}]+\}\{[^}]+\}', # \definecolor{MsBlue}{RGB}{...}
        r'\\setCJKfamilyfont\{[^}]+\}(\[[^]]*\])?\{[^}]+\}',  # å­—ä½“è®¾ç½®
        r'\\setmainfont(\[[^]]*\])?\{[^}]+\}',       # è‹±æ–‡å­—ä½“
        r'\\titleformat\{[^}]+\}\{[^}]*\}\{[^}]*\}\{[^}]*\}\{[^}]*\}\{[^}]*\}',  # æ ‡é¢˜æ ¼å¼
        r'\\setlist\[[^]]+\]\{[^}]+\}',             # \setlist[enumerate]{...}
        r'\\newcommand\{[^}]+\}',                    # è‡ªå®šä¹‰å‘½ä»¤
        r'\\renewcommand\{[^}]+\}',                  # é‡å®šä¹‰å‘½ä»¤
    ]

    def __init__(
        self,
        project_path: Path,
        run_dir: Path = None,
        enable_security_manager: bool = True,
        config: Optional[Dict[str, Any]] = None,
    ):
        """
        Args:
            project_path: é¡¹ç›®æ ¹ç›®å½•ï¼ˆè¢«ä¿æŠ¤çš„é¡¹ç›®ï¼Œä¸å†™å…¥ä»»ä½•æ–‡ä»¶ï¼‰
            run_dir: è¿è¡Œç›®å½•ï¼ˆå¤‡ä»½å’Œæ—¥å¿—æ”¾åœ¨è¿™é‡Œï¼Œéš”ç¦»é¡¹ç›®æ±¡æŸ“ï¼‰
            enable_security_manager: æ˜¯å¦å¯ç”¨å¢å¼ºå®‰å…¨ç®¡ç†å™¨
        """
        self.project_path = Path(project_path)
        self.run_dir = Path(run_dir) if run_dir else self.project_path
        self.config = config or {}

        fp_cfg = (self.config.get("format_protection") or {})
        self.protected_files = list(fp_cfg.get("protected_files") or ["extraTex/@config.tex", "main.tex"])
        self.compile_verify_cfg = (fp_cfg.get("compile_verify") or {})
        self.compile_verify_enabled = bool(self.compile_verify_cfg.get("enabled", True))
        self.compile_engine = str(self.compile_verify_cfg.get("engine", "xelatex"))
        self.compile_timeout_sec = int(self.compile_verify_cfg.get("timeout", 60))

        self.format_hashes = self._compute_format_hashes()

        # ğŸ”’ é›†æˆå®‰å…¨ç®¡ç†å™¨
        self.security_manager: Optional[SecurityManager] = None
        if enable_security_manager and SECURITY_MANAGER_AVAILABLE:
            self.security_manager = SecurityManager(
                project_path=self.project_path,
                hash_file=self.project_path / ".format_hashes.json",
                config=self.config,
            )
            # åˆå§‹åŒ–å“ˆå¸Œï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            if not self.security_manager.hash_file.exists():
                self.security_manager.initialize_hashes()

    def _compute_format_hashes(self) -> Dict[str, str]:
        """è®¡ç®—å…³é”®æ ¼å¼æ–‡ä»¶çš„å“ˆå¸Œå€¼"""
        hashes = {}
        for file_path in self.protected_files:
            full_path = self.project_path / file_path
            if full_path.exists():
                content = full_path.read_text(encoding="utf-8")
                # æå–æ ¼å¼å®šä¹‰è¡Œ
                format_lines = self._extract_format_lines(content)
                hashes[file_path] = hashlib.sha256(
                    "".join(format_lines).encode()
                ).hexdigest()
        return hashes

    def _extract_format_lines(self, content: str) -> List[str]:
        """æå–æ ¼å¼å®šä¹‰è¡Œ"""
        lines = content.split("\n")
        format_lines = []

        for line in lines:
            # æ£€æŸ¥æ˜¯å¦åŒ…å«å—ä¿æŠ¤çš„å‘½ä»¤
            for pattern in self.PROTECTED_PATTERNS:
                if re.search(pattern, line):
                    format_lines.append(line)
                    break

        return format_lines

    def extract_protected_zones(self, content: str) -> List[ProtectedZone]:
        """
        ğŸ”§ ç¡¬ç¼–ç ï¼šä½¿ç”¨æ­£åˆ™æå–ä¿æŠ¤åŒºåŸŸ

        Args:
            content: æ–‡ä»¶å†…å®¹

        Returns:
            List[ProtectedZone]: ä¿æŠ¤åŒºåŸŸåˆ—è¡¨
        """
        zones = []
        lines = content.split("\n")

        for line_no, line in enumerate(lines, 1):
            for pattern in self.PROTECTED_PATTERNS:
                matches = re.finditer(pattern, line)
                for match in matches:
                    zones.append(ProtectedZone(
                        name="format_definition",
                        start=match.start(),
                        end=match.end(),
                        content=match.group(0),
                        line_number=line_no
                    ))

        return zones

    def validate_format_integrity(self) -> Dict[str, bool]:
        """
        ğŸ”§ ç¡¬ç¼–ç ï¼šéªŒè¯æ ¼å¼æœªè¢«ç¯¡æ”¹

        Returns:
            Dict: {æ–‡ä»¶è·¯å¾„: æ˜¯å¦å®Œæ•´}
        """
        results = {}
        current_hashes = self._compute_format_hashes()

        for file_path, original_hash in self.format_hashes.items():
            current_hash = current_hashes.get(file_path)
            results[file_path] = (current_hash == original_hash)

        return results

    def safe_modify_file(
        self,
        file_path: Path,
        new_content: str,
        ai_explanation: str = None,
        auto_sanitize: bool = True,
        compile_verify: Optional[bool] = None,
    ) -> Optional[Path]:
        """
        ğŸ¤ åä½œç‚¹ï¼šAI å»ºè®®ä¿®æ”¹ + ç¡¬ç¼–ç å®‰å…¨æ£€æŸ¥
        ğŸ”’ é›†æˆå®‰å…¨ç®¡ç†å™¨è¿›è¡Œé¢„æ£€æŸ¥

        Args:
            file_path: è¦ä¿®æ”¹çš„æ–‡ä»¶è·¯å¾„
            new_content: æ–°å†…å®¹
            ai_explanation: AI å¯¹ä¿®æ”¹çš„è§£é‡Š
            auto_sanitize: æ˜¯å¦è‡ªåŠ¨æ¸…ç†æ ¼å¼æ³¨å…¥

        Returns:
            Optional[Path]: å¤‡ä»½æ–‡ä»¶è·¯å¾„ï¼›å¤±è´¥æ—¶æŠ›å¼‚å¸¸

        Raises:
            FormatProtectionError: æ ¼å¼ä¿æŠ¤å¤±è´¥
            CompilationError: ç¼–è¯‘å¤±è´¥
            SecurityError: å®‰å…¨æ£€æŸ¥å¤±è´¥ï¼ˆé€šè¿‡ SecurityManagerï¼‰
        """
        file_path = Path(file_path)

        # ä»…å…è®¸ä¿®æ”¹ project_path å†…çš„æ–‡ä»¶ï¼Œé¿å…è·¯å¾„ç©¿è¶Š/è¯¯å†™åˆ°ä»“åº“å¤–ã€‚
        try:
            file_path.resolve().relative_to(self.project_path.resolve())
        except Exception:
            raise FormatProtectionError(f"æ‹’ç»ä¿®æ”¹é¡¹ç›®ç›®å½•ä¹‹å¤–çš„æ–‡ä»¶ï¼š{file_path}")

        # ========== ğŸ”’ å®‰å…¨ç®¡ç†å™¨é¢„æ£€æŸ¥ ==========
        if self.security_manager:
            # 1. ç³»ç»Ÿæ–‡ä»¶é»‘åå• + å®Œæ•´æ€§æ ¡éªŒ
            self.security_manager.pre_edit_check(file_path)

            # 2. æ ¼å¼æ³¨å…¥æ£€æŸ¥ + è‡ªåŠ¨æ¸…ç†
            new_content = self.security_manager.pre_apply_check(
                file_path, new_content, auto_sanitize
            )

        # æ£€æŸ¥æ˜¯å¦ä¸ºå—ä¿æŠ¤æ–‡ä»¶ï¼ˆå— config.yaml æ§åˆ¶ï¼‰
        try:
            relative_path = file_path.resolve().relative_to(self.project_path.resolve()).as_posix()
        except ValueError:
            relative_path = str(file_path)

        if relative_path in self.protected_files:
            raise FormatProtectionError(
                f"æ‹’ç»ä¿®æ”¹å—ä¿æŠ¤æ–‡ä»¶ï¼š{relative_path}\n"
                f"AI è§£é‡Šï¼š{ai_explanation or 'æœªæä¾›'}"
            )

        # ========== é˜¶æ®µ 1ï¼šç¡¬ç¼–ç  - å¤‡ä»½ ==========
        # ğŸ†• å¤‡ä»½åˆ° .complete_example/<run_id>/backups/ è€Œéé¡¹ç›®ç›®å½•
        backup_dir = self.run_dir / "backups"
        backup_filename = f"{relative_path.replace('/', '_')}.backup"
        backup_path = backup_dir / backup_filename
        backup_path.parent.mkdir(parents=True, exist_ok=True)
        shutil.copy(file_path, backup_path)

        # ========== é˜¶æ®µ 2ï¼šç¡¬ç¼–ç  - æ£€æŸ¥æ ¼å¼åŒºåŸŸ ==========
        old_content = file_path.read_text(encoding="utf-8")
        protected_zones = self.extract_protected_zones(old_content)

        for zone in protected_zones:
            if zone.content not in new_content:
                # ğŸ§  AIï¼šå°è¯•è¯Šæ–­
                diagnosis = self._ai_diagnose_format_loss(
                    zone, old_content, new_content
                )

                # ğŸ§  AIï¼šå°è¯•ä¿®å¤
                fixed_content = self._ai_attempt_fix(
                    new_content, zone, diagnosis
                )

                # å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œå›æ»š
                if zone.content not in fixed_content:
                    shutil.copy(backup_path, file_path)
                    raise FormatProtectionError(
                        f"æ ¼å¼ä¿æŠ¤å¤±è´¥ï¼Œå·²å›æ»š\n"
                        f"ç ´ååŒºåŸŸï¼š{zone.name} (ç¬¬ {zone.line_number} è¡Œ)\n"
                        f"åŸå†…å®¹ï¼š{zone.content}\n"
                        f"AI è¯Šæ–­ï¼š{diagnosis}\n"
                        f"AI è§£é‡Šï¼š{ai_explanation or 'æœªæä¾›'}"
                    )
                else:
                    new_content = fixed_content

        # ========== é˜¶æ®µ 3ï¼šç¡¬ç¼–ç  - åº”ç”¨ä¿®æ”¹ ==========
        file_path.write_text(new_content, encoding="utf-8")

        # ========== é˜¶æ®µ 4ï¼šç¡¬ç¼–ç  - ç¼–è¯‘éªŒè¯ï¼ˆå¯æŒ‰æ‰¹æ¬¡å¤–éƒ¨ç»Ÿä¸€æ‰§è¡Œï¼‰ ==========
        do_compile = self.compile_verify_enabled if compile_verify is None else bool(compile_verify)
        if do_compile and not self.compile_verify_project():
            shutil.copy(backup_path, file_path)
            raise CompilationError(
                "ç¼–è¯‘å¤±è´¥ï¼Œå·²å›æ»š\n"
                f"ä¿®æ”¹çš„æ–‡ä»¶ï¼š{file_path}\n"
                f"AI è§£é‡Šï¼š{ai_explanation or 'æœªæä¾›'}"
            )

        # ========== é˜¶æ®µ 5ï¼šæˆåŠŸï¼Œè®°å½• ==========
        self._log_modification(
            file_path, backup_path, ai_explanation
        )

        return backup_path

    def _ai_diagnose_format_loss(
        self,
        zone: ProtectedZone,
        old_content: str,
        new_content: str
    ) -> str:
        """ğŸ§  AIï¼šè¯Šæ–­æ ¼å¼ä¸¢å¤±çš„åŸå› """
        # ç®€åŒ–ç‰ˆæœ¬ï¼šè¿”å›ç¡¬ç¼–ç çš„è¯Šæ–­
        return f"æ ¼å¼å®šä¹‰ '{zone.content[:30]}...' åœ¨æ–°å†…å®¹ä¸­æœªæ‰¾åˆ°"

    def _ai_attempt_fix(
        self,
        new_content: str,
        zone: ProtectedZone,
        diagnosis: str
    ) -> str:
        """ğŸ§  AIï¼šå°è¯•ä¿®å¤æ ¼å¼ä¸¢å¤±"""
        # ç®€åŒ–ç‰ˆæœ¬ï¼šç›´æ¥æ’å…¥åŸæ ¼å¼
        # å®é™…ç‰ˆæœ¬å¯ä»¥è®© AI åˆ†æä¸Šä¸‹æ–‡å¹¶æ™ºèƒ½æ’å…¥
        return new_content  # ä¸åšä¿®æ”¹ï¼Œè®©å¤–éƒ¨å¤„ç†

    def compile_verify_project(self) -> bool:
        """
        ç¡¬ç¼–ç ï¼šé¡¹ç›®çº§ç¼–è¯‘éªŒè¯ï¼ˆå°½é‡é¿å…æ±¡æŸ“é¡¹ç›®æ ¹ç›®å½•ï¼‰ã€‚

        è¯´æ˜ï¼š
        - ä½¿ç”¨ `-output-directory` å°† aux/pdf ç­‰äº§ç‰©å†™å…¥æœ¬æ¬¡ run_dir çš„æ„å»ºç›®å½•ï¼›
          é¡¹ç›®æ ¹ç›®å½•ä»ä½œä¸º cwdï¼Œä¿è¯ç›¸å¯¹è·¯å¾„ï¼ˆextraTex/ã€figures/ã€references/ï¼‰å¯è§£æã€‚
        - æŒ‰ä»“åº“çº¦å®šæ‰§è¡Œ 4 æ­¥ï¼šxelatex â†’ bibtex â†’ xelatex â†’ xelatexï¼ˆå¦‚æ£€æµ‹åˆ° bibtex éœ€æ±‚ï¼‰ã€‚
        """
        if not self.compile_verify_enabled:
            return True

        project_root = self.project_path
        main_tex = project_root / "main.tex"
        if not main_tex.exists():
            return False

        build_dir = self.run_dir / "_latex_build"
        build_dir.mkdir(parents=True, exist_ok=True)

        log_file = self.run_dir / "logs" / "compile.log"
        log_file.parent.mkdir(parents=True, exist_ok=True)

        def _append_log(title: str, result: subprocess.CompletedProcess[str]):
            with open(log_file, "a", encoding="utf-8") as f:
                f.write(f"\n\n===== {title} =====\n")
                f.write(result.stdout or "")
                f.write("\n\n=== STDERR ===\n")
                f.write(result.stderr or "")

        def _run(cmd: List[str], title: str) -> bool:
            try:
                result = subprocess.run(
                    cmd,
                    cwd=project_root,
                    capture_output=True,
                    timeout=self.compile_timeout_sec,
                    text=True,
                )
                _append_log(title, result)
                return result.returncode == 0
            except subprocess.TimeoutExpired:
                with open(log_file, "a", encoding="utf-8") as f:
                    f.write(f"\n\n===== {title} =====\nç¼–è¯‘è¶…æ—¶ï¼ˆ{self.compile_timeout_sec}ç§’ï¼‰\n")
                return False
            except Exception as e:
                with open(log_file, "a", encoding="utf-8") as f:
                    f.write(f"\n\n===== {title} =====\nç¼–è¯‘å¼‚å¸¸ï¼š{e}\n")
                return False

        # æ¸…ç©ºæ—§æ—¥å¿—ï¼Œé¿å…æ··æ·†
        log_file.write_text("", encoding="utf-8")

        engine = self.compile_engine
        # 1) xelatex
        if not _run([engine, "-interaction=nonstopmode", f"-output-directory={build_dir}", "main.tex"], f"{engine} #1"):
            return False

        # 2) bibtexï¼ˆä»…åœ¨ aux å£°æ˜äº† bibdata æ—¶è¿è¡Œï¼‰
        aux_file = build_dir / "main.aux"
        need_bibtex = False
        if aux_file.exists():
            try:
                aux_text = aux_file.read_text(encoding="utf-8", errors="ignore")
                need_bibtex = "\\bibdata" in aux_text
            except Exception:
                need_bibtex = False

        if need_bibtex:
            # bibtex éœ€è¦ä»é¡¹ç›®æ ¹ç›®å½•è§£æ references/*.bib çš„ç›¸å¯¹è·¯å¾„ï¼š
            # ä¼˜å…ˆä½¿ç”¨â€œç›¸å¯¹è·¯å¾„â€å‚æ•°ï¼Œé¿å… TeX å®‰å…¨ç­–ç•¥ï¼ˆopenout_anyï¼‰é˜»æ­¢å†™å…¥ç»å¯¹è·¯å¾„ *.blg/*.bblã€‚
            try:
                bibtex_target = (build_dir / "main").resolve().relative_to(project_root.resolve()).as_posix()
            except Exception:
                bibtex_target = None

            if bibtex_target:
                if not _run(["bibtex", bibtex_target], "bibtex"):
                    return False
            else:
                with open(log_file, "a", encoding="utf-8") as f:
                    f.write("\n\n===== bibtex =====\nè·³è¿‡ï¼šbuild_dir ä¸åœ¨é¡¹ç›®ç›®å½•å†…ï¼Œæ— æ³•å®‰å…¨è¿è¡Œ bibtexã€‚\n")

        # 3) xelatex
        if not _run([engine, "-interaction=nonstopmode", f"-output-directory={build_dir}", "main.tex"], f"{engine} #2"):
            return False

        # 4) xelatex
        if not _run([engine, "-interaction=nonstopmode", f"-output-directory={build_dir}", "main.tex"], f"{engine} #3"):
            return False

        return True

    def _log_modification(
        self,
        file_path: Path,
        backup_path: Path,
        ai_explanation: str
    ):
        """ğŸ†• è®°å½•ä¿®æ”¹æ—¥å¿—åˆ° .complete_example/<run_id>/logs/"""
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "file": str(file_path),
            "backup": str(backup_path),
            "ai_explanation": ai_explanation or "æœªæä¾›"
        }
        # ğŸ†• å†™å…¥ .complete_example/<run_id>/logs/execution.log è€Œéé¡¹ç›®ç›®å½•
        log_file = self.run_dir / "logs" / "execution.log"
        log_file.parent.mkdir(parents=True, exist_ok=True)
        with open(log_file, "a", encoding="utf-8") as f:
            f.write(json.dumps(log_entry, ensure_ascii=False) + "\n")
