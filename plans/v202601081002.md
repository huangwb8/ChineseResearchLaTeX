# AI智能内容优化迁移实施计划

**计划编号**: v202601081002
**创建日期**: 2026-01-08
**当前版本**: v1.2.0 → 目标版本 v1.3.0+
**计划状态**: 待审查

---

## 一、现状分析

### 1.1 已实现功能（20%完成度）

| 功能模块 | 实现状态 | 说明 |
|---------|---------|------|
| AI语义文件映射 | ✅ 已实现 | mapping_engine.py 使用AI判断文件对应关系 |
| 资源文件扫描复制 | ✅ 已实现 | resource_manager.py 处理图片/代码文件 |
| 引用完整性验证 | ✅ 已实现 | reference_validator.py 检查label/ref/cite |
| 硬编码内容复制 | ✅ 已实现 | migrator.py:133-134 直接复制文件 |
| 安全白名单机制 | ✅ 已实现 | 保护 main.tex、@config.tex 不被修改 |
| 自动备份回滚 | ✅ 已实现 | snapshot_targets/restore_snapshot |

### 1.2 核心缺失功能（80%待实现）

| 用户需求 | 当前状态 | 缺失原因 |
|---------|---------|----------|
| AI智能优化写作 | ❌ 未实现 | 当前仅为硬编码复制，无内容重构 |
| 引用关系保护 | ❌ 未实现 | AI重写时可能破坏 \ref{}、\cite{} |
| 字数限制适配 | ❌ 未实现 | 新模板可能有不同字数要求 |
| 专业PI写作风格 | ❌ 未实现 | 无质量保证机制 |
| 多轮迭代优化 | ❌ 未实现 | 无反馈改进循环 |

### 1.3 关键代码位置

**当前内容迁移逻辑** ([migrator.py:125-136](core/migrator.py#L125-L136))：

```python
if t_type == "copy_one_to_one":
    if not source_rel:
        skipped.append({**t, "skip_reason": "missing_source"})
        continue
    source_abs = (old_project / source_rel).resolve()
    if not source_abs.exists():
        skipped.append({**t, "skip_reason": f"source_not_found: {source_rel}"})
        continue
    content = safe_read_text(source_abs)
    _atomic_write(target_abs, content)  # ← 硬编码复制，无AI优化
    applied.append({**t, "status": "copied"})
    continue
```

**问题**：直接复制旧内容到新模板，未考虑：
- 新模板的格式差异（章节编号、结构要求）
- 字数限制变化
- 内容质量提升需求
- 引用关系保护

---

## 二、技术架构设计

### 2.1 四步迁移流程

```
旧项目内容
    ↓
┌─────────────────────────────────────────────────────────────┐
│ Step 1: 硬编码复制（已实现 ✅）                               │
│ - 保护原始内容不丢失                                          │
│ - 处理一对多、多对一映射                                      │
│ - 复制资源文件                                                │
│ - 验证引用完整性                                              │
└─────────────────────────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────────────────────────┐
│ Step 2: AI智能优化写作（核心待实现 ❌）                        │
│ - 分析新模板要求（结构、字数、风格）                           │
│ - 逐章节AI重写优化                                            │
│ - 保护引用关系（硬编码规则 + AI约束）                         │
│ - 调整字数以符合限制                                          │
└─────────────────────────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────────────────────────┐
│ Step 3: 质量保证（待实现 ❌）                                  │
│ - LaTeX编译验证（xelatex×4）                                 │
│ - 引用完整性二次验证                                          │
│ - 专业写作风格检查（术语一致性、逻辑连贯性）                   │
│ - 人工审核触发条件                                            │
└─────────────────────────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────────────────────────┐
│ Step 4: 多轮迭代优化（待实现 ❌）                              │
│ - 根据质量问题反馈                                            │
│ - 调用专业NSFC写作技能                                        │
│ - 收敛判断（质量≥90% 或 连续改进<5%）                        │
└─────────────────────────────────────────────────────────────┘
    ↓
新项目（专业PI级国自然标书）
```

### 2.2 核心模块设计

#### 2.2.1 内容优化引擎（`core/content_optimizer.py`）

**职责**：AI驱动的内容重写和优化

**核心函数**：

```python
async def optimize_chapter_content(
    old_content: str,
    new_template_requirements: TemplateRequirements,
    chapter_context: ChapterContext,
    reference_constraints: ReferenceConstraints,
    config: Dict,
) -> OptimizationResult:
    """
    AI优化章节内容

    Args:
        old_content: 旧项目章节内容
        new_template_requirements: 新模板要求（字数、结构、格式）
        chapter_context: 章节上下文（位置、标题、前后关系）
        reference_constraints: 引用约束（必须保留的label、cite）
        config: 优化配置（温度、模型、轮次）

    Returns:
        OptimizationResult: 优化后内容、元数据、质量评分
    """
```

**关键特性**：
1. **引用保护**（硬编码规则 + AI提示词）：
   ```python
   # 硬编码保护：在AI调用前提取引用
   protected_refs = extract_refs(old_content) | extract_cites(old_content)

   # AI提示词约束
   prompt = f"""
   请优化以下LaTeX内容，严格遵守以下规则：
   1. 绝对禁止修改或删除任何 \\ref{{...}} 和 \\cite{{...}} 命令
   2. 绝对禁止修改或删除任何 \\label{{...}} 命令
   3. 可以调整引用前后的文字，但必须保留引用命令本身
   4. 引用命令必须完整保留，包括大括号内的内容
   ...
   """
   ```

2. **字数控制**：
   ```python
   # 分阶段字数适配
   if len(new_content) > max_word_count * 1.2:
       # 字数超标20%以上：触发压缩策略
       strategy = "compress"
   elif len(new_content) < min_word_count * 0.8:
       # 字数不足80%：触发扩充策略
       strategy = "expand"
   else:
       strategy = "fine_tune"
   ```

3. **专业风格保证**：
   ```python
   prompt += """
   写作风格要求：
   - 学术严谨性：使用精确的科学术语，避免口语化表达
   - 逻辑连贯性：段落之间有清晰的逻辑过渡
   - 论证充分性：每个论点都有充分的证据支持
   - 专业PI视角：展现项目负责人（PI）的科研视野和深度
   - NSFC标书规范：符合国家自然科学基金申请书的写作规范
   """
   ```

#### 2.2.2 引用保护器（`core/reference_guard.py`）

**职责**：确保AI优化不破坏引用关系

**核心函数**：

```python
def protect_references(content: str) -> ProtectedContent:
    """
    保护LaTeX内容中的引用命令

    Returns:
        ProtectedContent:
        - original: 原始内容
        - protected: 替换引用后的内容（用于AI处理）
        - ref_map: 引用占位符映射（{ref_1: "\\fig{tab:results}"}）
    """

def restore_references(optimized_content: str, ref_map: Dict[str, str]) -> str:
    """
    将占位符还原为LaTeX引用命令
    """

def validate_reference_preservation(
    original: str,
    optimized: str,
) -> ReferencePreservationReport:
    """
    验证优化后内容是否保留了所有引用
    """
```

**工作流程**：

```
原始内容：
"实验结果如图\\ref{fig:results}所示，与文献\\cite{smith2023}一致。"
    ↓
protect_references()
    ↓
AI处理内容：
"实验结果如图 REF_PLACEHOLDER_1 所示，与文献 REF_PLACEHOLDER_2 一致。"
    ↓
AI优化（输出）：
"根据实验结果 REF_PLACEHOLDER_1 ，我们的发现与 REF_PLACEHOLDER_2 高度吻合。"
    ↓
restore_references()
    ↓
最终内容：
"根据实验结果 \\ref{fig:results} ，我们的发现与 \\cite{smith2023} 高度吻合。"
```

**硬编码安全检查**：

```python
def validate_reference_preservation(original: str, optimized: str) -> bool:
    """
    硬编码验证：确保所有引用都完整保留
    """
    original_refs = extract_refs(original) | extract_cites(original) | extract_labels(original)
    optimized_refs = extract_refs(optimized) | extract_cites(optimized) | extract_labels(optimized)

    if original_refs != optimized_refs:
        raise ReferenceIntegrityError(
            f"引用完整性检查失败：\n"
            f"  原始引用: {original_refs}\n"
            f"  优化后引用: {optimized_refs}\n"
            f"  缺失引用: {original_refs - optimized_refs}"
        )

    return True
```

#### 2.2.3 质量验证器（`core/quality_validator.py`）

**职责**：多维度评估优化后内容质量

**验证维度**：

```python
@dataclass
class QualityReport:
    """质量报告"""
    # LaTeX编译
    compilation_success: bool
    compilation_errors: List[str]
    compilation_warnings: List[str]

    # 引用完整性
    reference_integrity: float  # 0-1
    undefined_refs: Set[str]
    missing_cites: Set[str]

    # 字数合规性
    word_count_compliant: bool
    actual_word_count: int
    target_word_count: Tuple[int, int]  # (min, max)

    # 写作风格评分（AI评分）
    terminology_score: float  # 术语一致性
    logic_coherence_score: float  # 逻辑连贯性
    evidence_quality_score: float  # 论证充分性
    professional_style_score: float  # 专业风格

    # 总体评分
    overall_score: float  # 0-1
    passed: bool  # 是否通过质量阈值
```

**验证流程**：

```python
def validate_migration_quality(
    new_project: Path,
    optimized_files: List[str],
    quality_thresholds: QualityThresholds,
) -> QualityReport:
    """
    多维度质量验证
    """
    # 1. LaTeX编译验证
    compilation_result = compile_latex(new_project)

    # 2. 引用完整性验证
    ref_report = validate_references(new_project, optimized_files, bib_files)

    # 3. 字数合规性检查
    word_count_report = check_word_counts(new_project, optimized_files)

    # 4. AI写作风格评分
    style_scores = ai_rate_writing_style(new_project, optimized_files)

    # 5. 综合评分
    overall_score = calculate_weighted_score([
        (compilation_result.success, 0.3),  # 编译成功权重30%
        (ref_report.intact_rate, 0.3),  # 引用完整权重30%
        (word_count_report.compliance_rate, 0.2),  # 字数合规权重20%
        (style_scores.average, 0.2),  # 写作风格权重20%
    ])

    return QualityReport(...)
```

#### 2.2.4 迭代优化器（`core/iteration_optimizer.py`）

**职责**：根据质量报告进行多轮迭代优化

**核心逻辑**：

```python
async def iterative_optimization(
    new_project: Path,
    initial_plan: MigrationPlan,
    config: Dict,
) -> IterationResult:
    """
    多轮迭代优化
    """
    max_rounds = config["migration"]["max_rounds"]  # 默认5轮
    convergence_threshold = config["migration"]["convergence_threshold"]  # 默认0.05

    quality_history: List[float] = []

    for round_num in range(1, max_rounds + 1):
        logger.info(f"开始第 {round_num} 轮优化...")

        # 1. 质量评估
        quality_report = validate_migration_quality(new_project, ...)
        quality_history.append(quality_report.overall_score)

        # 2. 收敛判断
        if len(quality_history) >= 2:
            improvement = quality_history[-1] - quality_history[-2]
            if improvement < convergence_threshold:
                logger.info(f"收敛检测：改进幅度 {improvement:.3f} < {convergence_threshold}")
                break

        if quality_report.overall_score >= 0.9:
            logger.info(f"质量达标：{quality_report.overall_score:.3f} >= 0.9")
            break

        # 3. 问题诊断
        issues = diagnose_quality_issues(quality_report)

        # 4. 针对性优化
        for issue in issues:
            if issue.type == "reference_error":
                await fix_reference_errors(issue.files)
            elif issue.type == "word_count_mismatch":
                await adjust_word_count(issue.files, issue.target)
            elif issue.type == "poor_writing_style":
                await call_nsfc_writing_skills(issue.files, issue.suggestion)
            # ...

        # 5. LaTeX编译验证
        compilation_result = compile_latex(new_project)
        if not compilation_result.success:
            logger.error(f"编译失败，触发回滚机制")
            restore_snapshot(new_project, backup_root, security)
            break

    return IterationResult(
        final_quality=quality_history[-1],
        rounds_completed=round_num,
        converged=len(quality_history) >= 2 and improvement < convergence_threshold,
    )
```

### 2.3 NSFC写作技能集成

**配置文件调用路径**（config.yaml已配置）：

```yaml
skill_integration:
  available_skills:
    nsfc-writing-core:
      purpose: "统一术语、检查一致性"
      trigger: "每次优化开始前"
      priority: 1

    nsfc-rationale-writer:
      purpose: "补强立项依据"
      trigger: "立项依据内容不足或质量低"
      priority: 2

    nsfc-aims-writer:
      purpose: "补强研究内容与目标"
      trigger: "研究内容章节需要优化"
      priority: 2

    nsfc-innovation-writer:
      purpose: "提炼创新点"
      trigger: "特色与创新章节需要优化"
      priority: 3

    # ... 其他技能
```

**调用逻辑**：

```python
async def call_nsfc_skill(
    skill_name: str,
    target_files: List[str],
    context: Dict,
) -> SkillResult:
    """
    调用NSFC写作技能

    Args:
        skill_name: 技能名称（如 "nsfc-rationale-writer"）
        target_files: 目标文件列表
        context: 上下文信息（章节类型、问题诊断等）

    Returns:
        SkillResult: 技能执行结果
    """
    # 使用 Skill tool 调用
    result = await Skill(
        skill=skill_name,
        args=f"--files {','.join(target_files)} --context {context}"
    )
    return result
```

---

## 三、分步实施计划

### Phase 1: 基础设施搭建（Week 1）

#### Step 1.1: 创建内容优化引擎骨架

**文件**：`core/content_optimizer.py`

**任务**：
- [ ] 创建 `TemplateRequirements` 数据类（存储模板要求）
- [ ] 创建 `ChapterContext` 数据类（存储章节上下文）
- [ ] 创建 `OptimizationResult` 数据类（存储优化结果）
- [ ] 实现 `optimize_chapter_content()` 函数骨架
- [ ] 添加单元测试

**验收标准**：
- 函数签名正确，类型注解完整
- 可以接收输入并返回结构化结果
- 单元测试通过基础用例

#### Step 1.2: 实现引用保护器

**文件**：`core/reference_guard.py`

**任务**：
- [ ] 实现 `protect_references()` - 替换引用为占位符
- [ ] 实现 `restore_references()` - 还原占位符为引用
- [ ] 实现 `validate_reference_preservation()` - 硬编码验证
- [ ] 添加引用保护单元测试（10+测试用例）

**验收标准**：
- 所有测试用例通过（包括边界情况）
- 引用保护覆盖率100%（包括 \ref, \cite, \label）
- 占位符不会与正常文本冲突

#### Step 1.3: 创建质量验证器骨架

**文件**：`core/quality_validator.py`

**任务**：
- [ ] 创建 `QualityReport` 数据类
- [ ] 实现 `validate_migration_quality()` 骨架
- [ ] 集成现有 `reference_validator.py`
- [ ] 集成 LaTeX 编译验证（调用现有编译脚本）

**验收标准**：
- 可以生成完整的质量报告
- 与现有模块无缝集成
- 编译验证可正常执行

#### Step 1.4: 更新迁移器主流程

**文件**：`core/migrator.py`

**任务**：
- [ ] 在 `apply_plan()` 中添加 Step 2 调用（内容优化）
- [ ] 在 `apply_plan()` 中添加 Step 3 调用（质量验证）
- [ ] 在 `apply_plan()` 中添加 Step 4 调用（迭代优化）
- [ ] 更新 `ApplyResult` 数据类，添加质量相关字段
- [ ] 添加配置开关（`enable_ai_optimization`，默认 False）

**验收标准**：
- 四步流程可以正确执行
- 配置开关可以控制是否启用AI优化
- 向后兼容（关闭AI优化时行为与v1.2.0一致）

---

### Phase 2: AI优化核心实现（Week 2）

#### Step 2.1: 实现模板要求解析

**文件**：`core/template_analyzer.py`（新建）

**任务**：
- [ ] 解析新模板的章节结构（extraTex/*.tex）
- [ ] 提取每章节的字数限制（从注释或配置）
- [ ] 识别章节类型（立项依据/研究内容/创新点等）
- [ ] 生成 `TemplateRequirements` 对象

**实现示例**：

```python
def analyze_template_requirements(
    new_project: Path,
    config: Dict,
) -> TemplateRequirements:
    """
    分析新模板要求
    """
    # 从 @config.tex 或注释中提取字数限制
    word_limits = extract_word_limits_from_comments(new_project)

    # 分析章节结构
    chapter_structure = analyze_chapter_structure(new_project)

    # 识别章节类型
    chapter_types = classify_chapters(chapter_structure)

    return TemplateRequirements(
        word_limits=word_limits,
        chapter_structure=chapter_structure,
        chapter_types=chapter_types,
        format_requirements=extract_format_requirements(new_project),
    )
```

#### Step 2.2: 实现AI内容优化调用

**文件**：`core/content_optimizer.py`

**任务**：
- [ ] 构建AI提示词模板（包含引用保护规则、字数要求、风格要求）
- [ ] 实现 AI 调用逻辑（使用 Claude API）
- [ ] 实现字数后处理（超标压缩/不足扩充）
- [ ] 添加重试机制（AI调用失败时）

**提示词模板设计**：

```python
def build_optimization_prompt(
    old_content: str,
    requirements: TemplateRequirements,
    context: ChapterContext,
) -> str:
    """
    构建AI优化提示词
    """
    prompt = f"""
# 任务：优化NSFC申请书章节内容

## 章节信息
- 章节标题：{context.title}
- 章节类型：{context.chapter_type}
- 位置：第{context.chapter_number}章

## 原始内容
```latex
{old_content}
```

## 新模板要求
- 字数限制：{requirements.min_words} - {requirements.max_words} 字
- 格式要求：{requirements.format_description}
- 风格要求：专业PI级NSFC标书写作风格

## 优化规则（必须严格遵守）
1. **引用保护**：绝对禁止修改任何 \\ref{{...}}、\\cite{{...}}、\\label{{...}} 命令
2. **字数控制**：优化后字数必须在 {requirements.min_words} - {requirements.max_words} 范围内
3. **内容保留**：保留所有核心科学观点和论证逻辑
4. **风格提升**：使用学术严谨的专业表达，避免口语化
5. **逻辑连贯**：确保段落间有清晰的逻辑过渡

## 输出要求
- 仅输出优化后的LaTeX内容，不要有任何解释性文字
- 保持原有的LaTeX命令结构（如 \\section, \\subsection）
- 确保所有LaTeX语法正确

请开始优化：
"""
    return prompt
```

#### Step 2.3: 实现字数自适应调整

**文件**：`core/content_optimizer.py`

**任务**：
- [ ] 实现 `compress_content()` - 压缩超标内容
- [ ] 实现 `expand_content()` - 扩充不足内容
- [ ] 实现 `fine_tune_content()` - 微调接近边界的内容
- [ ] 添加字数统计函数（支持中英文混合）

**实现策略**：

```python
def adapt_word_count(
    content: str,
    target_min: int,
    target_max: int,
) -> str:
    """
    字数自适应调整
    """
    current_count = count_chinese_words(content)

    if current_count > target_max * 1.2:
        # 超标20%以上：压缩策略
        return await compress_content(
            content,
            target=target_max,
            strategy="remove_redundancy"  # 删除冗余表达
        )
    elif current_count < target_min * 0.8:
        # 不足80%：扩充策略
        return await expand_content(
            content,
            target=target_min,
            strategy="add_evidence"  # 增加论证细节
        )
    else:
        # 接近目标：微调策略
        return await fine_tune_content(
            content,
            target_range=(target_min, target_max),
        )

def count_chinese_words(text: str) -> int:
    """
    中文字数统计（参考LaTeX字数统计规则）
    """
    # 统计中文字符
    chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
    # 统计英文单词
    english_words = len(re.findall(r'\b[A-Za-z]+\b', text))
    # 中文字符按1字计，英文单词按0.5字计（NSFC惯例）
    return chinese_chars + int(english_words * 0.5)
```

#### Step 2.4: 集成NSFC写作技能

**文件**：`core/skill_integration.py`（新建）

**任务**：
- [ ] 实现 `call_nsfc_skill()` 通用调用函数
- [ ] 实现技能触发条件判断逻辑
- [ ] 实现技能结果解析和应用
- [ ] 添加技能调用日志记录

**实现示例**：

```python
async def trigger_nsfc_skills(
    quality_report: QualityReport,
    new_project: Path,
    config: Dict,
) -> List[SkillResult]:
    """
    根据质量报告触发相应NSFC写作技能
    """
    results = []

    # 遍历技能配置
    for skill_name, skill_config in config["skill_integration"]["available_skills"].items():
        # 判断是否需要触发
        if should_trigger_skill(skill_config, quality_report):
            logger.info(f"触发技能: {skill_name}")

            # 调用技能
            result = await Skill(
                skill=skill_name,
                args=f"--project {new_project} --quality-report {quality_report.to_json()}"
            )

            results.append(result)

    return results

def should_trigger_skill(skill_config: Dict, quality_report: QualityReport) -> bool:
    """
    判断是否需要触发技能
    """
    trigger = skill_config.get("trigger")

    if trigger == "每次优化开始前":
        return True
    elif trigger == "立项依据内容不足或质量低":
        # 检查立项依据章节的质量评分
        rationale_score = quality_report.chapter_scores.get("立项依据", 1.0)
        return rationale_score < 0.7
    # ... 其他触发条件

    return False
```

---

### Phase 3: 质量保证实现（Week 3）

#### Step 3.1: 实现LaTeX编译验证

**文件**：`core/quality_validator.py`

**任务**：
- [ ] 调用现有的 LaTeX 编译脚本（`scripts/compile.sh` 或类似）
- [ ] 解析编译日志，提取错误和警告
- [ ] 验证PDF生成是否成功
- [ ] 添加编译超时控制

**实现示例**：

```python
def compile_latex(
    project_root: Path,
    engine: str = "xelatex",
    max_passes: int = 4,
    timeout: int = 120,
) -> CompilationResult:
    """
    LaTeX编译验证（4步法）
    """
    project_root = project_root.resolve()
    main_tex = project_root / "main.tex"

    if not main_tex.exists():
        raise FileNotFoundError(f"未找到主文件: {main_tex}")

    # 编译序列：xelatex → bibtex → xelatex → xelatex
    pass_sequence = [
        ("xelatex", ["-interaction=nonstopmode"]),
        ("bibtex", []),
        ("xelatex", ["-interaction=nonstopmode"]),
        ("xelatex", ["-interaction=nonstopmode"]),
    ]

    logs: List[str] = []
    errors: List[str] = []
    warnings: List[str] = []

    for pass_num, (cmd, args) in enumerate(pass_sequence, 1):
        logger.info(f"编译第 {pass_num} 步: {cmd}")

        # 执行编译命令
        result = subprocess.run(
            [cmd] + args + [str(main_tex)],
            cwd=project_root,
            capture_output=True,
            text=True,
            timeout=timeout,
        )

        logs.append(result.stdout)

        # 解析错误和警告
        if result.returncode != 0:
            pass_errors = parse_latex_errors(result.stdout)
            errors.extend([f"Pass {pass_num}: {e}" for e in pass_errors])

        pass_warnings = parse_latex_warnings(result.stdout)
        warnings.extend([f"Pass {pass_num}: {w}" for w in pass_warnings])

    # 检查PDF是否生成
    pdf_path = main_tex.with_suffix(".pdf")
    success = pdf_path.exists()

    return CompilationResult(
        success=success,
        errors=errors,
        warnings=warnings,
        pdf_path=str(pdf_path) if success else None,
    )
```

#### Step 3.2: 实现AI写作风格评分

**文件**：`core/quality_validator.py`

**任务**：
- [ ] 实现 `ai_rate_writing_style()` 函数
- [ ] 设计评分提示词（术语/逻辑/论证/风格）
- [ ] 解析AI评分结果
- [ ] 添加评分置信度检查

**评分提示词设计**：

```python
def build_style_rating_prompt(content: str, chapter_type: str) -> str:
    """
    构建写作风格评分提示词
    """
    return f"""
# 任务：评估NSFC申请书章节的写作质量

## 章节类型
{chapter_type}

## 章节内容
```latex
{content[:3000]}  # 限制token数
```

## 评分维度（0-1分）

### 1. 术语一致性（terminology_score）
- 同一概念是否使用统一术语
- 专业术语使用是否准确
- 是否有口语化或不规范表达

### 2. 逻辑连贯性（logic_coherence_score）
- 段落之间是否有清晰的逻辑过渡
- 论证链条是否完整
- 是否有逻辑跳跃或矛盾

### 3. 论证充分性（evidence_quality_score）
- 每个论点是否有充分的证据支持
- 文献引用是否恰当
- 数据或实验证据是否充分

### 4. 专业风格（professional_style_score）
- 是否符合专业PI的写作水平
- 是否体现科研深度和视野
- 是否符合NSFC标书的规范

## 输出格式（JSON）
```json
{{
  "terminology_score": 0.85,
  "logic_coherence_score": 0.75,
  "evidence_quality_score": 0.90,
  "professional_style_score": 0.80,
  "overall_score": 0.825,
  "strengths": ["术语使用准确", "论证充分"],
  "weaknesses": ["段落间过渡不够自然"],
  "suggestions": ["建议在第2段增加过渡句"]
}}
```

请进行评分：
"""
```

#### Step 3.3: 实现质量收敛判断

**文件**：`core/iteration_optimizer.py`

**任务**：
- [ ] 实现 `check_convergence()` 函数
- [ ] 支持多种收敛条件（质量达标/改进微小/无问题）
- [ ] 添加收敛判断日志
- [ ] 实现早退机制

**收敛条件实现**：

```python
def check_convergence(
    quality_history: List[float],
    current_quality: QualityReport,
    thresholds: Dict,
) -> ConvergenceStatus:
    """
    检查是否满足收敛条件
    """
    # 条件1：质量达到阈值（如0.9）
    if current_quality.overall_score >= thresholds.get("min_quality", 0.9):
        return ConvergenceStatus(
            converged=True,
            reason=f"质量达标: {current_quality.overall_score:.3f} >= {thresholds['min_quality']}",
        )

    # 条件2：连续改进微小（如<5%）
    if len(quality_history) >= 2:
        improvement = quality_history[-1] - quality_history[-2]
        if improvement < thresholds.get("min_improvement", 0.05):
            return ConvergenceStatus(
                converged=True,
                reason=f"改进微小: {improvement:.3f} < {thresholds['min_improvement']}",
            )

    # 条件3：无任何质量问题
    if current_quality.issues_count == 0:
        return ConvergenceStatus(
            converged=True,
            reason="无发现任何质量问题",
        )

    return ConvergenceStatus(converged=False, reason="尚未收敛")
```

---

### Phase 4: 集成测试与优化（Week 4）

#### Step 4.1: 端到端集成测试

**任务**：
- [ ] 创建完整测试用例（简单/中等/复杂迁移场景）
- [ ] 测试四步流程的完整执行
- [ ] 测试配置开关功能
- [ ] 测试备份回滚机制
- [ ] 性能测试（运行时间/内存占用）

**测试场景设计**：

```python
# test_e2e_simple.py
def test_simple_one_to_one_migration():
    """
    测试简单一对一迁移（无AI优化）
    """
    old_project = Path("testdata/old_simple")
    new_project = Path("testdata/new_template")

    # 执行迁移
    result = run_migration(
        old_project=old_project,
        new_project=new_project,
        enable_ai_optimization=False,  # 关闭AI优化
    )

    # 验证
    assert result.success
    assert result.applied_count == 3
    assert result.resources["copied_count"] == 5
    assert result.references["passed"]

# test_e2e_ai_optimization.py
def test_ai_optimization_migration():
    """
    测试AI优化迁移（完整四步流程）
    """
    old_project = Path("testdata/old_complex")
    new_project = Path("testdata/new_template")

    # 执行迁移
    result = run_migration(
        old_project=old_project,
        new_project=new_project,
        enable_ai_optimization=True,
        max_rounds=3,
    )

    # 验证
    assert result.success
    assert result.quality_score >= 0.8
    assert result.compilation_success
    assert result.references["passed"]
    assert result.iteration_rounds <= 3
```

#### Step 4.2: 性能优化

**任务**：
- [ ] 分析AI调用的token消耗
- [ ] 优化提示词长度（去除冗余信息）
- [ ] 实现结果缓存机制（避免重复调用）
- [ ] 添加并行处理（多章节同时优化）

**优化策略**：

```python
# 1. 结果缓存
@lru_cache(maxsize=128)
def cached_ai_call(prompt_hash: str) -> str:
    """缓存AI调用结果"""
    return call_ai_api(prompt_hash)

# 2. 并行处理
async def optimize_chapters_parallel(
    chapters: List[Chapter],
    config: Dict,
) -> List[OptimizationResult]:
    """并行优化多个章节"""
    tasks = [
        optimize_chapter_content(chapter, config)
        for chapter in chapters
    ]
    return await asyncio.gather(*tasks)

# 3. 提示词压缩
def compress_prompt(prompt: str) -> str:
    """压缩提示词（去除示例、简化指令）"""
    # 使用更简洁的指令
    # 移除冗余示例
    # 使用更紧凑的格式
    pass
```

#### Step 4.3: 文档更新

**任务**：
- [ ] 更新 SKILL.md（添加AI优化流程说明）
- [ ] 更新 README.md（更新功能特性列表）
- [ ] 更新 config.yaml（添加AI优化相关配置）
- [ ] 更新 CHANGELOG.md（记录v1.3.0变更）

**文档更新清单**：

```markdown
# SKILL.md 更新内容
## 工作流程（更新）
### Step 1: 内容复制与资源迁移（已实现 ✅）
### Step 2: AI智能内容优化（新增 ⭐）
### Step 3: 质量验证与编译（新增 ⭐）
### Step 4: 多轮迭代优化（新增 ⭐）

## 核心参数（更新）
- `enable_ai_optimization`: 是否启用AI优化（默认: false）
- `max_optimization_rounds`: 最大优化轮次（默认: 5）
- `quality_threshold`: 质量达标阈值（默认: 0.9）
```

---

## 四、风险控制

### 4.1 安全风险

| 风险点 | 影响 | 缓解措施 |
|--------|------|----------|
| AI破坏引用关系 | 高 | 硬编码引用保护 + AI提示词约束 + 二次验证 |
| AI生成内容质量不稳定 | 中 | 多轮迭代 + 质量评分 + NSFC技能兜底 |
| LaTeX编译失败 | 高 | 编译前语法检查 + 失败自动回滚 |
| 字数控制失效 | 中 | 后处理硬编码调整 + 多次验证 |
| 资源消耗过大 | 低 | 结果缓存 + 并行处理限制 |

### 4.2 回滚机制

```python
# 在关键步骤失败时自动回滚
try:
    # Step 2: AI优化
    optimized_result = await optimize_content(...)

    # 验证引用完整性
    if not validate_reference_preservation(original, optimized):
        raise ReferenceIntegrityError("引用完整性检查失败")

    # Step 3: 质量验证
    quality_report = validate_quality(...)

    if not quality_report.compilation_success:
        raise CompilationError("LaTeX编译失败")

    # 更新文件
    _atomic_write(target_path, optimized_content)

except (ReferenceIntegrityError, CompilationError) as e:
    logger.error(f"优化失败: {e}")
    # 回滚到Step 1的硬编码复制版本
    restore_snapshot(new_project, backup_root, security)
    # 使用非优化版本
    logger.warning("使用非优化版本继续")
```

### 4.3 人工审核触发条件

以下情况自动触发人工审核：

```python
def should_trigger_manual_review(quality_report: QualityReport) -> bool:
    """
    判断是否需要人工审核
    """
    triggers = [
        quality_report.overall_score < 0.7,  # 质量评分过低
        len(quality_report.undefined_refs) > 3,  # 引用错误过多
        not quality_report.word_count_compliant,  # 字数严重不合规
        quality_report.compilation_errors > 0,  # 编译有错误
        quality_report.professional_style_score < 0.6,  # 专业风格评分低
    ]

    return any(triggers)
```

---

## 五、里程碑与时间线

| 里程碑 | 交付物 | 预计完成时间 |
|--------|--------|--------------|
| M1: 基础设施搭建完成 | content_optimizer.py, reference_guard.py, quality_validator.py | Week 1 |
| M2: AI优化核心实现 | 模板解析、AI调用、字数控制、技能集成 | Week 2 |
| M3: 质量保证实现 | LaTeX验证、风格评分、收敛判断 | Week 3 |
| M4: 集成测试完成 | 测试用例、性能优化、文档更新 | Week 4 |
| **M5: v1.3.0 发布** | 完整四步迁移流程、所有文档更新 | Week 5 |

---

## 六、成功标准

### 6.1 功能完整性

- ✅ 四步迁移流程全部实现
- ✅ AI智能优化写作可用
- ✅ 引用关系100%保护
- ✅ 字数限制自动适配
- ✅ 专业PI风格输出

### 6.2 质量指标

- LaTeX编译成功率 ≥ 95%
- 引用完整性保持率 = 100%
- 质量评分 ≥ 0.85（平均）
- 迭代收敛轮次 ≤ 5轮
- 人工审核触发率 ≤ 20%

### 6.3 性能指标

- 单章节优化时间 ≤ 3分钟（含AI调用）
- 总迁移时间 ≤ 30分钟（典型10章节项目）
- 内存占用 ≤ 2GB
- 缓存命中率 ≥ 30%

---

## 七、后续优化方向（v1.4.0+）

1. **交互式优化**：允许用户在每轮迭代后手动调整优化方向
2. **增量迁移**：支持只迁移变更的部分（而非全量重写）
3. **模板库扩展**：支持更多NSFC模板版本（地区基金、联合基金等）
4. **多语言支持**：支持英文申请书优化
5. **云端部署**：支持远程服务器执行（避免本地资源限制）

---

**变更历史记录**: 变更历史记录在 [CHANGELOG.md](../../CHANGELOG.md)
