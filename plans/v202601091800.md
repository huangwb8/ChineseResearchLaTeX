# nsfc-justification-writer 改良计划

> **创建日期**：2026-01-09
> **当前版本**：v0.3.0
> **目标版本**：v0.4.0

---

## 一、开发度评估总结

### 1.1 已实现能力（v0.3.0）

| 类别 | 功能 | 状态 | 完成度 |
|------|------|------|--------|
| **Tier1 硬编码诊断** | 结构检查（`\subsubsection` 数量/标题） | ✅ | 90% |
| **Tier1 硬编码诊断** | 引用核验（`.bib` key 存在性） | ✅ | 95% |
| **Tier1 硬编码诊断** | 字数统计（CJK 字符计数） | ✅ | 95% |
| **Tier1 硬编码诊断** | 质量规则（禁止短语/命令检测） | ✅ | 85% |
| **安全写入** | 白名单文件控制 + 备份 | ✅ | 95% |
| **版本管理** | diff/回滚功能 | ✅ | 90% |
| **术语一致性** | 基于 `alias_groups` 的跨章节检查 | ✅ | 70% |
| **CLI 工具** | diagnose/wordcount/refs/terms/coach/review | ✅ | 85% |
| **HTML 报告** | 可视化诊断报告 | ✅ | 80% |
| **信息表** | init 模板生成 + 交互式收集 | ⚠️ | 60% |
| **AI 集成** | Tier2 语义分析 | ❌ | 20% |
| **AI 集成** | writing_coach 智能建议 | ⚠️ | 40% |
| **示例推荐** | 基于关键词匹配 examples/ | ⚠️ | 50% |

**总体完成度**：约 **75%**

### 1.2 测试覆盖情况

- **文件数量**：29 个 Python 文件
- **测试文件**：4 个 (`test_latex_parser.py`, `test_reference_validator.py`, `test_wordcount_and_diagnostic.py`, `e2e/test_cli_flow.py`)
- **测试通过**：8 个测试全部通过
- **覆盖率评估**：约 40-50%（缺少核心模块单元测试和边界情况测试）

---

## 二、缺陷清单（按优先级排序）

### 2.1 高优先级缺陷

#### 缺陷 #1：AI 集成功能未完善

**表现**：
- [prompts/tier2_diagnostic.txt](skills/nsfc-justification-writer/prompts/tier2_diagnostic.txt) 为空，导致 `--tier2` 功能实际上不工作
- [prompts/writing_coach.txt](skills/nsfc-justification-writer/prompts/writing_coach.txt) 过于简略（仅 31 行），缺少具体指导模板
- [core/ai_integration.py](skills/nsfc-justification-writer/core/ai_integration.py) 的 `process_request` 可能缺少实际 API 调用逻辑

**影响**：用户启用 `--tier2` 或依赖 AI 建议时，体验降级为硬编码 fallback

**建议修复**：
1. 完善 `tier2_diagnostic.txt` prompt，包含：
   - 逻辑闭环检查（价值→不足→假说→切入点）
   - 术语一致性语义检查（超越别名匹配）
   - 可核验性检查（绝对表述识别）
   - 建议生成（按优先级排序）
2. 扩展 `writing_coach.txt`，添加各阶段的具体输出模板
3. 补充 `ai_integration.py` 的实际 API 调用代码（或说明依赖环境变量）

---

#### 缺陷 #2：配置与文档不一致

**表现**：
- [SKILL.md:60-64](skills/nsfc-justification-writer/SKILL.md#L60-L64) 描述了"4 段闭环"叙事结构，但未明确对应到 `\subsubsection` 标题
- [config.yaml:60-64](skills/nsfc-justification-writer/config.yaml#L60-L64) 的 `expected_subsubsections` 为 `["研究背景", "国内外研究现状", "现有研究的局限性", "研究切入点"]`，与 SKILL.md 描述的"价值与必要性/现状与不足/科学问题/核心假说/本项目切入点"不完全对应
- 模板与实际文件名可能不匹配

**影响**：用户对预期输出结构产生混淆

**建议修复**：
1. 统一 SKILL.md、config.yaml、templates/structure_template.tex 的结构描述
2. 在 SKILL.md 中添加"推荐 `\subsubsection` 标题与内容映射表"
3. 更新 `expected_subsubsections` 为更清晰的标题列表

---

#### 缺陷 #3：示例推荐功能不完善

**表现**：
- [core/example_matcher.py](skills/nsfc-justification-writer/core/example_matcher.py) 的匹配逻辑过于简单（基于关键词模糊匹配）
- [examples/](skills/nsfc-justification-writer/examples/) 目录下只有 `medical/example_001.tex` 和 `engineering/example_001.tex`，示例数量不足
- 缺少示例与特定研究领域的关联元数据

**影响**：`examples` 命令推荐结果可能不准确

**建议修复**：
1. 为每个示例添加 `metadata.yaml`（包含领域/关键词/难度标签）
2. 改进匹配算法，结合关键词 + 领域 + 字数综合评分
3. 新增 3-5 个跨领域示例（信息学/材料/社科等）

---

### 2.2 中优先级缺陷

#### 缺陷 #4：测试覆盖不足

**表现**：
- 缺少对 [core/diagnostic.py](skills/nsfc-justification-writer/core/diagnostic.py) 的单元测试
- 缺少对 [core/writing_coach.py](skills/nsfc-justification-writer/core/writing_coach.py) 的单元测试
- 缺少边界情况测试（如空文件/超大文件/编码错误）
- E2E 测试仅验证 CLI 调用，未验证写入后的 LaTeX 文件正确性

**影响**：代码质量保障不足，潜在 bug 可能未被发现

**建议修复**：
1. 为每个 core 模块添加单元测试（目标覆盖率 80%+）
2. 添加集成测试：模拟完整写作流程（骨架→段落→修订→验收）
3. 添加边界测试：空输入/超长文本/非法字符

---

#### 缺陷 #5：信息表交互式收集不完善

**表现**：
- [core/info_form.py](skills/nsfc-justification-writer/core/info_form.py) 的 `interactive_collect_info_form()` 验证逻辑不完整
- 不支持从已有信息表更新（只能重新填写）
- 缺少对必填字段的强制检查

**影响**：用户可能生成不完整的信息表

**建议修复**：
1. 添加必填字段验证（【必填】标记的字段不能为空）
2. 支持增量更新模式（`--update` 参数）
3. 添加输出格式选择（Markdown/YAML/JSON）

---

#### 缺陷 #6：与其他 Skill 集成不足

**表现**：
- 与 `nsfc-bib-manager` 的集成是单向的（仅检测缺失，不自动触发核验）
- 与 `nsfc-aims-writer`、`nsfc-methods-feasibility-writer` 等缺少术语同步机制

**影响**：用户需要手动在多个 Skill 间同步信息

**建议修复**：
1. 在 `refs` 命令输出中添加可直接复制给 `nsfc-bib-manager` 的提示词
2. 在 `terms` 命令输出中添加"建议同步到其他章节"的提示
3. 考虑未来添加 `--sync` 参数自动调用相关 Skill

---

### 2.3 低优先级缺陷

#### 缺陷 #7：HTML 报告缺少交互性

**表现**：
- [templates/html/report_template.html](skills/nsfc-justification-writer/templates/html/report_template.html) 生成的报告是静态的
- 无法点击问题直接跳转到源文件位置

**建议修复**：添加"复制行号"或"打开文件"按钮（需要编辑器集成支持）

---

#### 缺陷 #8：配置管理不够灵活

**表现**：
- [config.yaml:114-119](skills/nsfc-justification-writer/config.yaml#L114-L119) 的 `alias_groups` 是硬编码的
- 缺少针对不同学科的预设配置

**建议修复**：
1. 支持从 `~/.config/nsfc-justification-writer/override.yaml` 加载用户配置
2. 提供医学/工学/理学等学科的预设 `alias_groups`

---

#### 缺陷 #9：LaTeX 模板验证不完整

**表现**：
- `apply-section` 写入时未验证新正文是否包含破坏模板的命令（如 `\section`）
- 虽然有 `avoid_commands` 检测，但检测后只是警告，不阻止写入

**建议修复**：
1. 在写入前强制检查 `avoid_commands`，发现则拒绝写入
2. 添加更详细的 LaTeX 语法检查（如括号匹配）

---

#### 缺陷 #10：缺少文档与安装指南

**表现**：
- [README.md](skills/nsfc-justification-writer/README.md) 可能不够详细（需确认）
- 缺少"首次使用指南"和"常见问题"

**建议修复**：
1. 补充完整的 README（安装/快速开始/命令参考/FAQ）
2. 添加 `docs/` 目录放置详细教程

---

## 三、改良计划（按优先级执行）

### 阶段 1：修复高优先级缺陷（v0.3.1 → v0.3.2）

#### 1.1 完善 AI 集成（缺陷 #1）

1. **编写 `tier2_diagnostic.txt` prompt**
   - 定义 Tier2 诊断的 4 个维度：逻辑闭环/术语一致性/可核验性/建议生成
   - 为每个维度设计输出格式（JSON 或结构化文本）
   - 添加约束条件（不破坏结构、优先可核验性）

2. **扩展 `writing_coach.txt`**
   - 为每个阶段（skeleton/draft/revise/polish/final）设计详细输出模板
   - 添加"本轮只做三件事"的具体任务描述模板
   - 添加"可复制提示词"的标准格式

3. **验证 `ai_integration.py`**
   - 确认 `process_request` 方法是否正确调用 AI API
   - 添加 fallback 机制的日志输出（方便调试）

#### 1.2 统一配置与文档（缺陷 #2）

1. **创建"推荐标题与内容映射表"**
   | `\subsubsection` 标题 | 对应内容段落 | 核心要素 |
   |------------------------|--------------|----------|
   | 研究背景 | 价值与必要性 | 痛点→影响范围→为何现在做 |
   | 国内外研究现状 | 主流路线与不足 | 代表性工作→2-4条不足 |
   | 现有研究的局限性 | 核心假说与科学问题 | 假说（可证伪）→关键问题 |
   | 研究切入点 | 本项目差异化切口 | 切入点→过渡到研究内容 |

2. **更新 config.yaml 的 `expected_subsubsections`**
   - 与推荐标题列表一致
   - 添加 `strict_title_match: false` 选项（允许用户自定义标题）

3. **在 SKILL.md 中添加映射表说明**

#### 1.3 改进示例推荐（缺陷 #3）

1. **为现有示例添加 `metadata.yaml`**
   ```yaml
   category: medical
   keywords: [深度学习, 医学影像, 肺结节检测]
   difficulty: intermediate
   word_count: 3800
   structure_version: v2026
   ```

2. **改进 [core/example_matcher.py](skills/nsfc-justification-writer/core/example_matcher.py)**
   - 实现关键词匹配 + 领域匹配 + 字数相似度的综合评分
   - 添加"按难度排序"选项

3. **新增 2-3 个跨领域示例**

---

### 阶段 2：完善核心功能（v0.3.3 → v0.3.4）

#### 2.1 补充测试覆盖（缺陷 #4）

1. **为 core 模块添加单元测试**
   - `test_diagnostic.py`：测试 Tier1/Tier2 诊断逻辑
   - `test_writing_coach.py`：测试阶段判断和建议生成
   - `test_example_matcher.py`：测试示例匹配算法

2. **添加集成测试**
   - `test_full_workflow.py`：模拟完整写作流程
   - 验证从骨架到验收的各阶段输出

3. **添加边界测试**
   - 空文件/超大文件/非法字符/编码错误

#### 2.2 改进信息表收集（缺陷 #5）

1. **添加必填字段验证**
   - 检测【必填】字段是否为空
   - 给出具体缺失字段列表

2. **支持增量更新**
   - `init --update <existing_file>` 命令
   - 保留已有答案，仅询问缺失或需修改的字段

3. **多格式输出**
   - `--format yaml|json|markdown` 参数

#### 2.3 加强 Skill 集成（缺陷 #6）

1. **`refs` 命令输出优化**
   - 添加"可直接复制给 nsfc-bib-manager 的提示词"段落

2. **`terms` 命令输出优化**
   - 添加"建议同步到以下章节"的列表

3. **未来扩展**
   - 考虑 `--sync` 参数（调用其他 Skill）

---

### 阶段 3：优化用户体验（v0.3.5 → v0.4.0）

#### 3.1 改进 HTML 报告（缺陷 #7）

1. **添加交互功能**
   - 点击问题高亮对应行
   - "复制到剪贴板"按钮

2. **优化 UI 设计**
   - 更清晰的配色
   - 响应式布局

#### 3.2 灵活化配置（缺陷 #8）

1. **支持用户配置覆盖**
   - 从 `~/.config/nsfc-justification-writer/override.yaml` 加载
   - 文档说明如何自定义 `alias_groups`

2. **学科预设**
   - 添加 `config/presets/medical.yaml` 等
   - `--preset medical` 参数快速加载

#### 3.3 加强 LaTeX 验证（缺陷 #9）

1. **写入前强制检查**
   - 发现 `avoid_commands` 则拒绝写入（可 `--force` 绕过）

2. **括号匹配检查**
   - 检测 `{}`、`[]`、`$$` 是否匹配

#### 3.4 完善文档（缺陷 #10）

1. **扩展 README.md**
   - 安装说明
   - 快速开始（5 分钟教程）
   - 命令参考
   - FAQ

2. **添加 docs/ 目录**
   - `tutorial.md`：完整写作流程教程
   - `architecture.md`：架构说明
   - `contributing.md`：贡献指南

---

## 四、实施注意事项

1. **保持向后兼容**：配置文件格式和 CLI 接口不应 breaking change
2. **测试驱动**：每修复一个缺陷，先添加测试，再修改代码
3. **文档同步**：代码修改后同步更新 SKILL.md 和 README.md
4. **变更记录**：所有修改记录在根级 `CHANGELOG.md`（不在各文件内维护版本历史）
5. **AI 功能可选**：确保没有 AI 也能使用基础功能（Tier1 硬编码能力）

---

## 五、验收标准

改良完成后，应满足：

1. ✅ `--tier2` 功能能正常工作（输出有意义的 AI 建议）
2. ✅ `coach` 命令能给出具体的"三件事"提示
3. ✅ 示例推荐准确率 > 80%
4. ✅ 测试覆盖率 > 80%
5. ✅ 信息表必填字段验证生效
6. ✅ 配置与文档完全一致
7. ✅ 与其他 Skill 的集成提示清晰

---

**变更历史记录在 [CHANGELOG.md](../CHANGELOG.md)**
