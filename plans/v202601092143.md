# nsfc-justification-writer 硬编码 vs AI 智能规划分析

**创建日期**：2026-01-09
**评估版本**：`skills/nsfc-justification-writer` v0.6.1
**分析范围**：核心模块（`core/`）、配置（`config.yaml`）、提示词（`prompts/`）

---

## 一、硬编码部分

### 1. 结构规则（`hard_rules.py` + `config.yaml`）

| 项目 | 硬编码内容 | 文件位置 |
|------|-----------|---------|
| **预期小标题** | `["研究背景", "国内外研究现状", "现有研究的局限性", "研究切入点"]` | `config.yaml` L62-L66 |
| **最小小节数** | `min_subsubsection_count: 4` | `config.yaml` L70 |
| **严格标题匹配** | `strict_title_match: true` | `config.yaml` L67 |
| **最小相似度阈值** | `min_title_similarity: 0.6` | `config.yaml` L69 |

### 2. 质量规则（`hard_rules.py`）

| 项目 | 硬编码内容 | 文件位置 |
|------|-----------|---------|
| **禁止表述** | `["国际领先", "国内首次", "世界领先", "填补空白"]` | `config.yaml` L103-L107 |
| **避免命令** | `["\\section", "\\subsection", "\\input", "\\include"]` | `config.yaml` L108-L112 |

### 3. 安全写入策略（`security.py`）

| 项目 | 硬编码内容 | 文件位置 |
|------|-----------|---------|
| **白名单文件** | `["extraTex/1.1.立项依据.tex"]` | `config.yaml` L73-L74 |
| **黑名单文件** | `["main.tex", "extraTex/@config.tex"]` | `config.yaml` L75-L77 |
| **禁止glob模式** | `["**/*.cls", "**/*.sty"]` | `config.yaml` L78-L80 |

### 4. 字数统计（`wordcount.py` + `config.yaml`）

| 项目 | 硬编码内容 | 文件位置 |
|------|-----------|---------|
| **目标字数** | `target: 4000` | `config.yaml` L115 |
| **容差范围** | `tolerance: 200` | `config.yaml` L116 |
| **统计模式** | `mode: "cjk_only"` 或 `"cjk_strip_commands"` | `config.yaml` L119 |

### 5. 术语一致性维度（`config.yaml` + `term_consistency.py`）

```yaml
# config.yaml L129-L135
dimensions:
  研究对象:
    研究对象: ["患者", "病例", "受试者", "样本"]
  指标:
    准确率: ["准确率", "精确度"]
  术语:
    深度学习: ["深度学习", "DL"]
```

### 6. LaTeX 解析规则（`latex_parser.py`）

| 项目 | 硬编码内容 | 文件位置 |
|------|-----------|---------|
| **小节命令正则** | `r"\\subsubsection\*?"` | `latex_parser.py` L14 |
| **注释检测逻辑** | 转义计数 + `verb/lstinline` 跳过 | `latex_parser.py` L57-L103 |
| **括号匹配算法** | 支持嵌套的平衡括号解析 | `latex_parser.py` L143-L159 |

### 7. 示例关键词匹配（`example_matcher.py`）

```python
# example_matcher.py L71-L86
_category_boost()  # 硬编码的领域-关键词映射
# medical: ["临床", "医学", "医疗", "患者", ...]
# engineering: ["算法", "工程", "系统", "部署", ...]
# cs: ["计算机", "软件", "网络", "安全", ...]
```

### 8. 写作阶段推断（`writing_coach.py`）

```python
# writing_coach.py L30-L42
def _infer_stage(*, tex_text: str, tier1: Dict[str, Any], word_target: int, tol: int) -> WritingStage:
    if not tex_text.strip():
        return "skeleton"
    if not bool(tier1.get("structure_ok")):
        return "skeleton"
    wc = int(tier1.get("word_count", 0))
    if wc < max(int(word_target * 0.4), 600):
        return "draft"
    if not bool(tier1.get("citation_ok")) or tier1.get("forbidden_phrases_hits") or tier1.get("avoid_commands_hits"):
        return "revise"
    if abs(wc - word_target) > tol:
        return "polish"
    return "final"
```

---

## 二、AI 智能规划部分

### 1. 意图解析（`intent_parser.py` + `prompts/intent_parse.txt`）

| AI 任务 | 描述 | 文件位置 |
|---------|------|---------|
| **解析用户指令** | 将自然语言指令解析为 `action/target/focus/constraints` | `intent_parser.py` L22-L42 |
| **Fallback** | 返回 `{"action": null, ...}` | `intent_parser.py` L29-L30 |

### 2. Tier2 语义诊断（`hybrid_coordinator.py` + `prompts/tier2_diagnostic.txt`）

| AI 任务 | 描述 | 文件位置 |
|---------|------|---------|
| **逻辑连贯性检查** | 识别逻辑跳跃、论证不足 | `prompts/tier2_diagnostic.txt` L27-L42 |
| **术语/缩写一致性问题** | 语义层面的同义词/缩写混用 | 同上 |
| **证据不足识别** | 标记不可量化/不可验证陈述 | 同上 |
| **修改建议生成** | 给出 3-6 条可执行建议 | 同上 |

### 3. 写作教练（`writing_coach.py` + `prompts/writing_coach.txt`）

| AI 任务 | 描述 | 文件位置 |
|---------|------|---------|
| **阶段判断** | 基于当前文本状态判断写作阶段 | `prompts/writing_coach.txt` L72-L102 |
| **三轮任务规划** | 每轮只做三件事 + 需要用户补充的问题 | 同上 |
| **可复制提示词生成** | 输出让 AI 助手生成/修改某小节正文的提示词 | 同上 |

### 4. 评审建议生成（`review_advice.py` + `prompts/review_suggestions.txt`）

| AI 任务 | 描述 | 文件位置 |
|---------|------|---------|
| **评审人视角质疑** | 基于 DoD + Tier1 生成 8-12 个评审人可能会问的问题 | `prompts/review_suggestions.txt` L45-L69 |
| **可执行修改建议** | 对应的 8-12 条可执行修改建议 | 同上 |

### 5. 术语一致性 AI 检查（`term_consistency.py: TermConsistencyAI`）

| AI 任务 | 描述 | 文件位置 |
|---------|------|---------|
| **语义术语一致性** | 识别隐含的同义词/缩写混用（非硬编码别名组） | `term_consistency.py` L175-L233 |
| **输出格式** | `{"issues": [...], "suggestions": [...]}` | 同上 |

### 6. 示例推荐（`example_matcher.py: ExampleRecommenderAI`）

| AI 任务 | 描述 | 文件位置 |
|---------|------|---------|
| **语义匹配推荐** | 基于用户主题/方向，从 `examples/` 中进行语义匹配 | `example_matcher.py` L151-L237 |
| **推荐理由生成** | 输出每个推荐示例的理由 | 同上 |

### 7. 标题模糊匹配（`latex_parser.py: match_title_via_ai`）

| AI 任务 | 描述 | 文件位置 |
|---------|------|---------|
| **语义标题匹配** | 当 `strict_title_match=false` 时，AI 从候选标题中选择最匹配的一个 | `latex_parser.py` L275-L311 |

---

## 三、混合策略（硬编码 + AI Fallback）

| 功能 | 主策略（硬编码） | AI 增强 | 文件位置 |
|------|-----------------|---------|---------|
| **示例推荐** | 关键词/类别启发式匹配 (`recommend_examples`) | AI 语义匹配 + 推荐理由 (`ExampleRecommenderAI`) | `example_matcher.py` L105-L277 |
| **术语一致性** | 硬编码别名组矩阵 (`build_term_matrices`) | AI 语义分析 (`TermConsistencyAI`) | `term_consistency.py` L67-L293 |
| **标题匹配** | 严格字符串匹配 / 相似度阈值 (`find_subsubsection_hybrid`) | AI 语义匹配 (`match_title_via_ai`) | `latex_parser.py` L314-L351 |
| **写作教练** | 硬编码阶段推断 + 固定问题清单 (`_fallback_markdown`) | AI 生成阶段判断 + 动态问题 + 可复制提示词 | `writing_coach.py` L86-L218 |
| **评审建议** | 基于 DoD + Tier1 的固定问题模板 (`_fallback_review_markdown`) | AI 生成评审人视角质疑 + 修改建议 | `review_advice.py` L23-L106 |

---

## 四、架构设计原则

该 skill 采用 **"硬编码为主，AI 为辅"** 的设计：

1. **硬编码保证可复现性**：结构/引用/字数/禁用表述等基础诊断完全硬编码
2. **AI 负责语义理解**：逻辑连贯性、术语一致性、写作建议等需要语义理解的任务
3. **所有 AI 调用都有 Fallback**：AI 不可用时自动回退到硬编码能力
4. **Prompt 可配置化**：`config.yaml` 的 `prompts.*` 支持文件路径或直接多行文本

### 核心设计模式

```python
# ai_integration.py - 统一的 AI 调用接口
async def process_request(
    self,
    *,
    task: str,
    prompt: str,
    fallback: Callable[[], Any],  # Fallback 是必需的
    output_format: str = "json",
    cache_dir: Optional[Path] = None,
    fresh: bool = False,
) -> Any:
    # AI 不可用时自动调用 fallback()
```

---

## 五、关键代码引用

| 模块 | 文件路径 |
|------|---------|
| **架构说明** | `docs/architecture.md` |
| **硬编码规则** | `core/hard_rules.py` |
| **AI 集成层** | `core/ai_integration.py` |
| **协同编排** | `core/hybrid_coordinator.py` |
| **LaTeX 解析** | `core/latex_parser.py` |
| **诊断** | `core/diagnostic.py` |
| **写作教练** | `core/writing_coach.py` |
| **评审建议** | `core/review_advice.py` |
| **术语一致性** | `core/term_consistency.py` |
| **示例匹配** | `core/example_matcher.py` |
| **安全策略** | `core/security.py` |
| **配置加载** | `core/config_loader.py` |
| **CLI 入口** | `scripts/run.py` |

---

## 六、可扩展点

| 扩展点 | 说明 |
|--------|------|
| **学科预设** | 在 `config/presets/` 增加 `<preset>.yaml`，主要覆盖 `terminology.alias_groups` |
| **示例库** | 在 `examples/<category>/` 增加 `.tex` 与 `*.metadata.yaml`（keywords/description） |
| **质量规则** | 在 `config.yaml` 的 `quality.forbidden_phrases/avoid_commands` 里增补规则 |
| **Prompt 模板** | 在 `prompts/` 目录新增或覆盖 `.txt` 文件，或在 `config.yaml` 直接写多行 prompt |

---

## 七、优化建议

### 1. 结构规则：从"硬编码标题"转向"内容维度覆盖"

#### 现状问题

当前 `structure.expected_subsubsections` 硬编码了 4 个标题：

```yaml
# config.yaml L62-L66
structure:
  expected_subsubsections:
    - 研究背景
    - 国内外研究现状
    - 现有研究的局限性
    - 研究切入点
  strict_title_match: true
```

**问题**：
- 用户可能使用不同的标题用词（如"选题意义""文献综述""研究空白""创新点"等）
- 严格匹配会误报"结构缺失"
- 标题形式不重要，重要的是**内容维度是否完整**

#### 改进方向

**从"检查标题"转向"检查内容维度"**：

| 内容维度 | 对应叙事要素 | 检查方式（AI） |
|---------|-------------|--------------|
| 价值与必要性 | 痛点→影响范围/成本→为何现在必须做 | 检测是否有"问题/需求/必要性"相关表述 |
| 现状与不足 | 主流路线→代表性工作→2–4条不足 | 检测是否有"现状/现有工作/不足/瓶颈"相关表述 |
| 科学问题/假说 | 可证伪假说→关键科学问题→验证维度 | 检测是否有"假说/科学问题/假设"相关表述 |
| 项目切入点 | 差异化切口→可交付/指标→承上启下 | 检测是否有"本项目/我们/拟/将"相关表述 |

#### 实施建议

1. **保留硬编码作为"推荐模板"**（`SKILL.md` L72-L82 的映射表）
2. **将 `structure.strict_title_match` 默认改为 `false`**
3. **新增 AI 维度覆盖检查**（Tier2 扩展）：

```python
# 新增：core/dimension_coverage.py
class DimensionCoverageAI:
    """
    AI 主导的内容维度覆盖检查。

    说明：
    - 不依赖具体标题用词，而是基于内容语义判断 4 个维度是否覆盖
    - 返回每个维度的覆盖度（高/中/低）+ 缺失部分提示
    """

    async def check(self, *, tex_text: str) -> Dict[str, Any]:
        prompt = """
        请分析以下立项依据文本是否覆盖了 4 个必要维度（不依赖标题）：
        1) 价值与必要性：说明为什么要做、痛点是什么
        2) 现状与不足：现有工作及其局限性
        3) 科学问题/假说：核心假说与关键科学问题
        4) 项目切入点：本项目相对现有工作的差异化切口

        返回 JSON：
        {
          "dimensions": {
            "价值与必要性": {"covered": true, "confidence": 0.95, "evidence": "..."},
            "现状与不足": {"covered": true, "confidence": 0.88, "evidence": "..."},
            ...
          },
          "missing_dimensions": ["科学问题/假说"],
          "suggestions": ["建议补充核心假说..."]
        }
        """
```

4. **诊断输出调整**：

```markdown
# 原来（硬编码标题匹配）
- ❌ 结构缺失：subsubsection=3，缺少：研究切入点

# 改进后（维度覆盖检查）
- ⚠️ 内容维度覆盖度：3/4
  - ✅ 价值与必要性（高置信度）
  - ✅ 现状与不足（中置信度）
  - ✅ 科学问题/假说（中置信度）
  - ❌ 项目切入点（未检测到）：建议补充"本项目相对现有工作的差异化切口"
```

#### 配置调整建议

```yaml
# config.yaml
structure:
  # 保留推荐模板（用于 coach 模式建议用户）
  recommended_subsubsections:
    - 研究背景
    - 国内外研究现状
    - 现有研究的局限性
    - 研究切入点

  # 改为 false：不强制标题匹配，仅检查数量
  strict_title_match: false

  # 新增：启用 AI 维度覆盖检查
  enable_dimension_coverage_check: true

  # 最小小节数（仍保留，作为兜底检查）
  min_subsubsection_count: 4
```

#### 核心原则

> **标题是形式，内容是本质**。用户用什么样的标题不重要，重要的是确保立项依据覆盖了 4 个核心维度的内容。AI 应该智能识别内容维度，而不是机械地匹配标题字符串。

---

### 2. 质量规则：从"硬编码禁词表"转向"AI 语义判断"

#### 现状问题

当前 `quality.forbidden_phrases` 硬编码了禁用表述：

```yaml
# config.yaml L103-L107
quality:
  forbidden_phrases:
    - 国际领先
    - 国内首次
    - 世界领先
    - 填补空白
```

**问题**：
- 用户可能用各种同义词变体（"国际一流""国内首创""世界级水平""开创性"等）
- 穷尽同义词是不可能的
- 核心目标是避免"吹牛式表述"，而不是禁用特定词语
- 硬编码匹配会让用户觉得"在玩文字游戏"

#### 改进方向

**从"禁词匹配"转向"吹牛表述识别"**：

| 问题类型 | 特征（AI 检测） | 示例（不限于此） |
|---------|---------------|-----------------|
| **绝对化表述** | 无对照的"最/首/唯一/领先/首创" | "国际领先""国内首创""世界一流""首个""唯一" |
| **填补空白式** | "填补空白""开创性""突破性"无具体指标 | "填补了...空白""具有开创性意义""重大突破" |
| **无依据夸大** | "重大""重要""关键"无数据/对比支撑 | "具有重大意义""具有重要价值""关键技术" |
| **自我定性** | 用绝对形容词自我评价 | "卓越""杰出""优秀""顶尖"（无第三方评价引用） |

#### 实施建议

1. **保留硬编码作为"高风险示例"**（用于提示和警告）

```yaml
# config.yaml
quality:
  # 保留作为"高风险示例"（用于提示用户）
  high_risk_examples:
    - 国际领先
    - 国内首次
    - 世界领先
    - 填补空白

  # 新增：启用 AI 语义判断
  enable_ai_judgment: true
```

2. **新增 AI 吹牛表述识别**：

```python
# 新增：core/boastful_expression_checker.py
class BoastfulExpressionAI:
    """
    AI 主导的"吹牛表述"识别。

    说明：
    - 不依赖禁词表，而是基于语义判断是否"会引起评审不适"
    - 区分"有数据支撑的结论"和"无依据的自我夸大"
    - 返回具体的"问题表述 + 修改建议"
    """

    async def check(self, *, tex_text: str) -> Dict[str, Any]:
        prompt = """
        请分析以下立项依据文本，识别"可能引起评审专家不适的表述"。

        评审专家通常反感的表述类型：
        1) 绝对化表述：无对照的"最/首/唯一/领先/首创"
        2) 填补空白式："填补空白""开创性"无具体指标
        3) 无依据夸大："重大/重要/关键"无数据/对比支撑
        4) 自我定性：用绝对形容词自我评价（无第三方引用）

        请注意区分：
        - 有数据/引用支撑的结论是 OK 的（如"相比 X 方法提升 30%""引用自 Y 期刊"）
        - 无依据的自我夸大需要标记

        返回 JSON：
        {
          "issues": [
            {
              "category": "绝对化表述/填补空白/无依据夸大/自我定性",
              "text": "原文片段（不超过 50 字）",
              "reason": "为何会引起评审不适",
              "suggestion": "如何改为可验证/可对照的表述"
            }
          ],
          "summary": {
            "total_issues": 3,
            "by_category": {"绝对化表述": 2, "无依据夸大": 1}
          }
        }
        """
```

3. **诊断输出调整**：

```markdown
# 原来（硬编码禁词匹配）
- ⚠️ 不可核验表述：国际领先、填补空白

# 改进后（AI 语义判断）
- ⚠️ 发现 3 处"可能引起评审不适的表述"：
  1. [绝对化表述] "本研究达到国际领先水平"
     - 原因：无第三方引用或对比数据支撑
     - 建议：改为"在 XXX 指标上相比当前主流方法提升 XX%"
  2. [填补空白] "填补了国内该领域研究空白"
     - 原因：未说明具体空白是什么、有何依据
     - 建议：改为"针对 XXX 场景下的 YYY 问题，目前尚无成熟解决方案"
  3. [无依据夸大] "具有重要的科学意义和应用价值"
     - 原因：未说明具体意义是什么、如何量化
     - 建议：改为"有望降低 XXX 成本 XX%/提升 XXX 效率 XX%"
```

4. **质量闸门集成**：

```python
# quality_gate.py 增强
class QualityGateAI:
    async def check_new_body_quality(
        self,
        *,
        new_body: str,
        config: Dict[str, Any],
        ai: AIIntegration,
    ) -> QualityGateResult:
        """写入前质量闸门（AI 增强版）"""

        # 保留硬编码作为兜底（快速检查）
        rule = load_quality_rule(config)
        t = strip_comments(new_body or "")
        forbidden_hits = [p for p in rule.high_risk_examples if p and (p in t)]

        # AI 语义判断（深度检查）
        if config.get("quality", {}).get("enable_ai_judgment", True):
            boastful_ai = BoastfulExpressionAI(ai)
            ai_result = await boastful_ai.check(tex_text=new_body)
            # 合并结果...
```

#### 配置调整建议

```yaml
# config.yaml
quality:
  # 保留作为"高风险示例"（用于快速提示）
  high_risk_examples:
    - 国际领先
    - 国内首次
    - 世界领先
    - 填补空白

  # 改为 false：硬编码禁词不阻断，仅警告
  strict_mode: false

  # 新增：启用 AI 语义判断
  enable_ai_judgment: true
  ai_judgment_mode: "semantic"  # semantic | keyword（兜底）

  avoid_commands:  # 保留（LaTeX 命令不需要 AI 判断）
    - "\\section"
    - "\\subsection"
    - "\\input"
    - "\\include"
```

#### 核心原则

> **禁词是治标，语义判断是治本**。用户不会用完全相同的词语，但"吹牛式表述"的语义特征是稳定的。AI 应该识别"无依据的自我夸大"，而不是机械地禁用特定词语。

#### 与结构规则改进的协同

两个改进方向的核心思想一致：

| 改进项 | 从 | 到 |
|--------|-----|-----|
| **结构规则** | 硬编码 4 个标题，严格匹配 | AI 语义分析 4 个内容维度是否覆盖 |
| **质量规则** | 硬编码禁词表，字符串匹配 | AI 语义识别"吹牛式表述" |

两者都是从"机械匹配"转向"语义理解"，让 AI 真正发挥智能判断的优势。

---

### 3. 字数规则：从"固定默认值"转向"用户意图优先"

#### 现状问题

当前 `word_count.target` 硬编码了默认值：

```yaml
# config.yaml L115
word_count:
  target: 4000
  tolerance: 200
```

**问题**：
- `4000` 字仅是示例值（`references/info_form.md` 明确说明"例如目标 4000 字"），无官方依据
- 用户在 Prompt 中明确指定"写 3000 字"时，系统仍按 4000 字判断阶段和状态
- 不同学科/不同类型项目的字数要求差异很大
- 核心问题是：**配置默认值 vs 用户意图的优先级不明确**

#### 改进方向

**从"固定默认值"转向"用户意图优先"**：

| 优先级 | 来源 | 说明 |
|--------|------|------|
| **P0（最高）** | 用户在 Prompt 中明确指定的字数 | "写 3000 字""控制在 2500-3000 字"等 |
| **P1** | 信息表 (`info_form.md`) 中的字数限制 | 用户在信息表中填写的目标字数 |
| **P2** | 项目/学科预设 (`config/presets/*.yaml`) | 不同学科的默认字数要求 |
| **P3（最低）** | 全局默认值 (`config.yaml`) | 仅作为兜底默认值 |

#### 实施建议

1. **增强意图解析，识别用户字数需求**：

```python
# core/intent_parser.py 增强
@dataclass(frozen=True)
class ParsedIntent:
    action: Optional[str]
    target: Optional[str]
    focus: Optional[str]
    constraints: Optional[str]
    reason: Optional[str] = None

    # 新增字段
    word_count_target: Optional[int] = None  # 用户指定的字数目标
    word_count_range: Optional[tuple[int, int]] = None  # 用户指定的字数范围

async def parse_intent(
    *,
    instruction: str,
    ai: AIIntegration,
) -> ParsedIntent:
    prompt = INTENT_PARSE_PROMPT.format(instruction=instruction.strip())

    # 增强版 Prompt，增加字数提取
    # ...
```

2. **`prompts/intent_parse.txt` 增强版**：

```text
你是 NSFC 标书写作助手的"意图解析器"。

任务：把用户指令解析为 JSON，字段：
- action: expand|compress|rewrite|restructure|diagnose
- target: 目标段落/小标题（优先匹配 \\subsubsection 标题）
- focus: 关注点（可为空）
- constraints: 约束（可为空，例如 年份范围、字数、必须保留信息点）
- word_count_target: 用户指定的目标字数（整数，可为 null）
- word_count_range: 用户指定的字数范围 [min, max]（可为 null）
- reason: 无法判断时说明原因（可为 null）

字数识别规则：
- 明确数字："写 3000 字" → word_count_target=3000
- 范围："控制在 2500-3000 字" → word_count_range=[2500, 3000]
- 约/左右："约 3000 字" → word_count_target=3000（tolerance 自动放宽）
- 未指定：word_count_target=null，word_count_range=null

要求：
- 只输出 JSON（不要解释）
- 若无法判断 action/target/字数，请用 null

用户指令：
{instruction}
```

3. **字数优先级判断逻辑**：

```python
# core/wordcount.py 增强
def resolve_word_count_target(
    *,
    user_intent: Optional[ParsedIntent] = None,
    info_form_text: Optional[str] = None,
    preset_config: Optional[Dict[str, Any]] = None,
    global_config: Optional[Dict[str, Any]] = None,
) -> tuple[int, int]:  # (target, tolerance)
    """
    解析字数目标，按优先级返回 (target, tolerance)

    优先级：
    1. 用户 Prompt 中明确指定的字数
    2. 信息表中的字数限制
    3. 学科预设的字数要求
    4. 全局默认值（兜底）
    """

    # P0: 用户 Prompt 中的字数
    if user_intent:
        if user_intent.word_count_target:
            target = user_intent.word_count_target
            # 如果用户说"约 3000 字"，tolerance 放宽到 ±10%
            if "约" in user_intent.constraints or "左右" in user_intent.constraints:
                tol = max(int(target * 0.1), 200)
            else:
                tol = 200  # 默认 ±200
            return target, tol
        if user_intent.word_count_range:
            min_w, max_w = user_intent.word_count_range
            target = (min_w + max_w) // 2
            tol = (max_w - min_w) // 2
            return target, tol

    # P1: 信息表中的字数限制
    if info_form_text:
        # 解析 "字数限制：3000±200" 或 "目标字数：3000"
        match = re.search(r'字数[：:]\s*(\d+)\s*[±±]\s*(\d+)', info_form_text)
        if match:
            target, tol = int(match.group(1)), int(match.group(2))
            return target, tol
        match = re.search(r'字数[：:]\s*(\d+)', info_form_text)
        if match:
            return int(match.group(1)), 200

    # P2: 学科预设
    if preset_config and preset_config.get("word_count"):
        wc = preset_config["word_count"]
        if isinstance(wc, dict):
            return int(wc.get("target", 4000)), int(wc.get("tolerance", 200))

    # P3: 全局默认值（兜底）
    return 4000, 200
```

4. **诊断输出调整**：

```markdown
# 原来（固定 4000 字）
- ℹ️ 字数统计（中文字符，不含注释）：2210
  目标：4000，偏差：-1790，状态：need_expand

# 改进后（用户意图优先）
- ℹ️ 字数统计（中文字符，不含注释）：2210
  目标：3000（用户指定），偏差：-790，状态：need_expand
  来源：用户 Prompt "写 3000 字左右的立项依据"
```

5. **写作教练阶段判断适配**：

```python
# core/writing_coach.py 调整
def _infer_stage(*, tex_text: str, tier1: Dict[str, Any], word_target: int, tol: int) -> WritingStage:
    # word_target 现在是动态解析的，而非固定 4000
    # ...
```

#### 配置调整建议

```yaml
# config.yaml
word_count:
  # 全局默认值（兜底，优先级最低）
  target: 4000
  tolerance: 200

  # 新增：说明这是示例值，非强制
  _note: "4000 字为示例值，实际字数应根据用户意图/学科预设/信息表动态确定"

# config/presets/medical.yaml（示例）
word_count:
  target: 5000   # 医学项目可能需要更多字数
  tolerance: 300

# config/presets/engineering.yaml（示例）
word_count:
  target: 3500   # 工程项目可能更简洁
  tolerance: 200
```

#### 核心原则

> **用户意图优先，配置默认兜底**。AI 应该智能识别用户的字数需求，而不是机械地使用固定默认值。配置中的 `target: 4000` 仅是示例/兜底值，实际使用时应按优先级动态解析。

#### 与前两个改进的协同

四个改进方向的核心思想一致：

| 改进项 | 从 | 到 |
|--------|-----|-----|
| **结构规则** | 硬编码 4 个标题，严格匹配 | AI 语义分析 4 个内容维度是否覆盖 |
| **质量规则** | 硬编码禁词表，字符串匹配 | AI 语义识别"吹牛式表述" |
| **字数规则** | 固定默认值 4000 | 用户意图优先（Prompt > 信息表 > 学科预设 > 全局默认） |
| **术语规则** | 硬编码别名组矩阵 | AI 语义识别术语/缩写/指标口径一致性 |

四者都是从"机械固定"转向"智能适应"，让系统真正响应用户的实际需求。

---

### 4. 术语规则：从"硬编码别名组"转向"AI 语义一致性判断"

#### 现状问题

当前 `terminology.dimensions/alias_groups` 硬编码了术语别名组：

```yaml
# config.yaml L129-L135
terminology:
  dimensions:
    研究对象:
      研究对象: ["患者", "病例", "受试者", "样本"]
    指标:
      准确率: ["准确率", "精确度"]
    术语:
      深度学习: ["深度学习", "DL"]
```

**问题**：
- 用户的术语千差万别，不可能穷尽所有可能的别名组合
- 不同学科/项目的术语体系差异巨大
- 核心目标是"术语一致性"，而不是"匹配硬编码别名组"
- 硬编码别名组只能覆盖少数常见情况，实际使用价值有限

#### 改进方向

**从"别名组匹配"转向"AI 语义一致性判断"**：

| 检查类型 | 硬编码（现状） | AI 语义判断（改进后） |
|---------|---------------|---------------------|
| **研究对象** | 预定义 `["患者", "病例", "受试者", "样本"]` | AI 识别文中的"被观察实体"及其变体表述 |
| **指标口径** | 预定义 `准确率: ["准确率", "精确度"]` | AI 识别"衡量标准"及其同义/近义表述 |
| **术语一致性** | 预定义 `深度学习: ["深度学习", "DL"]` | AI 识别"专业概念"及其缩写/全称混用 |
| **缩写混用** | 无法检测 | AI 识别同一概念的不同缩写形式 |

#### 实施建议

1. **保留硬编码作为"示例规则"**（用于演示和兜底）：

```yaml
# config.yaml
terminology:
  # 保留作为"示例规则"（用于演示和兜底）
  dimensions:
    研究对象:
      研究对象: ["患者", "病例", "受试者", "样本"]
    指标:
      准确率: ["准确率", "精确度"]
    术语:
      深度学习: ["深度学习", "DL"]

  # 新增：启用 AI 语义一致性判断
  enable_ai_semantic_check: true
  ai_mode: "auto"  # auto | semantic_only | legacy_only
```

2. **AI 语义一致性判断**（已有 `TermConsistencyAI`，需增强）：

```python
# core/term_consistency.py 增强
class TermConsistencyAI:
    """
    AI 主导的跨章节术语一致性检查。

    说明：
    - 不依赖硬编码别名组，而是基于语义判断术语/缩写/指标口径是否一致
    - 识别同义词、近义词、缩写混用、翻译变体等问题
    - 区分"同一概念的不同表述"和"不同概念"（避免误报）
    """

    async def check(
        self,
        *,
        files: Mapping[str, Path],
        max_chars: int = 20000,
        cache_dir: Optional[Path] = None,
        fresh: bool = False,
    ) -> Dict[str, Any]:
        prompt = """
        请分析以下 LaTeX 文档内容的术语/缩写/指标口径一致性。

        检查类型：
        1) **研究对象一致性**：识别"被观察实体"的不同表述
           - 同一对象的不同表述（如"患者/病例/受试者"）
           - 翻译变体（如"patient/Patient/病人"）
           - 缩写混用（如"SUB/subjects"）

        2) **指标口径一致性**：识别"衡量标准"的不同表述
           - 同一指标的不同名称（如"准确率/精确度/precision"）
           - 计算方式差异（如"F1-score/F1分数/F1值"）

        3) **术语一致性**：识别"专业概念"的不同表述
           - 全称/缩写混用（如"深度学习/DL/Deep Learning"）
           - 中英混用（如"卷积神经网络/conv/CNN"）
           - 同一概念的不同翻译

        4) **缩写定义**：检查缩写是否首次出现时有定义
           - 识别未定义的缩写
           - 识别同一缩写的多次定义

        请注意区分：
        - "同一概念的不同表述"需要标记
        - "不同概念"不是问题（如"准确率"和"召回率"是两个不同指标）
        - 优先报告"高频混用"问题（出现 3 次以上）

        输入（JSON，key 为章节名，value 为去注释后的 LaTeX 文本，可能截断）：
        {file_contents_json}

        返回 JSON：
        {
          "issues": [
            {
              "category": "研究对象/指标口径/术语一致性/缩写定义",
              "severity": "high/medium/low",
              "detail": "具体问题描述",
              "examples": [
                {"chapter": "1.1 立项依据", "text": "...", "line": 12},
                {"chapter": "2.1 研究内容", "text": "...", "line": 45}
              ],
              "suggestion": "修改建议"
            }
          ],
          "summary": {
            "total_issues": 5,
            "by_category": {"研究对象": 2, "术语一致性": 3},
            "high_frequency": ["患者/病例混用", "DL/深度学习混用"]
          }
        }
        """
```

3. **诊断输出调整**：

```markdown
# 原来（硬编码别名组）
## 术语一致性
| 术语 | 1.1 立项依据 | 2.1 研究内容 | 3.1 研究基础 | 结论 |
|------|-------------|-------------|-------------|------|
| 研究对象 | 患者(3) | 患者(5) | 患者(2) | ✅ 一致 |
| 深度学习 | DL(2) | 深度学习(3) | DL(1) | ⚠️ 不一致 |

# 改进后（AI 语义判断）
## 术语一致性检查（AI 语义分析）

### 高频术语一致性（出现 3 次以上）
- ✅ **研究对象**：一致（"患者"为主）
- ⚠️ **深度学习相关**：混用（"深度学习" 6 次、"DL" 4 次、"Deep Learning" 2 次）
  - 建议：统一为"深度学习"（首次出现时注明英文缩写 DL）

### 发现 5 处术语一致性问题：

1. [研究对象-中]
   - **1.1 立项依据 L12**："患者(n=120)"
   - **2.1 研究内容 L45**："病例共 150 例"
   - **3.1 研究基础 L23**："受试者样本"
   - 建议：统一为"患者"（医学领域通用表述）

2. [术语一致性-中]
   - **1.1 立项依据 L34**："采用深度学习(DL)模型"
   - **2.1 研究内容 L67**："基于 Deep Learning 方法"
   - **3.1 研究基础 L89**："深度学习算法"
   - 建议：统一为"深度学习"，首次出现时注明"(DL)"

3. [缩写定义-低]
   - **1.1 立项依据 L45**："使用 CNN 处理..."（未定义）
   - 建议：首次使用 CNN 时标注"卷积神经网络(CNN)"
```

#### 配置调整建议

```yaml
# config.yaml
terminology:
  # 保留作为"示例规则"（用于演示和兜底）
  dimensions:
    研究对象:
      研究对象: ["患者", "病例", "受试者", "样本"]
    指标:
      准确率: ["准确率", "精确度"]
    术语:
      深度学习: ["深度学习", "DL"]

  # 改为 auto：AI 语义判断为主，硬编码为辅
  mode: auto  # auto | semantic_only | legacy_only

  # 新增：启用 AI 语义一致性判断
  enable_ai_semantic_check: true
  ai_mode: "auto"  # auto | semantic_only | legacy_only

  ai:
    enabled: true
    max_chars: 20000
```

#### 核心原则

> **硬编码是示例，语义判断是本质**。用户的术语千差万别，不可能穷尽所有可能的别名组合。AI 应该基于语义判断术语/缩写/指标口径的一致性，而不是机械地匹配预定义的别名组。

#### 与前三个改进的协同

四个改进方向的核心思想一致：

| 改进项 | 从 | 到 |
|--------|-----|-----|
| **结构规则** | 硬编码 4 个标题，严格匹配 | AI 语义分析 4 个内容维度是否覆盖 |
| **质量规则** | 硬编码禁词表，字符串匹配 | AI 语义识别"吹牛式表述" |
| **字数规则** | 固定默认值 4000 | 用户意图优先（Prompt > 信息表 > 学科预设 > 全局默认） |
| **术语规则** | 硬编码别名组矩阵 | AI 语义识别术语/缩写/指标口径一致性 |

四者都是从"机械固定"转向"智能适应"，让系统真正响应用户的实际需求。

---

### 5. 写作阶段推断：从"硬编码规则链"转向"AI 智能判断"

#### 现状问题

当前 `_infer_stage` 使用硬编码的 if-else 规则链：

```python
# core/writing_coach.py L30-L42
def _infer_stage(*, tex_text: str, tier1: Dict[str, Any], word_target: int, tol: int) -> WritingStage:
    if not tex_text.strip():
        return "skeleton"
    if not bool(tier1.get("structure_ok")):
        return "skeleton"
    wc = int(tier1.get("word_count", 0))
    if wc < max(int(word_target * 0.4), 600):
        return "draft"
    if not bool(tier1.get("citation_ok")) or tier1.get("forbidden_phrases_hits") or tier1.get("avoid_commands_hits"):
        return "revise"
    if abs(wc - word_target) > tol:
        return "polish"
    return "final"
```

**问题**：
- 用户写作习惯千差万别：有人先搭骨架再填充，有人边写边调结构，有人先写核心再补充
- 硬编码规则太死板：字数 < 40% 就是 `draft`？可能用户写得精炼，内容已经很完整
- 无法理解用户真实意图：用户可能在某个阶段反复打磨，但规则会误判
- 阈值固定（40%、600 字）无法适应不同学科/项目类型

#### 改进方向

**从"规则链判断"转向"AI 综合评估"**：

| 判断维度 | 硬编码（现状） | AI 智能判断（改进后） |
|---------|---------------|---------------------|
| **内容完整度** | 只看小节数量（≥ 4 个） | 理解 4 个内容维度的覆盖程度与深度 |
| **写作进度** | 只看字数（是否达到 40%） | 综合字数 + 内容密度 + 逻辑完整性 |
| **质量状态** | 机械检查引用/禁词 | 理解内容质量：逻辑连贯性、论证充分度 |
| **下一步建议** | 固定套路 | 根据当前状态给出个性化建议 |

#### 实施建议

1. **保留硬编码作为兜底（AI 不可用时）**

2. **新增 AI 阶段推断**：

```python
# core/writing_coach.py 增强
async def _infer_stage_with_ai(
    *,
    tex_text: str,
    tier1: Dict[str, Any],
    word_target: int,
    tol: int,
    ai: AIIntegration,
    cache_dir: Optional[Path] = None,
) -> WritingStage:
    """
    AI 主导的写作阶段推断。

    说明：
    - 不依赖固定阈值，而是综合评估内容完整度、质量状态、写作进度
    - 返回阶段 + 置信度 + 推理依据
    """

    prompt = f"""
请分析以下立项依据文本，判断当前处于哪个写作阶段。

写作阶段定义：
1) skeleton（骨架）：刚起步，仅有结构框架，内容严重不足
2) draft（草稿）：有基本内容，但逻辑不完整/论证不充分/需要大量补充
3) revise（修订）：内容基本完整，但有问题（引用缺失/不可核验表述/逻辑跳跃）
4) polish（润色）：内容完整且无质量问题，但字数不达标需要压缩/扩写
5) final（定稿）：内容完整、质量合格、字数达标，可最终检查

输入信息：
- 当前字数：{tier1.get('word_count', 0)}（目标：{word_target}，容差：±{tol}）
- 结构状态：{'✅ 完整' if tier1.get('structure_ok') else '❌ 不完整'}（小节数：{tier1.get('subsubsection_count', 0)}）
- 引用状态：{'✅ 正常' if tier1.get('citation_ok') else '❌ 缺失引用'}
- 质量问题：禁用词 {tier1.get('forbidden_phrases_hits', [])}，危险命令 {tier1.get('avoid_commands_hits', [])}

文本内容（去注释后，最多 3000 字）：
{tex_text[:3000]}

返回 JSON：
{{
  "stage": "skeleton|draft|revise|polish|final",
  "confidence": 0.95,
  "reasoning": "判断依据（2-3 句）",
  "next_steps": ["下一步建议1", "下一步建议2", "下一步建议3"],
  "blocked_by": ["引用缺失", "不可核验表述"]  # 阻塞因素，可为空
}}
"""

    def _fallback() -> Dict[str, Any]:
        # AI 不可用时回退到硬编码规则
        return {
            "stage": _infer_stage_fallback(tex_text=tex_text, tier1=tier1, word_target=word_target, tol=tol),
            "confidence": 0.5,
            "reasoning": "AI 不可用，使用硬编码规则推断",
            "next_steps": [],
            "blocked_by": [],
        }

    obj = await ai.process_request(
        task="infer_writing_stage",
        prompt=prompt,
        fallback=_fallback,
        output_format="json",
        cache_dir=cache_dir,
    )

    if isinstance(obj, dict) and obj.get("stage"):
        return obj.get("stage", "auto")

    return _infer_stage_fallback(tex_text=tex_text, tier1=tier1, word_target=word_target, tol=tol)


def _infer_stage_fallback(*, tex_text: str, tier1: Dict[str, Any], word_target: int, tol: int) -> WritingStage:
    """硬编码兜底（AI 不可用时使用）"""
    if not tex_text.strip():
        return "skeleton"
    if not bool(tier1.get("structure_ok")):
        return "skeleton"
    wc = int(tier1.get("word_count", 0))
    if wc < max(int(word_target * 0.4), 600):
        return "draft"
    if not bool(tier1.get("citation_ok")) or tier1.get("forbidden_phrases_hits") or tier1.get("avoid_commands_hits"):
        return "revise"
    if abs(wc - word_target) > tol:
        return "polish"
    return "final"
```

3. **诊断输出调整**：

```markdown
# 原来（硬编码规则）
阶段：draft（硬编码规则：字数 1200 < 1600）

# 改进后（AI 智能判断）
阶段：draft（置信度：0.92）
推理依据：内容覆盖了 3 个维度，但"项目切入点"缺失；字数虽不足但逻辑框架清晰
下一步建议：
1. 补充"项目切入点"部分（本项目相对现有工作的差异化切口）
2. 扩充"现状与不足"段落，增加 2-3 个代表性工作的不足分析
3. 统一术语口径（深度学习/DL 混用）
阻塞因素：无
```

4. **配置调整建议**：

```yaml
# config.yaml
writing_coach:
  # 新增：启用 AI 阶段推断
  enable_ai_stage_inference: true
  ai_inference_mode: "auto"  # auto | ai_only | fallback

  # 保留硬编码作为兜底
  fallback_rules:
    draft_threshold_ratio: 0.4  # 字数目标 40% 以下判定为 draft
    draft_min_chars: 600        # 最低 600 字
```

#### 核心原则

> **规则是死的，场景是活的**。用户写作习惯千差万别，不可能用固定规则覆盖所有场景。AI 应该综合理解内容完整度、质量状态、写作进度，给出个性化的阶段判断和建议。

#### 与前四个改进的协同

五个改进方向的核心思想一致：

| 改进项 | 从 | 到 |
|--------|-----|-----|
| **结构规则** | 硬编码 4 个标题，严格匹配 | AI 语义分析 4 个内容维度是否覆盖 |
| **质量规则** | 硬编码禁词表，字符串匹配 | AI 语义识别"吹牛式表述" |
| **字数规则** | 固定默认值 4000 | 用户意图优先（Prompt > 信息表 > 学科预设 > 全局默认） |
| **术语规则** | 硬编码别名组矩阵 | AI 语义识别术语/缩写/指标口径一致性 |
| **阶段推断** | 硬编码 if-else 规则链 | AI 综合评估内容状态 + 个性化建议 |

五者都是从"机械固定"转向"智能适应"，让系统真正响应用户的实际需求。

---

## 变更历史

本计划不在本文档内维护变更历史；统一记录在根级 `CHANGELOG.md`。
