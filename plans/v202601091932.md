# nsfc-justification-writer 改良计划

**生成时间**：2026-01-09
**当前版本**：v0.5.0
**计划编号**：v202601091932

---

## 零、设计理念

### 核心原则：零API配置，直接使用宿主环境AI

**设计哲学**：
本skill的AI能力**直接依赖Claude Code/Codex环境的内置AI**，用户无需额外配置任何API密钥、环境变量或第三方服务。

**技术实现**：
- 通过Skill的`responder`机制调用宿主环境的AI智能
- `AIIntegration`类自动接收来自Claude Code/Codex的AI响应
- 所有AI主导功能（LaTeX解析、术语检查、注释处理、示例推荐）均使用同一套机制

**用户体验**：
```bash
# 用户只需正常使用skill，无需任何额外配置
/justification diagnose --project-root /path/to/nsfc

# AI能力自动可用，无需：
# ✗ 配置 OPENAI_API_KEY
# ✗ 设置 ANTHROPIC_API_KEY
# ✗ 安装任何AI SDK
# ✗ 配置代理或端点
```

**优雅降级策略**：
- 当在Claude Code/Codex环境运行时，AI能力完全可用
- 当在纯CLI模式运行时（未通过Skill调用），自动降级到硬编码方案
- 所有AI主导功能均提供fallback机制，保证最低可用性

**与Vibe Coding理念一致**：
- Claude Code/Codex本身就是AI驱动的开发环境
- Skill作为环境的扩展，自然共享环境的AI能力
- 用户无需关心"AI从哪来"，专注于"AI能做什么"

---

## 一、开发度评估

### 1.1 总体评分：86/100（成熟可用，有改进空间）

| 维度 | 评分 | 说明 |
|------|------|------|
| **功能完整性** | 90/100 | 核心功能齐全：Tier1/Tier2诊断、写作教练、安全写入、版本管理 |
| **代码质量** | 85/100 | 结构清晰、模块化良好、类型注解完整；但部分逻辑可优化 |
| **测试覆盖** | 80/100 | 30个测试全部通过，但缺少边界条件和异常场景测试 |
| **文档完整** | 95/100 | SKILL.md、架构、教程、工作流文档齐全；Prompt模板独立管理 |
| **可扩展性** | 90/100 | 配置系统良好，支持preset/override；AI集成层优雅降级，适配Claude Code环境 |
| **用户体验** | 75/100 | CLI功能丰富，但缺少交互式引导和可视化工具 |

### 1.2 已实现功能清单

| 类别 | 功能 | 实现状态 | 位置 |
|------|------|----------|------|
| **诊断** | Tier1 硬编码诊断（结构/引用/字数/禁用表述） | ✅ 完整 | `core/diagnostic.py` |
| **诊断** | Tier2 AI 语义分析（逻辑/术语/证据） | ✅ 完整 | `core/hybrid_coordinator.py` |
| **诊断** | HTML 可视化报告 | ✅ 完整 | `core/html_report.py` |
| **写作** | 渐进式写作教练（5阶段引导） | ✅ 完整 | `core/writing_coach.py` |
| **写作** | 按 `\subsubsection` 精确替换 | ✅ 完整 | `core/latex_parser.py` |
| **写作** | 白名单写入保护 | ✅ 完整 | `core/security.py` |
| **版本** | 备份/diff/回滚 | ✅ 完整 | `core/versioning.py` |
| **引用** | 缺失bibkey检测 | ✅ 完整 | `core/reference_validator.py` |
| **引用** | DOI格式验证 | ✅ 完整 | `core/reference_validator.py` |
| **引用** | Crossref联网校验 | ✅ 完整 | `scripts/run.py:refs` |
| **术语** | 跨章节一致性检查 | ✅ 完整 | `core/term_consistency.py` |
| **示例** | 按主题推荐示例 | ✅ 完整 | `core/example_matcher.py` |
| **配置** | 多层配置覆盖（基础/preset/用户/命令行） | ✅ 完整 | `core/config_loader.py` |
| **AI** | 缓存机制（SHA256） | ✅ 完整 | `core/ai_integration.py` |
| **AI** | 分块处理（大文件支持） | ✅ 完整 | `core/hybrid_coordinator.py` |

---

## 二、缺陷分析（按优先级排序）

### 2.1 高优先级缺陷

#### 缺陷1：LaTeX解析器未利用AI的理解能力

**问题**：
- 当前 `latex_parser.py` 完全依赖硬编码正则表达式
- 无法充分利用Claude Code环境中的AI对LaTeX语法的深度理解
- 对于复杂的LaTeX结构（嵌套花括号、条件命令、自定义环境），正则表达式难以覆盖所有情况
- 硬编码方案需要持续维护以应对边缘情况

**影响**：
- 用户遇到复杂标题结构时需要手动简化
- 限制了skill处理真实LaTeX文档的能力
- 维护成本高，每次新增边缘情况都需要修改代码

**证据**：
```python
# latex_parser.py:12 - 纯硬编码方案
_SUBSUBSECTION_RE = re.compile(r"\\subsubsection\s*\{([^}]*)\}")
# 无法利用AI对LaTeX的理解能力
```

---

#### 缺陷2：写入策略未利用AI的意图理解能力（已合并到缺陷1）

**说明**：本缺陷已被缺陷1的AI主导解析方案覆盖，AI天然能理解用户意图，无需硬编码容错逻辑。

---

### 2.2 中优先级缺陷

#### 缺陷3：术语一致性检查未利用AI的语义理解能力

**问题**：
- 当前 `term_consistency.py` 完全依赖硬编码的术语维度和别名映射
- 无法充分利用AI对中文语义的理解能力
- 需要手动配置每个术语维度的别名组（如研究对象、指标、术语）
- AI能理解上下文中的术语关系，无需硬编码

**影响**：
- 用户需要手动维护术语别名映射
- 跨章节的隐含术语关系可能被遗漏
- 新领域/新项目需要重新配置术语维度

**证据**：
```python
# term_consistency.py - 硬编码的术语维度
# config.yaml 中需要手动配置：
terminology:
  dimensions:
    research_objects:
      aliases: ["研究对象", "受试者", "样本", "患者"]
    metrics:
      aliases: ["指标", "参数", "测量值", "结局"]
# AI能自动理解这些语义关系
```

---

#### 缺陷4：Prompt模板的硬编码问题

**问题**：
- `prompts/tier2_diagnostic.txt` 等模板文件内容固定
- 用户无法通过 `config.yaml` 或 `--override` 自定义Prompt
- 不同学科/领域可能需要不同的诊断侧重点

**影响**：
- 医学方向可能更关注"临床证据"
- 工程方向可能更关注"性能指标/可复现性"
- 当前Prompt无法适配

---

#### 缺陷5：错误处理的细粒度不足

**问题**：
- 脚本入口 `run.py` 的异常处理：
  ```python
  except Exception as e:
      if bool(getattr(args, "verbose", False)):
          traceback.print_exc()
          raise
      print(f"❌ {type(e).__name__}: {e}", file=sys.stderr)
  ```
- 用户看到的只是异常类型和消息，缺少：
  - 问题定位（哪个文件/哪行）
  - 修复建议（下一步操作）

**影响**：
- 新手用户遇到错误时不知道如何解决
- 需要加 `--verbose` 才能看到堆栈

---

### 2.3 低优先级缺陷

#### 缺陷6：LaTeX注释解析未利用AI的语法理解能力

**问题**：
- 当前 `latex_parser.py` 的 `strip_comments` 使用简单正则 `(?<!\\)%.*$`
- 无法充分利用AI对LaTeX语法的深度理解
- LaTeX的注释规则复杂：`\verb|...|`、`\lstinline[...]|...|` 等环境中的 `%` 不是注释
- 硬编码方案需要维护所有特殊环境列表

**影响**：
- 特殊LaTeX代码块中的 `%` 被误识别为注释
- 字数统计不准确
- 新增LaTeX环境需要修改代码

**证据**：
```python
# latex_parser.py - 简单正则无法处理复杂LaTeX语法
_COMMENT_RE = re.compile(r"(?<!\\)%.*$")
# AI能理解：\verb|%notcomment| 中的 % 不是注释
```

---

#### 缺陷7：缺少对大文件的流式处理

**问题**：
- 当前所有LaTeX读取都是 `Path.read_text()` 一次性加载
- 超大文件（>5MB）可能导致内存压力

**影响**：
- 理论上存在，实践中NSFC正文通常不会那么大
- 但若用户将多个章节合并处理，可能触发

---

#### 缺陷8：示例推荐系统未利用AI的语义理解能力

**问题**：
- 当前 `example_matcher.py` 使用关键词TF匹配
- 无法充分利用AI对中文语义的深度理解
- 需要预计算嵌入向量或手动配置关键词
- AI能直接理解查询意图和示例内容的语义相似性

**影响**：
- 用户查询 `"计算机视觉"` 无法匹配到 `"CV"` 或 `"图像处理"` 示例
- 跨领域术语（如"深度学习" vs "神经网络"）无法匹配
- 新示例需要手动提取关键词或生成嵌入

**证据**：
```python
# example_matcher.py - 关键词TF匹配
score = len(query_keywords & ex_keywords)
# AI能理解："计算机视觉" 和 "CV" 语义相近
```

---

---

## 三、改良计划

### 3.1 高优先级改进（P0）

#### 改进1：LaTeX解析改为AI主导

**目标**：充分利用Claude Code环境的AI能力，让AI自主理解和解析LaTeX结构

**设计理念**：
- **零API配置**：直接使用Claude Code环境的内置AI，用户无需任何额外配置
- AI擅长理解LaTeX语法，无需硬编码
- 优雅降级：AI不可用时保留简单正则作为fallback
- 让AI处理复杂情况，简单情况快速处理

**实现方案**：

1. **新增AI解析接口**
   ```python
   # core/latex_parser.py 新增
   from .ai_integration import AIIntegration

   class LatexParserAI:
       """AI主导的LaTeX解析器"""

       def __init__(self, ai_integration: AIIntegration):
           self.ai = ai_integration

       async def parse_subsubsections_ai(
           self, text: str, project_root: str
       ) -> List[LatexSection]:
           """使用AI解析\subsubsection结构"""

           prompt = f"""请解析以下LaTeX文本，提取所有\\subsubsection的结构信息。

要求：
1. 忽略注释中的\\subsubsection（%开头的内容）
2. 正确处理嵌套花括号、LaTeX命令（如\\textit{{}}）
3. 返回JSON格式：{{"sections": [ {{"title": "原始标题", "title_plain": "纯文本标题", "header_start": int, "header_end": int, "body_start": int, "body_end": int}} ]}}

LaTeX文本：
{text[:10000]}  # 限制长度避免token超限
"""

           result = await self.ai.process_request(
               task="parse_latex_sections",
               prompt=prompt,
               output_format="json",
               fallback=lambda: self._fallback_parse(text),
           )

           if result and "sections" in result:
               return self._build_sections(text, result["sections"])
           return self._fallback_parse(text)

       def _fallback_parse(self, text: str) -> List[LatexSection]:
           """AI不可用时，使用简单正则作为fallback"""
           return parse_subsubsections_regex(text)  # 保留原有正则方法
   ```

2. **更新Coordinator使用AI解析**
   ```python
   # core/hybrid_coordinator.py 修改
   class HybridCoordinator:
       def __init__(self, ...):
           # ... 现有代码
           self.latex_parser = LatexParserAI(ai_integration=self.ai)

       async def apply_section_body_ai(
           self, project_root: Path, title: str, new_body: str
       ) -> ApplyResult:
           """使用AI定位并替换section"""
           target = self.target_path(project_root=project_root)
           text = target.read_text(encoding="utf-8", errors="ignore")

           # 让AI理解用户意图，找到正确的section
           prompt = f"""用户要替换以下LaTeX文档中的一个\\subsubsection正文。

用户指定的标题（可能有变体）：{title}
新正文内容：
{new_body}

请：
1. 理解用户的意图，找到最匹配的\\subsubsection（即使标题不完全一致）
2. 只替换该section的正文，保留标题不变
3. 返回JSON：{{"found": true/false, "matched_title": "实际匹配的标题", "modified_latex": "完整的新LaTeX文本"}}

原始LaTeX：
{text[:15000]}
"""

           result = await self.ai.process_request(
               task="apply_section",
               prompt=prompt,
               output_format="json",
               fallback=lambda: self._fallback_apply(text, title, new_body),
           )

           if result and result.get("found"):
               # AI成功处理
               return ApplyResult(success=True, message=result.get("matched_title"))
           return self._fallback_apply(text, title, new_body)
   ```

3. **保留快速路径（可选）**
   ```python
   def find_subsubsection_hybrid(text: str, title: str) -> Optional[LatexSection]:
       """混合策略：简单正则 + AI fallback"""

       # 快速路径：尝试简单正则匹配
       try:
           return parse_subsubsections_regex_fast(text, title)
       except AmbiguousMatchError:
           # 复杂情况：交给AI处理
           if self.ai.is_available():
               return self._ai_find_section(text, title)
           raise
   ```

**优势**：
- ✅ AI天然理解LaTeX语法，无需硬编码所有边缘情况
- ✅ 用户输入容错性强，AI能理解意图
- ✅ 优雅降级，AI不可用时仍可工作
- ✅ 代码简洁，维护成本低

**工作量**：3-4小时

---

#### 改进2：CLI错误提示优化（配合改进1）

**目标**：当AI解析或section定位失败时，给用户友好的错误提示和候选项

**说明**：改进1已通过AI实现智能标题匹配，本改进专注于CLI用户体验

**实现方案**：

1. **增强错误提示**
   ```python
   # scripts/run.py:cmd_apply_section 修改
   try:
       result = await coord.apply_section_body_ai(...)  # 使用改进1的AI方法
   except ValueError as e:
       if "not found" in str(e) or "no match" in str(e):
           # 列出所有可用标题
           target = coord.target_path(project_root=Path(args.project_root))
           tex = target.read_text(encoding="utf-8", errors="ignore")

           # 优先使用AI解析，fallback到正则
           if coord.ai.is_available():
               sections = await coord.latex_parser.parse_subsubsections_ai(tex)
           else:
               sections = parse_subsubsections(tex)

           print(f"❌ 未找到匹配的标题：{args.title}", file=sys.stderr)
           print("可用的标题：", file=sys.stderr)
           for sec in sections:
               print(f"  - {sec.title}", file=sys.stderr)

           print("\n💡 提示：AI会尝试理解您的意图，如果标题不完全一致也能匹配", file=sys.stderr)
       raise
   ```

2. **添加--suggest-alias选项**
   ```bash
   # 新增CLI选项，让AI建议可能的别名
   python scripts/run.py apply-section --title "研究背景" --suggest-alias
   ```

**工作量**：1-2小时

---

### 3.2 中优先级改进（P1）

#### 改进3：术语一致性检查改为AI主导

**目标**：充分利用Claude Code环境的AI中文语义理解能力，让AI自主发现术语一致性问题

**设计理念**：
- **零API配置**：直接使用Claude Code环境的内置AI，用户无需任何额外配置
- AI天然理解中文语义，无需手动配置别名映射
- AI能识别隐含的术语关系（如同义词、缩写、翻译）
- 优雅降级：AI不可用时保留硬编码维度作为fallback

**实现方案**：

1. **新增AI术语一致性检查**
   ```python
   # core/term_consistency.py 新增
   class TermConsistencyAI:
       """AI主导的术语一致性检查"""

       def __init__(self, ai_integration: AIIntegration):
           self.ai = ai_integration

       async def check_consistency_ai(
           self, files: Dict[str, Path], project_root: str
       ) -> Dict[str, Any]:
           """使用AI检查术语一致性"""

           # 读取所有相关章节
           file_contents = {}
           for label, path in files.items():
               if path.exists():
                   file_contents[label] = path.read_text(encoding="utf-8", errors="ignore")

           prompt = f"""请分析以下LaTeX文档的术语一致性。

文档内容：
{json.dumps(file_contents, ensure_ascii=False, indent=2)[:20000]}

请检查：
1. **研究对象一致性**：不同章节中同一研究对象是否有不同表述（如"患者"、"受试者"、"样本"）
2. **指标一致性**：同一指标是否有不同表述（如"收缩压"、"SBP"、"血压"）
3. **术语一致性**：专业术语是否保持一致

返回JSON格式：
{{
  "research_objects": {{"inconsistencies": ["描述具体的不一致之处"]}},
  "metrics": {{"inconsistencies": ["描述具体的不一致之处"]}},
  "terminology": {{"inconsistencies": ["描述具体的不一致之处"]}},
  "suggestions": ["给出具体修改建议"]
}}
"""

           result = await self.ai.process_request(
               task="check_term_consistency",
               prompt=prompt,
               output_format="json",
               fallback=lambda: self._fallback_check(files),
           )

           return result or {}

       def _fallback_check(self, files: Dict[str, Path]) -> Dict[str, Any]:
           """AI不可用时，使用硬编码维度作为fallback"""
           return check_term_consistency_legacy(files)  # 保留原有方法
   ```

2. **更新Coordinator**
   ```python
   # core/hybrid_coordinator.py 修改
   class HybridCoordinator:
       def __init__(self, ...):
           # ... 现有代码
           self.term_checker = TermConsistencyAI(ai_integration=self.ai)

       async def term_consistency_report_ai(
           self, project_root: Path
       ) -> str:
           """使用AI生成术语一致性报告"""
           targets = self.config.get("targets", {}) or {}
           files = {}
           for label, relpath in targets.get("term_check_files", {}).items():
               path = (project_root / relpath).resolve()
               if path.exists():
                   files[label] = path

           result = await self.term_checker.check_consistency_ai(
               files=files,
               project_root=str(project_root),
           )

           return self._format_term_report(result)

       def _format_term_report(self, result: Dict[str, Any]) -> str:
           """格式化AI返回的结果为Markdown"""
           lines = ["## 术语一致性检查（AI分析）\n"]

           for category in ["research_objects", "metrics", "terminology"]:
               if category in result:
                   lines.append(f"### {category}\n")
                   issues = result[category].get("inconsistencies", [])
                   if issues:
                       for issue in issues:
                           lines.append(f"- ❌ {issue}")
                   else:
                       lines.append("- ✅ 未发现明显不一致")
                   lines.append("")

           if result.get("suggestions"):
               lines.append("### 修改建议\n")
               for sugg in result["suggestions"]:
                   lines.append(f"- {sugg}")

           return "\n".join(lines)
   ```

3. **保留配置选项（可选）**
   ```yaml
   # config.yaml 新增
   terminology:
     mode: ai  # ai | legacy
     ai:
       enabled: true
       # 可选：给AI的提示维度
       dimensions: ["research_objects", "metrics", "terminology"]
     legacy:
       # 原有的硬编码配置作为fallback
       dimensions: ...
   ```

**优势**：
- ✅ AI自动理解语义关系，无需手动配置别名
- ✅ 能发现隐含的不一致（如"AI"和"人工智能"混用）
- ✅ 适应不同领域，无需重新配置
- ✅ 提供具体的修改建议，而非简单的警告

**工作量**：3-4小时

---

#### 改进4：实现Prompt模板可配置化

**目标**：支持通过override配置自定义Prompt

**实现方案**：

1. **配置结构**
   ```yaml
   # config.yaml 新增
   prompts:
     tier2_diagnostic: prompts/tier2_diagnostic.txt
     # 允许override
     tier2_diagnostic_medical: |
       你是医学立项依据诊断器。请关注：
       - 临床证据等级
       - 样本量与统计功效
       - 对照组设置
       ...
     tier2_diagnostic_engineering: |
       你是工程立项依据诊断器。请关注：
       - 性能指标可复现性
       - 基线对比
       - 消融实验设计
       ...
   ```

2. **动态加载逻辑**
   ```python
   def get_prompt(
       *,
       name: str,
       skill_root: Path,
       config: Dict,
       default: str,
       variant: Optional[str] = None,
   ) -> str:
       # 1. 尝试加载变体（如 tier2_diagnostic_medical）
       if variant:
           key = f"{name}_{variant}"
           if key in config.get("prompts", {}):
               return config["prompts"][key]

       # 2. 尝试加载文件
       file_path = config.get("prompts", {}).get(name, "")
       if file_path:
           full_path = (skill_root / file_path).resolve()
           if full_path.exists():
               return full_path.read_text(encoding="utf-8")

       # 3. 返回默认值
       return default
   ```

**工作量**：2小时

---

#### 改进5：增强错误处理细粒度

**目标**：提供问题定位和修复建议

**实现方案**：

1. **自定义异常基类**
   ```python
   # core/errors.py 扩展
   class SkillError(Exception):
       """所有skill异常的基类"""
       def __init__(self, message: str, fix_suggestion: str = ""):
           super().__init__(message)
           self.fix_suggestion = fix_suggestion

   class TargetFileNotFoundError(SkillError):
       def __init__(self, target_relpath: str, project_root: str):
           super().__init__(
               f"目标文件不存在：{target_relpath}",
               f"请确认：\n"
               f"1. 项目根目录是否正确：{project_root}\n"
               f"2. 模板是否已初始化（运行 make init-template）\n"
               f"3. 文件路径是否为：{target_relpath}"
           )

   class CitationMissingError(SkillError):
       def __init__(self, missing_keys: List[str]):
           super().__init__(
               f"检测到 {len(missing_keys)} 个缺失引用",
               f"建议：\n"
               f"1. 使用 nsfc-bib-manager 核验 DOI：\n"
               f"   python skills/nsfc-bib-manager/scripts/run.py add --doi <DOI>\n"
               f"2. 或手动添加到 references/*.bib"
           )
   ```

2. **CLI友好输出**
   ```python
   # scripts/run.py 主函数修改
   except SkillError as e:
       print(f"❌ {e}", file=sys.stderr)
       if e.fix_suggestion:
           print("\n💡 修复建议：", file=sys.stderr)
           print(e.fix_suggestion, file=sys.stderr)
       return 2
   ```

**工作量**：2-3小时

---

### 3.3 低优先级改进（P2）

#### 改进6：LaTeX注释解析改为AI主导

**目标**：充分利用Claude Code环境的AI对LaTeX语法的理解能力，正确处理注释和特殊环境

**设计理念**：
- **零API配置**：直接使用Claude Code环境的内置AI，用户无需任何额外配置
- AI天然理解LaTeX的注释规则和特殊环境
- 无需维护 `\verb`、`\lstinline`、`\verb Listing` 等环境列表
- 优雅降级：AI不可用时保留简单正则作为fallback

**实现方案**：

```python
# core/latex_parser.py 新增
class LatexCommentStripperAI:
    """AI主导的LaTeX注释解析器"""

    def __init__(self, ai_integration: AIIntegration):
        self.ai = ai_integration

    async def strip_comments_ai(
        self, text: str, preserve_structure: bool = False
    ) -> str:
        """使用AI移除LaTeX注释，保留特殊环境中的字符"""

        prompt = f"""请移除以下LaTeX文本中的注释，但保留代码块中的所有字符。

要求：
1. 移除 % 开头的行注释（保留换行）
2. 保留以下环境中的所有字符（包括%）：
   - \verb|...| （任何定界符）
   - \lstinline[...]|...|
   - \verb Listing|...|
   - 其他LaTeX代码环境
3. 返回处理后的纯文本

LaTeX文本：
{text[:20000]}
"""

        result = await self.ai.process_request(
            task="strip_latex_comments",
            prompt=prompt,
            output_format="text",
            fallback=lambda: self._fallback_strip(text),
        )

        return result or self._fallback_strip(text)

    def _fallback_strip(self, text: str) -> str:
        """AI不可用时，使用简单正则作为fallback"""
        return strip_comments_regex(text)  # 保留原有方法

    async def count_cjk_chars_ai(
        self, text: str
    ) -> int:
        """使用AI统计CJK字符数（考虑注释）"""

        # 先移除注释，再统计
        text_without_comments = await self.strip_comments_ai(text)

        prompt = f"""请统计以下文本中的中文字符数量（CJK字符）。

只返回数字，不要其他内容。

文本：
{text_without_comments[:10000]}
"""

        result = await self.ai.process_request(
            task="count_cjk_chars",
            prompt=prompt,
            output_format="text",
            fallback=lambda: self._fallback_count(text_without_comments),
        )

        try:
            return int(result.strip()) if result else self._fallback_count(text_without_comments)
        except ValueError:
            return self._fallback_count(text_without_comments)

    def _fallback_count(self, text: str) -> int:
        """AI不可用时，使用硬编码统计"""
        return sum(1 for c in text if '\u4e00' <= c <= '\u9fff')
```

**优势**：
- ✅ AI自动识别所有LaTeX代码环境，无需维护列表
- ✅ 能处理新出现的LaTeX包和环境
- ✅ 代码简洁，维护成本低
- ✅ 优雅降级，保证最低可用性

**工作量**：2-3小时

---

#### 改进7：实现大文件流式处理

**目标**：支持逐行解析大文件

**实现方案**：

```python
def count_cjk_chars_streaming(path: Path, chunk_size: int = 8192) -> int:
    """流式统计CJK字符（适用于超大文件）"""
    count = 0
    with path.open("r", encoding="utf-8", errors="ignore") as f:
        while True:
            chunk = f.read(chunk_size)
            if not chunk:
                break
            # 去除注释（简化版）
            chunk = _remove_comments_simple(chunk)
            count += sum(1 for c in chunk if '\u4e00' <= c <= '\u9fff')
    return count
```

**工作量**：2小时

---

#### 改进8：示例推荐改为AI主导

**目标**：充分利用Claude Code环境的AI语义理解能力，智能推荐最相关的示例

**设计理念**：
- **零API配置**：直接使用Claude Code环境的内置AI，用户无需任何额外配置
- AI直接理解查询意图和示例内容，无需嵌入向量
- 零预计算成本，新增示例无需处理
- AI能处理跨领域术语和隐含关联
- 优雅降级：AI不可用时保留关键词匹配作为fallback

**实现方案**：

```python
# core/example_matcher.py 新增
class ExampleRecommenderAI:
    """AI主导的示例推荐系统"""

    def __init__(self, ai_integration: AIIntegration):
        self.ai = ai_integration

    async def recommend_examples_ai(
        self, skill_root: Path, query: str, top_k: int = 3
    ) -> List[Dict[str, Any]]:
        """使用AI推荐最相关的示例"""

        # 读取所有示例的元数据和内容
        examples = load_all_examples(skill_root)  # 包含metadata.yaml和内容

        # 构建示例摘要
        example_summaries = []
        for ex in examples:
            summary = f"""
路径: {ex.relpath}
标题: {ex.title}
关键词: {', '.join(ex.keywords)}
摘要: {ex.summary}
内容片段: {ex.content[:500]}
"""
            example_summaries.append(summary)

        prompt = f"""用户查询：{query}

请从以下示例中选择最相关的 {top_k} 个，按相关性排序。

可用示例：
{chr(10).join(example_summaries)}

返回JSON格式：
{{
  "recommendations": [
    {{"rank": 1, "relpath": "示例路径", "title": "示例标题", "reason": "推荐理由（简述为何相关）"}},
    ...
  ]
}}

只返回JSON，不要其他内容。
"""

        result = await self.ai.process_request(
            task="recommend_examples",
            prompt=prompt,
            output_format="json",
            fallback=lambda: self._fallback_recommend(skill_root, query, top_k),
        )

        if result and "recommendations" in result:
            return result["recommendations"]
        return self._fallback_recommend(skill_root, query, top_k)

    def _fallback_recommend(
        self, skill_root: Path, query: str, top_k: int
    ) -> List[Dict[str, Any]]:
        """AI不可用时，使用关键词TF匹配作为fallback"""
        return recommend_examples_by_keywords(skill_root, query, top_k)  # 保留原有方法

    def format_recommendations_markdown(
        self, recommendations: List[Dict[str, Any]]
    ) -> str:
        """格式化推荐结果为Markdown"""
        lines = ["## 推荐示例\n"]

        for rec in recommendations:
            lines.append(f"### {rec.get('rank', '?')}. {rec.get('title', 'Unknown')}\n")
            lines.append(f"**路径**: `{rec.get('relpath', '')}`\n")
            lines.append(f"**推荐理由**: {rec.get('reason', '')}\n")
            lines.append("")

        return "\n".join(lines)
```

**优势**：
- ✅ **零预计算** - 无需预生成嵌入向量，新增示例立即可用
- ✅ **语义理解** - AI理解"计算机视觉"和"CV"是同一领域
- ✅ **跨领域匹配** - 能发现隐含关联（如"深度学习"→"神经网络"）
- ✅ **可解释性** - AI提供推荐理由，用户知道为何匹配
- ✅ **维护简单** - 无需维护嵌入模型或关键词映射

**工作量**：2-3小时

---

## 四、实施优先级路线图

### 第一阶段（P0，1-2周）
1. ✅ 改进1：LaTeX解析改为AI主导
2. ✅ 改进2：CLI错误提示优化（配合改进1）

**目标**：充分利用AI能力，提升LaTeX解析的鲁棒性和用户体验

---

### 第二阶段（P1，2-3周）
3. ✅ 改进3：术语一致性检查改为AI主导
4. ✅ 改进4：Prompt可配置化
5. ✅ 改进5：增强错误处理

**目标**：充分利用AI语义理解能力，减少手动配置，提升智能程度

---

### 第三阶段（P2，按需实施）
6. 改进6：LaTeX注释解析改为AI主导
7. 改进8：示例推荐改为AI主导
8. 改进7：大文件流式处理

**目标**：完善AI能力覆盖，提升整体智能化水平

---

## 五、测试策略

### 5.1 单元测试扩展

| 模块 | 新增测试用例 |
|------|-------------|
| `latex_parser` | AI解析mock测试、注释移除AI测试、fallback机制验证 |
| `term_consistency` | AI语义检查mock测试、术语关系识别 |
| `example_matcher` | AI推荐mock测试、语义相似度验证 |

### 5.2 集成测试

- 完整工作流：wizard → coach → apply → diagnose → review
- 边界条件：空文件、超大文件、特殊字符

### 5.3 回归测试

- 每次改进后运行 `pytest tests/` 确保无破坏
- 使用真实项目进行E2E测试

---

## 六、风险与缓解

| 风险 | 缓解措施 |
|------|----------|
| AI解析结果的可靠性 | 充分的mock测试+fallback机制+人工审核关键操作 |
| 性能优化引入新bug | 充分的单元测试+性能基准测试 |
| AI调用延迟增加 | 保留快速路径（简单正则）+异步处理 |
| 配置复杂度增加 | 提供预设（medical/engineering）+文档 |
| **零API配置的依赖性** | ✅ **非风险**：所有AI主导功能均提供硬编码fallback，保证在纯CLI模式下仍可用；用户获得"AI能力自动可用"的无缝体验，无需关心技术实现 |

---

## 变更历史

- 记录在根级 `CHANGELOG.md`
