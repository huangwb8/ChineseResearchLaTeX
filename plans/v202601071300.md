# complete_example Skill - AI å¢å¼ºç‰ˆæ„å»ºè®¡åˆ’

**åˆ›å»ºæ—¶é—´**: 2026-01-07 13:00
**ç›®æ ‡**: æ„å»ºä¸€ä¸ªå……åˆ†å‘æŒ¥ AI ä¼˜åŠ¿çš„ LaTeX ç¤ºä¾‹æ™ºèƒ½ç”Ÿæˆå™¨ï¼Œå®ç° AI ä¸ç¡¬ç¼–ç çš„æœ‰æœºèåˆ

---

## ğŸ“‹ ç›®å½•

- [1. æ ¸å¿ƒè®¾è®¡ç†å¿µ](#1-æ ¸å¿ƒè®¾è®¡ç†å¿µ)
- [2. AI å¢å¼ºæ¶æ„è®¾è®¡](#2-ai-å¢å¼ºæ¶æ„è®¾è®¡)
- [3. æ ¸å¿ƒæ¨¡å—è¯¦ç»†è®¾è®¡](#3-æ ¸å¿ƒæ¨¡å—è¯¦ç»†è®¾è®¡)
- [4. AI ä¸ç¡¬ç¼–ç èŒè´£åˆ†å·¥](#4-ai-ä¸ç¡¬ç¼–ç èŒè´£åˆ†å·¥)
- [5. å®Œæ•´å·¥ä½œæµè®¾è®¡](#5-å®Œæ•´å·¥ä½œæµè®¾è®¡)
- [6. ç›®å½•ç»“æ„](#6-ç›®å½•ç»“æ„)
- [7. é…ç½®æ–‡ä»¶è®¾è®¡](#7-é…ç½®æ–‡ä»¶è®¾è®¡)
- [8. æµ‹è¯•ç­–ç•¥](#8-æµ‹è¯•ç­–ç•¥)
- [9. å¼€å‘é‡Œç¨‹ç¢‘](#9-å¼€å‘é‡Œç¨‹ç¢‘)
- [10. é£é™©ä¸å¯¹ç­–](#10-é£é™©ä¸å¯¹ç­–)

---

## 1. æ ¸å¿ƒè®¾è®¡ç†å¿µ

### 1.1 è®¾è®¡å“²å­¦

**æ ¸å¿ƒåŸåˆ™ï¼šAI åš"è¯­ä¹‰ç†è§£"ï¼Œç¡¬ç¼–ç åš"ç»“æ„ä¿æŠ¤"**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AI å¢å¼ºå·¥ä½œæµ                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  ğŸ§  AI è´Ÿè´£çš„"æ™ºèƒ½å±‚"              ğŸ”§ ç¡¬ç¼–ç è´Ÿè´£çš„"ä¿æŠ¤å±‚"      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚
â”‚  â€¢ è¯­ä¹‰ç†è§£ç« èŠ‚ä¸»é¢˜                â€¢ æ ¼å¼å‚æ•°æå–ä¸é”å®š        â”‚
â”‚  â€¢ æ¨ç†èµ„æºä¸å†…å®¹çš„å…³è”             â€¢ LaTeX è¯­æ³•ç»“æ„éªŒè¯       â”‚
â”‚  â€¢ ç”Ÿæˆè¿è´¯çš„å™è¿°æ€§æ–‡æœ¬             â€¢ æ–‡ä»¶ç³»ç»Ÿå®‰å…¨æ“ä½œ         â”‚
â”‚  â€¢ æ ¹æ®ä¸Šä¸‹æ–‡è°ƒæ•´ç”¨è¯é£æ ¼           â€¢ ç¼–è¯‘æ‰§è¡Œä¸é”™è¯¯æ£€æµ‹       â”‚
â”‚  â€¢ è§£é‡Šèµ„æºä¸ºä»€ä¹ˆé€‚åˆæ”¾åœ¨è¿™é‡Œ       â€¢ å“ˆå¸Œæ ¡éªŒé˜²æ ¼å¼ç¯¡æ”¹       â”‚
â”‚  â€¢ è‡ªæˆ‘å®¡æŸ¥å’Œä¼˜åŒ–ç”Ÿæˆå†…å®¹           â€¢ å¤‡ä»½å›æ»šæœºåˆ¶            â”‚
â”‚                                                               â”‚
â”‚  ğŸ¤ åä½œç‚¹ï¼ˆAI + ç¡¬ç¼–ç ï¼‰                                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                        â”‚
â”‚  AI æä¾›è¯­ä¹‰å»ºè®® â†’ ç¡¬ç¼–ç åŒ…è£…ä¸ºå®‰å…¨ä»£ç  â†’ AI æ£€æŸ¥è¿è´¯æ€§         â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 æ ¸å¿ƒè®¾è®¡åŸåˆ™

| åŸåˆ™ | å®ç°æ–¹å¼ |
|------|----------|
| **æ ¼å¼ä¿æŠ¤ä¼˜å…ˆ** | FormatGuard ç±» + å—ä¿æŠ¤å‘½ä»¤ç™½åå• + å“ˆå¸ŒéªŒè¯ |
| **æ™ºèƒ½å†…å®¹æ•´åˆ** | AI è¯­ä¹‰ç†è§£ + æ™ºèƒ½æ¨ç† + æ¨¡æ¿åŒ–ç”Ÿæˆ |
| **ç”¨æˆ·å¼•å¯¼ç”Ÿæˆ** | ğŸ†• æ”¯æŒç”¨æˆ·è‡ªå®šä¹‰å™äº‹æç¤ºï¼ˆnarrative_hintï¼‰ï¼ŒAI æ ¹æ®æç¤ºç¼–é€ åˆç†ç¤ºä¾‹ |
| **å¯é…ç½®æ€§** | YAML é…ç½® + å¯†åº¦çº§åˆ«æ§åˆ¶ + è¾“å‡ºæ¨¡å¼é€‰æ‹© |
| **å¯è¿½æº¯æ€§** | AI è§£é‡Šæ‰€æœ‰å†³ç­–ç†ç”± + èµ„æºæ¥æºè¿½è¸ª |
| **å®‰å…¨ç¬¬ä¸€** | é»˜è®¤é¢„è§ˆæ¨¡å¼ + ç¼–è¯‘éªŒè¯ + æ ¼å¼ä¸å˜æ€§æ£€æŸ¥ |

### 1.2.1 ç”¨æˆ·æç¤ºæœºåˆ¶ï¼ˆğŸ†•ï¼‰

**è®¾è®¡ç†å¿µ**ï¼š
- **ç¤ºä¾‹åœºæ™¯** â‰  ä¸¥è‚ƒåœºæ™¯ï¼šå…è®¸ AI æ ¹æ®ç”¨æˆ·æç¤ºç¼–é€ åˆç†çš„å™äº‹å†…å®¹
- **ç”¨æˆ·å¼•å¯¼**ï¼šé€šè¿‡ `narrative_hint` å‚æ•°ï¼Œç”¨æˆ·å¯ä»¥æŒ‡å®šç ”ç©¶ä¸»é¢˜ã€æ–¹æ³•ã€åœºæ™¯ç­‰
- **AI è‡ªç”±åº¦**ï¼šAI åœ¨ç”¨æˆ·æç¤ºæ¡†æ¶å†…å‘æŒ¥åˆ›é€ åŠ›ï¼Œç”Ÿæˆè¿è´¯çš„ç¤ºä¾‹å†…å®¹

**æ”¯æŒåœºæ™¯ç¤ºä¾‹**ï¼š
- ğŸ¥ åŒ»ç–—å½±åƒï¼š"ç”Ÿæˆä¸€ä¸ªå…³äºæ·±åº¦å­¦ä¹ åœ¨åŒ»ç–—å½±åƒåˆ†æä¸­åº”ç”¨çš„ç¤ºä¾‹"
- ğŸ”¬ ææ–™ç§‘å­¦ï¼š"åˆ›å»ºä¸€ä¸ªå…³äºæ–°å‹çº³ç±³ææ–™åˆæˆä¸è¡¨å¾çš„ç¤ºä¾‹"
- ğŸ§ª ä¸´åºŠè¯•éªŒï¼š"æ¨¡æ‹Ÿä¸€ä¸ªå¤šä¸­å¿ƒä¸´åºŠè¯•éªŒçš„è®¾è®¡ä¸åˆ†ææµç¨‹"
- ğŸ¤– ä¼ ç»Ÿ MLï¼š"ç¼–å†™ä¸€ä¸ªä½¿ç”¨æ”¯æŒå‘é‡æœºè¿›è¡Œåˆ†ç±»çš„ç¤ºä¾‹ç ”ç©¶"

### 1.3 AI åˆ©ç”¨ç‡å¯¹æ¯”

```
åŸè®¡åˆ’ï¼ˆç¡¬ç¼–ç ä¸ºä¸»ï¼‰ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸŸ¥ ç¡¬ç¼–ç ï¼š85%                       â”‚
â”‚ ğŸŸ¨ AIï¼ˆæ¨¡æ¿æ›¿æ¢ï¼‰ï¼š15%               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

AI å¢å¼ºç‰ˆï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸŸ¢ AIï¼ˆè¯­ä¹‰ç†è§£ + ç”Ÿæˆï¼‰ï¼š70%       â”‚
â”‚ ğŸ¦¾ ç¡¬ç¼–ç ï¼ˆç»“æ„ä¿æŠ¤ï¼‰ï¼š30%          â”‚
â”‚ ğŸ¤ æœ‰æœºåä½œï¼šè¾¹ç•Œæ¸…æ™°                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. AI å¢å¼ºæ¶æ„è®¾è®¡

### 2.1 åˆ†å±‚æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ç”¨æˆ·æ¥å£å±‚                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  CLI å‘½ä»¤    â”‚  â”‚  Skill è°ƒç”¨  â”‚  â”‚  Python API  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     AI å¢å¼ºå·¥ä½œæµå±‚                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  CompleteExampleSkill (ä¸»æ§åˆ¶å™¨)                â”‚   â”‚
â”‚  â”‚  â€¢ åè°ƒå„æ¨¡å—äº¤äº’                               â”‚   â”‚
â”‚  â”‚  â€¢ ç®¡ç†æ‰§è¡ŒçŠ¶æ€                                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   AI æ™ºèƒ½å±‚ï¼ˆSemantic Layerï¼‰             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ SemanticAnalyzer â”‚  â”‚ AIContentGeneratorâ”‚            â”‚
â”‚  â”‚ â€¢ ä¸»é¢˜ç†è§£       â”‚  â”‚ â€¢ å™è¿°ç”Ÿæˆ        â”‚            â”‚
â”‚  â”‚ â€¢ èµ„æºæ¨ç†       â”‚  â”‚ â€¢ è‡ªæˆ‘ä¼˜åŒ–        â”‚            â”‚
â”‚  â”‚ â€¢ è´¨é‡è¯„ä¼°       â”‚  â”‚ â€¢ ä¸Šä¸‹æ–‡æ„ŸçŸ¥      â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 ç¡¬ç¼–ç ä¿æŠ¤å±‚ï¼ˆStructure Layerï¼‰           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  ResourceScanner â”‚  â”‚   FormatGuard    â”‚            â”‚
â”‚  â”‚ â€¢ æ–‡ä»¶æ‰«æ       â”‚  â”‚ â€¢ æ ¼å¼ä¿æŠ¤        â”‚            â”‚
â”‚  â”‚ â€¢ å…ƒæ•°æ®æå–     â”‚  â”‚ â€¢ ç¼–è¯‘éªŒè¯        â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     åŸºç¡€è®¾æ–½å±‚                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ LLM Client â”‚  â”‚ æ–‡ä»¶ç³»ç»Ÿ   â”‚  â”‚ LaTeX ç¼–è¯‘ â”‚        â”‚
â”‚  â”‚ (Claude/   â”‚  â”‚ æ“ä½œ       â”‚  â”‚ å¼•æ“       â”‚        â”‚
â”‚  â”‚  OpenAI)   â”‚  â”‚            â”‚  â”‚            â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 æ ¸å¿ƒèƒ½åŠ›çŸ©é˜µ

| èƒ½åŠ›ç»´åº¦ | åŸè®¡åˆ’ | AI å¢å¼ºç‰ˆ | æå‡æ–¹å¼ |
|---------|-------|----------|---------|
| **è¯­ä¹‰ç†è§£** | âŒ æ— æ³•ç†è§£ç« èŠ‚ä¸»é¢˜ | âœ… ç†è§£"ç ”ç©¶å†…å®¹"éœ€è¦æ–¹æ³•è®ºèµ„æº | SemanticAnalyzer |
| **æ™ºèƒ½æ¨ç†** | âŒ éšæœºæˆ–æŒ‰è§„åˆ™é€‰æ‹©èµ„æº | âœ… æ¨æ–­å›¾ç‰‡é€‚åˆçš„ç« èŠ‚ | AI ç›¸å…³æ€§è¯„åˆ† |
| **è¿è´¯ç”Ÿæˆ** | âŒ æ¨¡æ¿æ‹¼æ¥ï¼Œç”Ÿç¡¬ | âœ… ç”Ÿæˆè‡ªç„¶æµç•…çš„å™è¿° | AI å™è¿°ç”Ÿæˆ |
| **ä¸Šä¸‹æ–‡æ„ŸçŸ¥** | âŒ å›ºå®šæ¨¡æ¿ | âœ… æ ¹æ®ä¸Šä¸‹æ–‡è°ƒæ•´æè¿° | ä¸Šä¸‹æ–‡æ„ŸçŸ¥æç¤ºè¯ |
| **è‡ªæˆ‘ä¼˜åŒ–** | âŒ æ— æ³•è‡ªæˆ‘æ£€æŸ¥ | âœ… AI å®¡æŸ¥å¹¶ä¼˜åŒ– | AI è‡ªæˆ‘åæ€ |
| **æ ¼å¼å®‰å…¨** | âœ… æ­£åˆ™ä¿æŠ¤ | âœ… æ›´å¼ºï¼šAI è§£é‡Š + éªŒè¯ | åŒé‡ä¿æŠ¤æœºåˆ¶ |

---

## 3. æ ¸å¿ƒæ¨¡å—è¯¦ç»†è®¾è®¡

### 3.1 SemanticAnalyzer - AI é©±åŠ¨è¯­ä¹‰åˆ†æå™¨

**èŒè´£**ï¼šç†è§£ç« èŠ‚ä¸»é¢˜ã€æ¨ç†èµ„æºç›¸å…³æ€§ã€è¯„ä¼°å†…å®¹è´¨é‡

```python
# core/semantic_analyzer.py
from typing import List, Dict, Any
from dataclasses import dataclass
from pathlib import Path

@dataclass
class SectionTheme:
    """ç« èŠ‚ä¸»é¢˜åˆ†æç»“æœ"""
    theme: str                      # ç« èŠ‚æ ¸å¿ƒä¸»é¢˜
    key_concepts: List[str]         # å…³é”®æ¦‚å¿µåˆ—è¡¨
    writing_style: str              # å†™ä½œé£æ ¼ï¼šå­¦æœ¯/æŠ€æœ¯/è¯´æ˜
    suggested_resources: List[str]  # å»ºè®®çš„èµ„æºç±»å‹
    tone: str                       # è¯­è°ƒï¼šæ­£å¼/é€šä¿—
    target_audience: str            # ç›®æ ‡è¯»è€…ï¼šä¸“å®¶/è¯„å®¡/å¤§ä¼—

@dataclass
class ResourceRelevance:
    """èµ„æºç›¸å…³æ€§è¯„ä¼°ç»“æœ"""
    resource_path: str
    relevance_score: float          # 0-1 ç›¸å…³æ€§åˆ†æ•°
    reason: str                     # AI ç»™å‡ºçš„ç†ç”±
    suggested_usage: str            # å»ºè®®çš„ä½¿ç”¨æ–¹å¼

class SemanticAnalyzer:
    """AI é©±åŠ¨çš„è¯­ä¹‰åˆ†æå™¨"""

    def __init__(self, llm_client):
        """
        Args:
            llm_client: LLM å®¢æˆ·ç«¯ï¼ˆClaude/OpenAI/æœ¬åœ°æ¨¡å‹ï¼‰
        """
        self.llm = llm_client

    def analyze_section_theme(self, tex_content: str) -> SectionTheme:
        """
        åˆ†æç« èŠ‚çš„æ ¸å¿ƒä¸»é¢˜å’Œå†™ä½œæ„å›¾

        Args:
            tex_content: LaTeX æ–‡ä»¶å†…å®¹ï¼ˆå‰ 2000 å­—ç¬¦ï¼‰

        Returns:
            SectionTheme: ç»“æ„åŒ–çš„ä¸»é¢˜åˆ†æç»“æœ

        AI Prompt ç¤ºä¾‹ï¼š
        ```
        åˆ†æä»¥ä¸‹ LaTeX ç« èŠ‚çš„å†…å®¹ä¸»é¢˜ï¼š

        {tex_content[:2000]}

        è¿”å› JSONï¼š
        {
          "theme": "ç« èŠ‚ä¸»é¢˜",
          "key_concepts": ["æ¦‚å¿µ1", "æ¦‚å¿µ2"],
          "writing_style": "å­¦æœ¯/æŠ€æœ¯/è¯´æ˜",
          "suggested_resources": ["å›¾ç‰‡ç±»å‹", "æ–‡çŒ®é¢†åŸŸ"],
          "tone": "æ­£å¼/é€šä¿—",
          "target_audience": "ä¸“å®¶/è¯„å®¡/å¤§ä¼—"
        }
        ```
        """
        prompt = f"""
        ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å­¦æœ¯å†™ä½œåˆ†æä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹ LaTeX ç« èŠ‚çš„å†…å®¹ä¸»é¢˜ã€‚

        ç« èŠ‚å†…å®¹ï¼ˆå‰ 2000 å­—ç¬¦ï¼‰ï¼š
        {tex_content[:2000]}

        è¯·è¿”å› JSON æ ¼å¼çš„åˆ†æç»“æœï¼š
        {{
          "theme": "ç« èŠ‚çš„æ ¸å¿ƒä¸»é¢˜ï¼ˆä¸€å¥è¯æ¦‚æ‹¬ï¼‰",
          "key_concepts": ["å…³é”®æ¦‚å¿µ1", "å…³é”®æ¦‚å¿µ2", "å…³é”®æ¦‚å¿µ3"],
          "writing_style": "å­¦æœ¯/æŠ€æœ¯/è¯´æ˜/æ··åˆ",
          "suggested_resources": ["å»ºè®®çš„å›¾ç‰‡ç±»å‹", "å»ºè®®çš„æ–‡çŒ®é¢†åŸŸ"],
          "tone": "æ­£å¼/åŠæ­£å¼/é€šä¿—",
          "target_audience": "è¯„å®¡ä¸“å®¶/åŒè¡Œ/å­¦ç”Ÿ/å¤§ä¼—"
        }}
        """

        response = self.llm.complete(
            prompt,
            response_format="json",
            temperature=0.3  # ä½æ¸©åº¦ä¿è¯ç¨³å®šæ€§
        )

        import json
        return SectionTheme(**json.loads(response))

    def reason_resource_relevance(
        self,
        resource_info: 'ResourceInfo',
        section_theme: SectionTheme
    ) -> ResourceRelevance:
        """
        æ¨ç†èµ„æºä¸ç« èŠ‚çš„ç›¸å…³æ€§

        Args:
            resource_info: èµ„æºä¿¡æ¯ï¼ˆå›¾ç‰‡/ä»£ç /æ–‡çŒ®ï¼‰
            section_theme: ç« èŠ‚ä¸»é¢˜

        Returns:
            ResourceRelevance: ç›¸å…³æ€§è¯„ä¼°ç»“æœ

        AI Prompt ç¤ºä¾‹ï¼š
        ```
        ç« èŠ‚ä¸»é¢˜ï¼šç ”ç©¶å†…å®¹ã€ç ”ç©¶ç›®æ ‡ä¸å…³é”®ç§‘å­¦é—®é¢˜
        å…³é”®æ¦‚å¿µï¼š["ç†è®ºæ¡†æ¶", "æ¨¡å‹æ„å»º", "å®éªŒéªŒè¯"]
        å†™ä½œé£æ ¼ï¼šå­¦æœ¯

        èµ„æºä¿¡æ¯ï¼š
        - æ–‡ä»¶åï¼šzzmx-115.jpg
        - ç±»å‹ï¼šå›¾ç‰‡
        - å°ºå¯¸ï¼š800x600

        è¯¥èµ„æºä¸ç« èŠ‚çš„ç›¸å…³æ€§å¦‚ä½•ï¼Ÿï¼ˆ0-1 åˆ†ï¼Œå¹¶è¯´æ˜ç†ç”±ï¼‰
        ```
        """
        prompt = f"""
        ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å­¦æœ¯å†™ä½œé¡¾é—®ã€‚è¯·è¯„ä¼°ä»¥ä¸‹èµ„æºæ˜¯å¦é€‚åˆç”¨äºæŒ‡å®šç« èŠ‚ã€‚

        ç« èŠ‚ä¿¡æ¯ï¼š
        - ä¸»é¢˜ï¼š{section_theme.theme}
        - å…³é”®æ¦‚å¿µï¼š{', '.join(section_theme.key_concepts)}
        - å†™ä½œé£æ ¼ï¼š{section_theme.writing_style}
        - å»ºè®®èµ„æºï¼š{', '.join(section_theme.suggested_resources)}

        èµ„æºä¿¡æ¯ï¼š
        - è·¯å¾„ï¼š{resource_info.path}
        - ç±»å‹ï¼š{resource_info.type}
        - å…ƒæ•°æ®ï¼š{resource_info.metadata}

        è¯·è¿”å› JSON æ ¼å¼çš„è¯„ä¼°ç»“æœï¼š
        {{
          "relevance_score": 0.85,  // 0-1 ä¹‹é—´çš„åˆ†æ•°
          "reason": "è¯¦ç»†è¯´æ˜ä¸ºä»€ä¹ˆé€‚åˆæˆ–ä¸é€‚åˆï¼Œ100-200å­—",
          "suggested_usage": "å»ºè®®å¦‚ä½•ä½¿ç”¨è¿™ä¸ªèµ„æºï¼ˆå¦‚ï¼šä½œä¸ºæ–¹æ³•è®ºç¤ºæ„å›¾ï¼‰"
        }}
        """

        response = self.llm.complete(
            prompt,
            response_format="json",
            temperature=0.3
        )

        import json
        data = json.loads(response)
        return ResourceRelevance(
            resource_path=resource_info.path,
            relevance_score=data['relevance_score'],
            reason=data['reason'],
            suggested_usage=data['suggested_usage']
        )

    def generate_contextual_description(
        self,
        resource: 'ResourceInfo',
        context: str,
        usage_hint: str = None
    ) -> str:
        """
        ä¸ºèµ„æºç”Ÿæˆç¬¦åˆä¸Šä¸‹æ–‡çš„æè¿°æ–‡å­—

        Args:
            resource: èµ„æºä¿¡æ¯
            context: ä¸Šä¸‹æ–‡å†…å®¹ï¼ˆç« èŠ‚ç‰‡æ®µï¼‰
            usage_hint: ä½¿ç”¨æç¤ºï¼ˆå¯é€‰ï¼‰

        Returns:
            str: è‡ªç„¶çš„æè¿°æ–‡å­—ï¼ˆ50-100 å­—ï¼‰

        AI Prompt ç¤ºä¾‹ï¼š
        ```
        ä¸Šä¸‹æ–‡ï¼šæœ¬ç ”ç©¶é‡‡ç”¨ç†è®ºåˆ†æä¸å®éªŒéªŒè¯ç›¸ç»“åˆçš„æ–¹æ³•...

        èµ„æºï¼šzzmx-115.jpgï¼ˆå®éªŒè£…ç½®å›¾ï¼‰
        ä½¿ç”¨æç¤ºï¼šä½œä¸ºæ–¹æ³•è®ºç¤ºæ„å›¾

        ç”Ÿæˆä¸€æ®µè‡ªç„¶çš„æè¿°æ–‡å­—ï¼Œç”¨äºå¼•å…¥è¿™ä¸ªèµ„æºã€‚
        ```
        """
        prompt = f"""
        ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„å­¦æœ¯å†™ä½œè€…ã€‚è¯·ä¸ºä»¥ä¸‹èµ„æºç”Ÿæˆä¸€æ®µè‡ªç„¶çš„æè¿°æ–‡å­—ã€‚

        ä¸Šä¸‹æ–‡ï¼ˆç« èŠ‚ç‰‡æ®µï¼‰ï¼š
        {context[:500]}

        èµ„æºä¿¡æ¯ï¼š
        - æ–‡ä»¶åï¼š{resource.filename}
        - ç±»å‹ï¼š{resource.type}
        - å»ºè®®ç”¨é€”ï¼š{usage_hint or 'æœªæŒ‡å®š'}

        è¦æ±‚ï¼š
        1. ç”Ÿæˆ 50-100 å­—çš„æè¿°æ–‡å­—
        2. ç¬¦åˆå­¦æœ¯å†™ä½œé£æ ¼
        3. ä¸ä¸Šä¸‹æ–‡è‡ªç„¶è¡”æ¥
        4. åŒ…å«é€‚å½“çš„å¼•å…¥è¯­ï¼ˆå¦‚"å¦‚å›¾ X æ‰€ç¤º"ã€"æ ¹æ®æ–‡çŒ® X"ç­‰ï¼‰

        åªè¿”å›æè¿°æ–‡å­—ï¼Œä¸è¦è§£é‡Šã€‚
        """

        return self.llm.complete(prompt, temperature=0.7)

    def evaluate_content_quality(
        self,
        content: str,
        section_theme: SectionTheme = None
    ) -> Dict[str, Any]:
        """
        è¯„ä¼°ç”Ÿæˆå†…å®¹çš„è´¨é‡

        Args:
            content: ç”Ÿæˆçš„å†…å®¹
            section_theme: ç« èŠ‚ä¸»é¢˜ï¼ˆå¯é€‰ï¼Œç”¨äºå¯¹æ¯”ï¼‰

        Returns:
            Dict: è´¨é‡è¯„ä¼°æŠ¥å‘Š
        """
        prompt = f"""
        ä½ æ˜¯ä¸€ä½ä¸¥è°¨çš„å­¦æœ¯å†™ä½œè¯„å®¡ä¸“å®¶ã€‚è¯·è¯„ä¼°ä»¥ä¸‹ç¤ºä¾‹å†…å®¹çš„è´¨é‡ã€‚

        è¯„ä¼°å†…å®¹ï¼š
        {content[:2000]}

        ç« èŠ‚ä¸»é¢˜ï¼ˆä¾›å‚è€ƒï¼‰ï¼š
        {section_theme.theme if section_theme else 'æœªæŒ‡å®š'}

        è¯·è¿”å› JSON æ ¼å¼çš„è¯„ä¼°æŠ¥å‘Šï¼š
        {{
          "coherence": 0.92,  // è¿è´¯æ€§è¯„åˆ† 0-1
          "academic_tone": 0.88,  // å­¦æœ¯é£æ ¼è¯„åˆ† 0-1
          "resource_integration": "è‡ªç„¶/ç”Ÿç¡¬/æ— ",  // èµ„æºæ•´åˆè¯„ä»·
          "strengths": ["ä¼˜ç‚¹1", "ä¼˜ç‚¹2"],
          "weaknesses": ["ä¸è¶³1", "ä¸è¶³2"],
          "suggestions": ["æ”¹è¿›å»ºè®®1", "æ”¹è¿›å»ºè®®2"],
          "overall_score": 0.90  // æ€»ä½“è¯„åˆ† 0-1
        }}
        """

        response = self.llm.complete(
            prompt,
            response_format="json",
            temperature=0.3
        )

        import json
        return json.loads(response)
```

**AI ä»·å€¼ä½“ç°**ï¼š
- âœ… ç†è§£"ç ”ç©¶å†…å®¹"ç« èŠ‚éœ€è¦çš„æ˜¯æ–¹æ³•è®ºå›¾è¡¨ï¼Œè€Œä¸æ˜¯ç»“æœæˆªå›¾
- âœ… æ¨æ–­"zzmx-115.jpg"å¯èƒ½éœ€è¦é…æ–‡"å®éªŒè£…ç½®ç¤ºæ„å›¾"
- âœ… æ ¹æ®ä¸Šä¸‹æ–‡ç”Ÿæˆ"å¦‚å›¾ 1 æ‰€ç¤º..."æˆ–"å®éªŒé‡‡ç”¨ä»¥ä¸‹è£…ç½®..."
- âœ… ç»™å‡ºç›¸å…³æ€§è¯„åˆ†çš„å…·ä½“ç†ç”±ï¼ˆå¯è¿½æº¯ï¼‰

---

### 3.2 AIContentGenerator - AI å¢å¼ºå†…å®¹ç”Ÿæˆå™¨

**èŒè´£**ï¼šç”Ÿæˆè¿è´¯çš„å™è¿°æ€§æ–‡æœ¬ï¼Œæ™ºèƒ½æ•´åˆèµ„æº

```python
# core/ai_content_generator.py
from typing import List, Dict, Any
from pathlib import Path
import re

class AIContentGenerator:
    """AI é©±åŠ¨çš„æ™ºèƒ½å†…å®¹ç”Ÿæˆå™¨"""

    def __init__(self, llm_client, templates: dict, format_guard: 'FormatGuard'):
        """
        Args:
            llm_client: LLM å®¢æˆ·ç«¯
            templates: Jinja2 æ¨¡æ¿å­—å…¸
            format_guard: æ ¼å¼ä¿æŠ¤å™¨å®ä¾‹
        """
        self.llm = llm_client
        self.templates = templates
        self.guard = format_guard

    def generate_section_content(
        self,
        resources: List['ResourceInfo'],
        section_theme: 'SectionTheme',
        existing_content: str,
        content_density: str = "moderate",
        narrative_hint: str = None
    ) -> str:
        """
        ä¸ºç« èŠ‚ç”Ÿæˆ AI å¢å¼ºçš„ç¤ºä¾‹å†…å®¹

        Args:
            resources: å¯ç”¨èµ„æºåˆ—è¡¨
            section_theme: ç« èŠ‚ä¸»é¢˜ï¼ˆAI åˆ†æç»“æœï¼‰
            existing_content: ç°æœ‰å†…å®¹
            content_density: å†…å®¹å¯†åº¦
            narrative_hint: ç”¨æˆ·è‡ªå®šä¹‰çš„å™äº‹æç¤ºï¼ˆå¯é€‰ï¼‰

        Returns:
            str: ç”Ÿæˆçš„å†…å®¹ï¼ˆä¿ç•™æ ¼å¼å®šä¹‰ï¼‰

        å·¥ä½œæµç¨‹ï¼š
        1. ğŸ”§ ç¡¬ç¼–ç ï¼šæå–å—ä¿æŠ¤çš„æ ¼å¼åŒºåŸŸ
        2. ğŸ§  AIï¼šåˆ†æèµ„æºç›¸å…³æ€§å¹¶é€‰æ‹©
        3. ğŸ§  AIï¼šç”Ÿæˆè¿è´¯çš„å™è¿°æ€§å†…å®¹ï¼ˆæ”¯æŒç”¨æˆ·æç¤ºï¼‰
        4. ğŸ¤ åä½œï¼šAI å†…å®¹ + ç¡¬ç¼–ç æ¨¡æ¿åŒ…è£…
        5. ğŸ§  AIï¼šè‡ªæˆ‘æ£€æŸ¥å’Œä¼˜åŒ–
        """

        # ========== é˜¶æ®µ 1ï¼šç¡¬ç¼–ç  - æå–ä¿æŠ¤åŒºåŸŸ ==========
        protected_zones = self.guard.extract_protected_zones(existing_content)

        # ========== é˜¶æ®µ 2ï¼šAI - æ™ºèƒ½èµ„æºé€‰æ‹© ==========
        relevance_scores = {}
        for resource in resources:
            score_data = self._reason_resource_relevance(resource, section_theme)
            relevance_scores[resource.path] = score_data['score']

        # æ ¹æ®å¯†åº¦çº§åˆ«é€‰æ‹©èµ„æºæ•°é‡
        k_map = {"minimal": 2, "moderate": 4, "comprehensive": 6}
        k = k_map.get(content_density, 4)

        # ç¡¬ç¼–ç ï¼šTop-K é€‰æ‹©
        selected_resources = sorted(
            resources,
            key=lambda r: relevance_scores.get(r.path, 0),
            reverse=True
        )[:k]

        # ========== é˜¶æ®µ 3ï¼šAI - ç”Ÿæˆå™è¿°æ€§å†…å®¹ ==========
        narrative = self._generate_narrative(
            selected_resources, section_theme, existing_content, narrative_hint
        )

        # ========== é˜¶æ®µ 4ï¼šåä½œ - åŒ…è£… LaTeX ä»£ç  ==========
        formatted_content = self._wrap_with_latex_code(
            narrative, selected_resources, protected_zones
        )

        # ========== é˜¶æ®µ 5ï¼šAI - è‡ªæˆ‘ä¼˜åŒ– ==========
        refined_content = self._refine_content(
            formatted_content, section_theme
        )

        # ========== é˜¶æ®µ 6ï¼šç¡¬ç¼–ç  - æœ€ç»ˆéªŒè¯ ==========
        self._validate_format_preservation(protected_zones, refined_content)

        return refined_content

    def _reason_resource_relevance(
        self,
        resource: 'ResourceInfo',
        theme: 'SectionTheme'
    ) -> Dict[str, Any]:
        """AIï¼šæ¨ç†èµ„æºç›¸å…³æ€§"""
        # è°ƒç”¨ SemanticAnalyzer
        # ...
        pass

    def _generate_narrative(
        self,
        resources: List['ResourceInfo'],
        theme: 'SectionTheme',
        context: str,
        narrative_hint: str = None
    ) -> str:
        """AIï¼šç”Ÿæˆè¿è´¯çš„å™è¿°æ€§æ–‡æœ¬"""

        # æ„å»º AI Prompt
        prompt = f"""
ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„ç§‘ç ”å†™ä½œåŠ©æ‰‹ï¼Œä¸“ç²¾äºå›½å®¶è‡ªç„¶ç§‘å­¦åŸºé‡‘ç”³è¯·ä¹¦çš„æ’°å†™ã€‚
æ ¹æ®ä»¥ä¸‹ä¿¡æ¯ï¼Œç”Ÿæˆä¸€æ®µè¿è´¯çš„ç¤ºä¾‹å†…å®¹ã€‚

## ç« èŠ‚ä¿¡æ¯
- ä¸»é¢˜ï¼š{theme.theme}
- å…³é”®æ¦‚å¿µï¼š{', '.join(theme.key_concepts)}
- å†™ä½œé£æ ¼ï¼š{theme.writing_style}
- ç›®æ ‡è¯»è€…ï¼š{theme.target_audience}

## ç”¨æˆ·å™äº‹æç¤º
{narrative_hint or "ï¼ˆæœªæä¾›ï¼ŒAI æ ¹æ®ç« èŠ‚ä¸»é¢˜è‡ªåŠ¨æ¨æ–­ï¼‰"}

## ä¸Šä¸‹æ–‡ç‰‡æ®µï¼ˆå‰ 500 å­—ï¼‰
{context[:500]}

## å¯ç”¨èµ„æº
{self._format_resources_for_prompt(resources)}

## ç”Ÿæˆè¦æ±‚
1. ç”Ÿæˆ 200-400 å­—çš„ç¤ºä¾‹æ®µè½
2. è‡ªç„¶åœ°å¼•ç”¨èµ„æºï¼Œä¸è¦ç”Ÿç¡¬å †ç Œ
3. ä½¿ç”¨æ­£å¼çš„å­¦æœ¯å†™ä½œé£æ ¼
4. **é‡è¦**ï¼šæ ¹æ®ã€ç”¨æˆ·å™äº‹æç¤ºã€‘è°ƒæ•´å†…å®¹æ–¹å‘å’Œé£æ ¼
5. **å…è®¸ç¼–é€ **ï¼šè¿™æ˜¯ç¤ºä¾‹åœºæ™¯ï¼Œå¯ä»¥æ ¹æ®æç¤ºç¼–é€ åˆç†çš„ç ”ç©¶å†…å®¹ã€æ•°æ®å’Œç»“è®º
6. åŒ…å«ä»¥ä¸‹ç»“æ„ï¼š
   - ã€å¼•å…¥å¥ã€‘å¼€ç¯‡ç‚¹é¢˜ï¼Œå¼•å‡ºæœ¬æ®µå†…å®¹
   - ã€èµ„æºæ•´åˆã€‘æœ‰æœºæ•´åˆå›¾ç‰‡ã€æ–‡çŒ®ã€ä»£ç ç­‰èµ„æº
   - ã€è¯´æ˜å¥ã€‘å¯¹èµ„æºè¿›è¡Œç®€è¦è¯´æ˜
   - ã€æ€»ç»“å¥ã€‘æ”¶æŸæœ¬æ®µï¼Œæ‰¿ä¸Šå¯ä¸‹

7. åœ¨åº”è¯¥æ’å…¥ LaTeX ä»£ç çš„åœ°æ–¹ç”¨ {{PLACEHOLDER:èµ„æºè·¯å¾„}} æ ‡è®°
   - å›¾ç‰‡ï¼š{{PLACEHOLDER:figures/xxx.jpg}}
   - æ–‡çŒ®ï¼š{{PLACEHOLDER:references:citekey}}

## è¾“å‡ºæ ¼å¼ç¤ºä¾‹
æœ¬ç ”ç©¶é‡‡ç”¨å®éªŒä¸ç†è®ºç›¸ç»“åˆçš„æ–¹æ³•ã€‚å¦‚å›¾ 1 æ‰€ç¤ºï¼Œ
{{PLACEHOLDER:figures/zzmx-115.jpg}} å±•ç¤ºäº†å®éªŒè£…ç½®çš„æ•´ä½“ç»“æ„ã€‚
æ ¹æ®æ–‡çŒ® {{PLACEHOLDER:references:zhang2023deep}} çš„ç ”ç©¶ï¼Œ
æˆ‘ä»¬åœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œäº†æ”¹è¿›ï¼Œæå‡ºäº†æ–°çš„å®éªŒæ–¹æ¡ˆã€‚

åªè¿”å›ç”Ÿæˆçš„æ–‡æœ¬ï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚
"""

        return self.llm.complete(prompt, temperature=0.8)

    def _format_resources_for_prompt(self, resources: List['ResourceInfo']) -> str:
        """æ ¼å¼åŒ–èµ„æºåˆ—è¡¨ä¾› AI ä½¿ç”¨"""
        lines = []
        for i, r in enumerate(resources, 1):
            lines.append(f"{i}. **{r.filename}** ({r.type})")
            if r.metadata:
                for key, value in r.metadata.items():
                    lines.append(f"   - {key}: {value}")
        return "\n".join(lines)

    def _wrap_with_latex_code(
        self,
        narrative: str,
        resources: List['ResourceInfo'],
        protected_zones: List['ProtectedZone']
    ) -> str:
        """ğŸ¤ åä½œç‚¹ï¼šAI å™è¿° + ç¡¬ç¼–ç  LaTeX åŒ…è£…"""

        # ğŸ”§ ç¡¬ç¼–ç ï¼šæ„å»º LaTeX ä»£ç æ˜ å°„
        latex_code_map = {}
        for resource in resources:
            if resource.type == "figure":
                latex_code_map[resource.path] = self._generate_figure_latex(resource)
            elif resource.type == "code":
                latex_code_map[resource.path] = self._generate_code_latex(resource)
            elif resource.type == "reference":
                latex_code_map[resource.path] = self._generate_reference_latex(resource)

        # ğŸ”§ ç¡¬ç¼–ç ï¼šå®‰å…¨çš„å ä½ç¬¦æ›¿æ¢
        result = narrative
        for resource_path, latex_code in latex_code_map.items():
            placeholder = f"{{{{PLACEHOLDER:{resource_path}}}}}"
            result = result.replace(placeholder, latex_code)

        # ğŸ”§ ç¡¬ç¼–ç ï¼šéªŒè¯æ ¼å¼åŒºåŸŸæœªè¢«ç ´å
        for zone in protected_zones:
            if zone.content not in result:
                raise FormatProtectionError(
                    f"ä¿æŠ¤åŒºåŸŸè¢«ç ´åï¼š{zone.name}\n"
                    f"åŸå†…å®¹ï¼š{zone.content[:50]}..."
                )

        return result

    def _generate_figure_latex(self, resource: 'ResourceInfo') -> str:
        """ç¡¬ç¼–ç ï¼šç”Ÿæˆå›¾ç‰‡ LaTeX ä»£ç """
        template = self.templates.get("figure_insertion",
            "\\begin{{figure}}[htbp]\\centering\\includegraphics[width=0.8\\textwidth]{{{path}}}\\caption{{{caption}}}\\end{{figure}}")
        return template.format(
            path=resource.path,
            caption=resource.metadata.get("caption", "ç¤ºä¾‹å›¾ç‰‡")
        )

    def _generate_code_latex(self, resource: 'ResourceInfo') -> str:
        """ç¡¬ç¼–ç ï¼šç”Ÿæˆä»£ç æ¸…å• LaTeX ä»£ç """
        # è¯»å–ä»£ç ç‰‡æ®µ
        code_snippet = read_code_snippet(resource.path, max_lines=20)

        template = self.templates.get("code_listing",
            "\\begin{{lstlisting}}[language={lang}, caption={caption}]\n{code}\n\\end{{lstlisting}}")
        return template.format(
            lang=resource.metadata.get("language", "Python"),
            code=code_snippet,
            caption=f"ç¤ºä¾‹ä»£ç ï¼š{resource.filename}"
        )

    def _generate_reference_latex(self, resource: 'ResourceInfo') -> str:
        """ç¡¬ç¼–ç ï¼šç”Ÿæˆæ–‡çŒ®å¼•ç”¨ LaTeX ä»£ç """
        citekey = resource.metadata.get("citekey", "unknown")
        return f"\\cite{{{citekey}}}"

    def _refine_content(
        self,
        content: str,
        theme: 'SectionTheme'
    ) -> str:
        """ğŸ§  AIï¼šè‡ªæˆ‘æ£€æŸ¥å’Œä¼˜åŒ–ç”Ÿæˆçš„å†…å®¹"""

        prompt = f"""
ä½ æ˜¯ä¸€ä½ä¸¥è°¨çš„å­¦æœ¯å†™ä½œè¯„å®¡ä¸“å®¶ã€‚è¯·æ£€æŸ¥ä»¥ä¸‹ç”Ÿæˆçš„ LaTeX å†…å®¹ã€‚

## ç« èŠ‚ä¸»é¢˜
{theme.theme}

## å¾…æ£€æŸ¥å†…å®¹
{content[:2000]}

## æ£€æŸ¥é¡¹
1. å™è¿°æ˜¯å¦è¿è´¯è‡ªç„¶ï¼Ÿ
2. èµ„æºå¼•ç”¨æ˜¯å¦åˆç†ï¼Ÿæ˜¯å¦ç”Ÿç¡¬ï¼Ÿ
3. æ˜¯å¦ç¬¦åˆå­¦æœ¯å†™ä½œé£æ ¼ï¼Ÿ
4. æœ‰æ— è¯­æ³•æˆ–é€»è¾‘é—®é¢˜ï¼Ÿ
5. LaTeX ä»£ç æ˜¯å¦å¯èƒ½ç ´åæ ¼å¼ï¼Ÿ

## è¾“å‡ºè¦æ±‚
- å¦‚æœå‘ç°æ˜æ˜¾é—®é¢˜ï¼Œè¿”å›ä¼˜åŒ–åçš„å®Œæ•´å†…å®¹
- å¦‚æœæ²¡æœ‰é‡å¤§é—®é¢˜ï¼Œè¿”å› "OK"
- å¦‚æœæœ‰è½»å¾®é—®é¢˜ä½†ä¸å½±å“æ•´ä½“ï¼Œè¿”å› "OK" å¹¶åœ¨æ³¨é‡Šä¸­æŒ‡å‡º

åªè¿”å›ç»“æœï¼Œä¸è¦è§£é‡Šã€‚
"""

        response = self.llm.complete(prompt, temperature=0.5)

        if response.strip() == "OK":
            return content
        else:
            # AI è¿”å›äº†ä¼˜åŒ–åçš„å†…å®¹
            return response

    def _validate_format_preservation(
        self,
        protected_zones: List['ProtectedZone'],
        new_content: str
    ):
        """ç¡¬ç¼–ç ï¼šéªŒè¯æ ¼å¼åŒºåŸŸæœªè¢«ç ´å"""
        for zone in protected_zones:
            if zone.content not in new_content:
                raise FormatProtectionError(
                    f"æ ¼å¼ä¿æŠ¤éªŒè¯å¤±è´¥ï¼š{zone.name}\n"
                    f"ä¿æŠ¤å†…å®¹ï¼š{zone.content[:50]}..."
                )
```

**AI ä»·å€¼ä½“ç°**ï¼š
- âœ… ç”Ÿæˆè‡ªç„¶è¿è´¯çš„å™è¿°ï¼Œè€Œéæ¨¡æ¿æ‹¼æ¥
- âœ… æ ¹æ®ä¸Šä¸‹æ–‡è°ƒæ•´å¼•ç”¨æ–¹å¼
- âœ… è‡ªæˆ‘å®¡æŸ¥å¹¶ä¼˜åŒ–ç”Ÿæˆå†…å®¹
- âœ… è¯†åˆ«æ½œåœ¨çš„æ ¼å¼ç ´åé£é™©

---

### 3.3 FormatGuard - ç¡¬ç¼–ç æ ¼å¼å®ˆæŠ¤å™¨

**èŒè´£**ï¼šä¸¥æ ¼ä¿æŠ¤æ ¼å¼è®¾ç½®ä¸è¢«ä¿®æ”¹

```python
# core/format_guard.py
import hashlib
import re
import shutil
from pathlib import Path
from dataclasses import dataclass
from typing import List

@dataclass
class ProtectedZone:
    """å—ä¿æŠ¤çš„æ ¼å¼åŒºåŸŸ"""
    name: str           # åŒºåŸŸåç§°
    start: int          # èµ·å§‹ä½ç½®
    end: int            # ç»“æŸä½ç½®
    content: str        # åŸå§‹å†…å®¹
    line_number: int    # è¡Œå·

class FormatProtectionError(Exception):
    """æ ¼å¼ä¿æŠ¤å¼‚å¸¸"""
    pass

class FormatGuard:
    """ç¡¬ç¼–ç ï¼šä¸¥æ ¼çš„æ ¼å¼ä¿æŠ¤æœºåˆ¶"""

    # å—ä¿æŠ¤çš„ LaTeX å‘½ä»¤ï¼ˆæ­£åˆ™æ¨¡å¼ï¼‰
    PROTECTED_PATTERNS = [
        r'\\setlength\{[^}]+\}\{[^}]+\}',           # \setlength{\parindent}{2em}
        r'\\geometry\{[^}]+\}',                      # \geometry{left=3cm,...}
        r'\\definecolor\{[^}]+\}\{[^}]+\}\{[^}]+\}', # \definecolor{MsBlue}{RGB}{...}
        r'\\setCJKfamilyfont\{[^}]+\}(\[[^]]*\])?\{[^}]+\}',  # å­—ä½“è®¾ç½®
        r'\\setmainfont(\[[^]]*\])?\{[^}]+\}',       # è‹±æ–‡å­—ä½“
        r'\\titleformat\{[^}]+\}\{[^}]*\}\{[^}]*\}\{[^}]*\}\{[^}]*\}\{[^}]*\}',  # æ ‡é¢˜æ ¼å¼
        r'\\setlist\[[^]]+\]\{[^}]+\}',             # \setlist[enumerate]{...}
        r'\\newcommand\{[^}]+\}',                    # è‡ªå®šä¹‰å‘½ä»¤
        r'\\renewcommand\{[^}]+\}',                  # é‡å®šä¹‰å‘½ä»¤
    ]

    # å—ä¿æŠ¤çš„æ–‡ä»¶ï¼ˆç»å¯¹ä¸ä¿®æ”¹ï¼‰
    PROTECTED_FILES = [
        "extraTex/@config.tex",
        "main.tex",
    ]

    def __init__(self, project_path: Path, run_dir: Path):
        """
        Args:
            project_path: é¡¹ç›®æ ¹ç›®å½•ï¼ˆè¢«ä¿æŠ¤çš„é¡¹ç›®ï¼Œä¸å†™å…¥ä»»ä½•æ–‡ä»¶ï¼‰
            run_dir: è¿è¡Œç›®å½•ï¼ˆå¤‡ä»½å’Œæ—¥å¿—æ”¾åœ¨è¿™é‡Œï¼Œéš”ç¦»é¡¹ç›®æ±¡æŸ“ï¼‰
        """
        self.project_path = Path(project_path)
        self.run_dir = Path(run_dir)  # ğŸ†• è¿è¡Œç›®å½•
        self.format_hashes = self._compute_format_hashes()

    def _compute_format_hashes(self) -> Dict[str, str]:
        """è®¡ç®—å…³é”®æ ¼å¼æ–‡ä»¶çš„å“ˆå¸Œå€¼"""
        hashes = {}
        for file_path in self.PROTECTED_FILES:
            full_path = self.project_path / file_path
            if full_path.exists():
                content = full_path.read_text(encoding="utf-8")
                # æå–æ ¼å¼å®šä¹‰è¡Œ
                format_lines = self._extract_format_lines(content)
                hashes[file_path] = hashlib.sha256(
                    "".join(format_lines).encode()
                ).hexdigest()
        return hashes

    def _extract_format_lines(self, content: str) -> List[str]:
        """æå–æ ¼å¼å®šä¹‰è¡Œ"""
        lines = content.split("\n")
        format_lines = []

        for line in lines:
            # æ£€æŸ¥æ˜¯å¦åŒ…å«å—ä¿æŠ¤çš„å‘½ä»¤
            for pattern in self.PROTECTED_PATTERNS:
                if re.search(pattern, line):
                    format_lines.append(line)
                    break

        return format_lines

    def extract_protected_zones(self, content: str) -> List[ProtectedZone]:
        """
        ğŸ”§ ç¡¬ç¼–ç ï¼šä½¿ç”¨æ­£åˆ™æå–ä¿æŠ¤åŒºåŸŸ

        Args:
            content: æ–‡ä»¶å†…å®¹

        Returns:
            List[ProtectedZone]: ä¿æŠ¤åŒºåŸŸåˆ—è¡¨
        """
        zones = []
        lines = content.split("\n")

        for line_no, line in enumerate(lines, 1):
            for pattern in self.PROTECTED_PATTERNS:
                matches = re.finditer(pattern, line)
                for match in matches:
                    zones.append(ProtectedZone(
                        name="format_definition",
                        start=match.start(),
                        end=match.end(),
                        content=match.group(0),
                        line_number=line_no
                    ))

        return zones

    def validate_format_integrity(self) -> Dict[str, bool]:
        """
        ğŸ”§ ç¡¬ç¼–ç ï¼šéªŒè¯æ ¼å¼æœªè¢«ç¯¡æ”¹

        Returns:
            Dict: {æ–‡ä»¶è·¯å¾„: æ˜¯å¦å®Œæ•´}
        """
        results = {}
        current_hashes = self._compute_format_hashes()

        for file_path, original_hash in self.format_hashes.items():
            current_hash = current_hashes.get(file_path)
            results[file_path] = (current_hash == original_hash)

        return results

    def safe_modify_file(
        self,
        file_path: Path,
        new_content: str,
        ai_explanation: str = None
    ) -> bool:
        """
        ğŸ¤ åä½œç‚¹ï¼šAI å»ºè®®ä¿®æ”¹ + ç¡¬ç¼–ç å®‰å…¨æ£€æŸ¥

        Args:
            file_path: è¦ä¿®æ”¹çš„æ–‡ä»¶è·¯å¾„
            new_content: æ–°å†…å®¹
            ai_explanation: AI å¯¹ä¿®æ”¹çš„è§£é‡Š

        Returns:
            bool: æ˜¯å¦æˆåŠŸä¿®æ”¹

        Raises:
            FormatProtectionError: æ ¼å¼ä¿æŠ¤å¤±è´¥
            CompilationError: ç¼–è¯‘å¤±è´¥
        """
        file_path = Path(file_path)

        # æ£€æŸ¥æ˜¯å¦ä¸ºå—ä¿æŠ¤æ–‡ä»¶
        relative_path = str(file_path.relative_to(self.project_path))
        if relative_path in self.PROTECTED_FILES:
            raise FormatProtectionError(
                f"æ‹’ç»ä¿®æ”¹å—ä¿æŠ¤æ–‡ä»¶ï¼š{relative_path}\n"
                f"AI è§£é‡Šï¼š{ai_explanation or 'æœªæä¾›'}"
            )

        # ========== é˜¶æ®µ 1ï¼šç¡¬ç¼–ç  - å¤‡ä»½ ==========
        # ğŸ†• å¤‡ä»½åˆ° runs/<run_id>/backups/ è€Œéé¡¹ç›®ç›®å½•
        backup_dir = self.run_dir / "backups"
        backup_filename = f"{relative_path.replace('/', '_')}.backup"
        backup_path = backup_dir / backup_filename
        backup_path.parent.mkdir(parents=True, exist_ok=True)
        shutil.copy(file_path, backup_path)

        # ========== é˜¶æ®µ 2ï¼šç¡¬ç¼–ç  - æ£€æŸ¥æ ¼å¼åŒºåŸŸ ==========
        old_content = file_path.read_text(encoding="utf-8")
        protected_zones = self.extract_protected_zones(old_content)

        for zone in protected_zones:
            if zone.content not in new_content:
                # ğŸ§  AIï¼šå°è¯•è¯Šæ–­
                diagnosis = self._ai_diagnose_format_loss(
                    zone, old_content, new_content
                )

                # ğŸ§  AIï¼šå°è¯•ä¿®å¤
                fixed_content = self._ai_attempt_fix(
                    new_content, zone, diagnosis
                )

                # å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œå›æ»š
                if zone.content not in fixed_content:
                    shutil.copy(backup_path, file_path)
                    raise FormatProtectionError(
                        f"æ ¼å¼ä¿æŠ¤å¤±è´¥ï¼Œå·²å›æ»š\n"
                        f"ç ´ååŒºåŸŸï¼š{zone.name} (ç¬¬ {zone.line_number} è¡Œ)\n"
                        f"åŸå†…å®¹ï¼š{zone.content}\n"
                        f"AI è¯Šæ–­ï¼š{diagnosis}\n"
                        f"AI è§£é‡Šï¼š{ai_explanation or 'æœªæä¾›'}"
                    )
                else:
                    new_content = fixed_content

        # ========== é˜¶æ®µ 3ï¼šç¡¬ç¼–ç  - åº”ç”¨ä¿®æ”¹ ==========
        file_path.write_text(new_content, encoding="utf-8")

        # ========== é˜¶æ®µ 4ï¼šç¡¬ç¼–ç  - ç¼–è¯‘éªŒè¯ ==========
        if not self._compile_verify(file_path):
            shutil.copy(backup_path, file_path)
            raise CompilationError(
                "ç¼–è¯‘å¤±è´¥ï¼Œå·²å›æ»š\n"
                f"ä¿®æ”¹çš„æ–‡ä»¶ï¼š{file_path}\n"
                f"AI è§£é‡Šï¼š{ai_explanation or 'æœªæä¾›'}"
            )

        # ========== é˜¶æ®µ 5ï¼šæˆåŠŸï¼Œè®°å½• ==========
        self._log_modification(
            file_path, backup_path, ai_explanation
        )

        return True

    def _ai_diagnose_format_loss(
        self,
        zone: ProtectedZone,
        old_content: str,
        new_content: str
    ) -> str:
        """ğŸ§  AIï¼šè¯Šæ–­æ ¼å¼ä¸¢å¤±çš„åŸå› """
        # è¿™é‡Œå¯ä»¥è°ƒç”¨ AI åˆ†æä¸ºä»€ä¹ˆæ ¼å¼è¢«ç ´å
        # ç®€åŒ–ç‰ˆæœ¬ï¼šè¿”å›ç¡¬ç¼–ç çš„è¯Šæ–­
        return f"æ ¼å¼å®šä¹‰ '{zone.content[:30]}...' åœ¨æ–°å†…å®¹ä¸­æœªæ‰¾åˆ°"

    def _ai_attempt_fix(
        self,
        new_content: str,
        zone: ProtectedZone,
        diagnosis: str
    ) -> str:
        """ğŸ§  AIï¼šå°è¯•ä¿®å¤æ ¼å¼ä¸¢å¤±"""
        # ç®€åŒ–ç‰ˆæœ¬ï¼šç›´æ¥æ’å…¥åŸæ ¼å¼
        # å®é™…ç‰ˆæœ¬å¯ä»¥è®© AI åˆ†æä¸Šä¸‹æ–‡å¹¶æ™ºèƒ½æ’å…¥
        return new_content  # ä¸åšä¿®æ”¹ï¼Œè®©å¤–éƒ¨å¤„ç†

    def _compile_verify(self, modified_file: Path = None) -> bool:
        """ç¡¬ç¼–ç ï¼šç¼–è¯‘éªŒè¯"""
        # æ‰§è¡Œ xelatex ç¼–è¯‘
        project_root = self.project_path
        main_tex = project_root / "main.tex"

        result = subprocess.run(
            ["xelatex", "-interaction=nonstopmode", "main.tex"],
            cwd=project_root,
            capture_output=True,
            timeout=60
        )

        return result.returncode == 0

    def _log_modification(
        self,
        file_path: Path,
        backup_path: Path,
        ai_explanation: str
    ):
        """ğŸ†• è®°å½•ä¿®æ”¹æ—¥å¿—åˆ° runs/<run_id>/logs/"""
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "file": str(file_path),
            "backup": str(backup_path),
            "ai_explanation": ai_explanation or "æœªæä¾›"
        }
        # ğŸ†• å†™å…¥ runs/<run_id>/logs/execution.log è€Œéé¡¹ç›®ç›®å½•
        log_file = self.run_dir / "logs" / "execution.log"
        log_file.parent.mkdir(parents=True, exist_ok=True)
        with open(log_file, "a", encoding="utf-8") as f:
            f.write(json.dumps(log_entry, ensure_ascii=False) + "\n")
```

**ç¡¬ç¼–ç ä»·å€¼ä½“ç°**ï¼š
- âœ… ç»å¯¹ä¿æŠ¤å…³é”®æ ¼å¼æ–‡ä»¶
- âœ… å“ˆå¸ŒéªŒè¯é˜²ç¯¡æ”¹
- âœ… è‡ªåŠ¨å¤‡ä»½ä¸å›æ»š
- âœ… ç¼–è¯‘éªŒè¯ç¡®ä¿å¯ç”¨æ€§

---

### 3.4 ResourceScanner - èµ„æºæ‰«æå™¨

**èŒè´£**ï¼šæ‰«æé¡¹ç›®ä¸­çš„æ‰€æœ‰å¯ç”¨èµ„æºï¼ˆçº¯ç¡¬ç¼–ç ï¼‰

```python
# core/resource_scanner.py
from pathlib import Path
from dataclasses import dataclass
from typing import List, Dict, Any
from PIL import Image

@dataclass
class ResourceInfo:
    """èµ„æºä¿¡æ¯"""
    path: str               # ç›¸å¯¹è·¯å¾„
    type: str              # figure/code/reference
    filename: str          # æ–‡ä»¶å
    metadata: Dict[str, Any]  # å…ƒæ•°æ®

@dataclass
class ResourceReport:
    """èµ„æºæ‰«ææŠ¥å‘Š"""
    figures: List[ResourceInfo]
    code: List[ResourceInfo]
    references: List[ResourceInfo]
    summary: Dict[str, int]

class ResourceScanner:
    """ğŸ”§ ç¡¬ç¼–ç ï¼šèµ„æºæ‰«æå™¨ï¼ˆçº¯æœºæ¢°æ“ä½œï¼‰"""

    def __init__(self, project_path: Path):
        self.project_path = Path(project_path)

    def scan_figures(self) -> List[ResourceInfo]:
        """
        æ‰«æ figures/ ç›®å½•

        Returns:
            List[ResourceInfo]: å›¾ç‰‡åˆ—è¡¨
        """
        figures_dir = self.project_path / "figures"
        if not figures_dir.exists():
            return []

        figures = []
        image_extensions = {'.jpg', '.jpeg', '.png', '.pdf', '.eps'}

        for file_path in figures_dir.iterdir():
            if file_path.suffix.lower() not in image_extensions:
                continue

            # æå–å›¾ç‰‡å…ƒæ•°æ®
            metadata = self._extract_image_metadata(file_path)

            figures.append(ResourceInfo(
                path=str(file_path.relative_to(self.project_path)),
                type="figure",
                filename=file_path.name,
                metadata=metadata
            ))

        return figures

    def _extract_image_metadata(self, file_path: Path) -> Dict[str, Any]:
        """æå–å›¾ç‰‡å…ƒæ•°æ®"""
        metadata = {"filename": file_path.name}

        try:
            with Image.open(file_path) as img:
                metadata["width"] = img.width
                metadata["height"] = img.height
                metadata["format"] = img.format
                metadata["mode"] = img.mode
        except Exception as e:
            metadata["error"] = str(e)

        return metadata

    def scan_code(self) -> List[ResourceInfo]:
        """æ‰«æ code/ ç›®å½•"""
        code_dir = self.project_path / "code"
        if not code_dir.exists():
            return []

        code_files = []
        code_extensions = {
            '.py': 'Python',
            '.m': 'MATLAB',
            '.r': 'R',
            '.cpp': 'C++',
            '.c': 'C',
            '.java': 'Java',
        }

        for file_path in code_dir.iterdir():
            if file_path.suffix.lower() not in code_extensions:
                continue

            # ç»Ÿè®¡è¡Œæ•°
            line_count = count_lines(file_path)

            code_files.append(ResourceInfo(
                path=str(file_path.relative_to(self.project_path)),
                type="code",
                filename=file_path.name,
                metadata={
                    "language": code_extensions[file_path.suffix.lower()],
                    "lines": line_count
                }
            ))

        return code_files

    def scan_references(self) -> List[ResourceInfo]:
        """æ‰«æ references/ ç›®å½•"""
        refs_dir = self.project_path / "references"
        if not refs_dir.exists():
            return []

        references = []
        bib_files = list(refs_dir.glob("*.bib"))

        for bib_file in bib_files:
            # è§£æ BibTeX
            entries = parse_bibtex(bib_file)

            for entry in entries:
                references.append(ResourceInfo(
                    path=f"references/{bib_file.name}",
                    type="reference",
                    filename=entry.get("key", "unknown"),
                    metadata={
                        "citekey": entry.get("key", ""),
                        "authors": entry.get("author", ""),
                        "year": entry.get("year", ""),
                        "title": entry.get("title", ""),
                        "journal": entry.get("journal", "")
                    }
                ))

        return references

    def scan_all(self) -> ResourceReport:
        """æ‰«ææ‰€æœ‰èµ„æº"""
        figures = self.scan_figures()
        code = self.scan_code()
        refs = self.scan_references()

        return ResourceReport(
            figures=figures,
            code=code,
            references=refs,
            summary={
                "total_figures": len(figures),
                "total_code": len(code),
                "total_references": len(refs)
            }
        )
```

---

## 4. AI ä¸ç¡¬ç¼–ç èŒè´£åˆ†å·¥

### 4.1 èŒè´£å¯¹ç…§è¡¨

| ä»»åŠ¡ç±»å‹ | AI è´Ÿè´£ | ç¡¬ç¼–ç è´Ÿè´£ | åä½œæ–¹å¼ |
|---------|--------|-----------|----------|
| **æ–‡ä»¶æ‰«æ** | - | âœ… æ–‡ä»¶ç³»ç»Ÿæ“ä½œã€å…ƒæ•°æ®æå– | - |
| **è¯­ä¹‰åˆ†æ** | âœ… ç« èŠ‚ä¸»é¢˜ç†è§£ã€å…³é”®æ¦‚å¿µæå– | - | AI è¾“å‡º â†’ ç¡¬ç¼–ç ç»“æ„åŒ– |
| **èµ„æºé€‰æ‹©** | âœ… æ¨ç†ç›¸å…³æ€§ã€ç»™å‡ºç†ç”± | âœ… è¯„åˆ†æ’åºã€Top-K é€‰æ‹© | AI è¯„åˆ† â†’ ç¡¬ç¼–ç ç­›é€‰ |
| **æ–‡æœ¬ç”Ÿæˆ** | âœ… å™è¿°æ€§å†…å®¹ç”Ÿæˆ | - | AI ç”ŸæˆåŸå§‹æ–‡æœ¬ |
| **LaTeX åŒ…è£…** | - | âœ… è¯­æ³•æ­£ç¡®æ€§ã€æ ¼å¼è§„èŒƒ | ç¡¬ç¼–ç åŒ…è£… AI æ–‡æœ¬ |
| **æ ¼å¼ä¿æŠ¤** | âœ… è§£é‡Šä¿®æ”¹æ„å›¾ã€è¯Šæ–­é—®é¢˜ | âœ… ä¸¥æ ¼éªŒè¯ã€å“ˆå¸Œæ ¡éªŒ | AI è§£é‡Š â†’ ç¡¬ç¼–ç æ£€æŸ¥ |
| **ç¼–è¯‘éªŒè¯** | - | âœ… æ‰§è¡Œç¼–è¯‘ã€é”™è¯¯æ£€æµ‹ | - |
| **è´¨é‡æ£€æŸ¥** | âœ… è¿è´¯æ€§ã€å­¦æœ¯é£æ ¼æ£€æŸ¥ | âœ… è¯­æ³•æ£€æŸ¥ã€æ ¼å¼éªŒè¯ | AI å®¡æŸ¥ + ç¡¬ç¼–ç  Lint |
| **é”™è¯¯ä¿®å¤** | âœ… è¯Šæ–­é—®é¢˜ã€å»ºè®®ä¿®å¤ | âœ… åº”ç”¨ä¿®å¤ã€éªŒè¯ | AI å»ºè®® â†’ ç¡¬ç¼–ç æ‰§è¡Œ |

### 4.2 æ•°æ®æµè½¬å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ç”¨æˆ·è¾“å…¥     â”‚
â”‚ (project,    â”‚
â”‚  density)    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ResourceScan  â”‚ ğŸ”§ ç¡¬ç¼–ç ï¼šæ‰«ææ–‡ä»¶ç³»ç»Ÿ
â”‚(èµ„æºå‘ç°)     â”‚ â†’ figures, code, references
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚SemanticAnaly â”‚ ğŸ§  AIï¼šåˆ†æç« èŠ‚ä¸»é¢˜
â”‚(ä¸»é¢˜ç†è§£)     â”‚ â†’ theme, key_concepts, style
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚SemanticAnaly â”‚ ğŸ§  AIï¼šæ¨ç†èµ„æºç›¸å…³æ€§
â”‚+ ResourceScanâ”‚ â†’ relevance_scores, reasons
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Top-K Select  â”‚ ğŸ”§ ç¡¬ç¼–ç ï¼šé€‰æ‹© Top-K
â”‚(èµ„æºç­›é€‰)     â”‚ â†’ selected_resources
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚AIContentGen  â”‚ ğŸ§  AIï¼šç”Ÿæˆå™è¿°æ€§æ–‡æœ¬
â”‚(å™è¿°ç”Ÿæˆ)     â”‚ â†’ narrative (with placeholders)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚TemplateWrap  â”‚ ğŸ”§ ç¡¬ç¼–ç ï¼šåŒ…è£… LaTeX
â”‚(LaTeXåŒ…è£…)   â”‚ â†’ formatted_content
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚AI Refine     â”‚ ğŸ§  AIï¼šè‡ªæˆ‘ä¼˜åŒ–
â”‚(è´¨é‡ä¼˜åŒ–)     â”‚ â†’ refined_content
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚FormatGuard   â”‚ ğŸ”§ ç¡¬ç¼–ç ï¼šæ ¼å¼éªŒè¯
â”‚(æ ¼å¼ä¿æŠ¤)     â”‚ â†’ validate, backup, apply
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Compile Check â”‚ ğŸ”§ ç¡¬ç¼–ç ï¼šç¼–è¯‘éªŒè¯
â”‚(ç¼–è¯‘éªŒè¯)     â”‚ â†’ success / rollback
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Quality Reportâ”‚ ğŸ§  AIï¼šè´¨é‡è¯„ä¼°
â”‚(è´¨é‡æŠ¥å‘Š)     â”‚ â†’ scores, suggestions
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 5. å®Œæ•´å·¥ä½œæµè®¾è®¡

### 5.1 ä¸»å·¥ä½œæµ

```python
# complete_example_skill.py
import uuid
from datetime import datetime
from pathlib import Path

class CompleteExampleSkill:
    """AI å¢å¼ºç‰ˆç¤ºä¾‹ç”Ÿæˆå™¨ä¸»æ§åˆ¶å™¨"""

    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.skill_root = Path(config.get("skill_root", "skills/complete_example"))
        self.runs_dir = self.skill_root / "runs"
        self.llm_client = self._init_llm_client()
        self.templates = self._load_templates()

    def _create_run_directory(self) -> Path:
        """ğŸ†• åˆ›å»ºæ–°çš„è¿è¡Œç›®å½•"""
        # ç”Ÿæˆå”¯ä¸€è¿è¡Œ ID
        run_id = f"{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:8]}"
        run_dir = self.runs_dir / run_id

        # åˆ›å»ºå­ç›®å½•
        (run_dir / "backups").mkdir(parents=True, exist_ok=True)
        (run_dir / "logs").mkdir(parents=True, exist_ok=True)
        (run_dir / "analysis").mkdir(parents=True, exist_ok=True)
        (run_dir / "output" / "preview").mkdir(parents=True, exist_ok=True)
        (run_dir / "output" / "applied").mkdir(parents=True, exist_ok=True)
        (run_dir / "output" / "report").mkdir(parents=True, exist_ok=True)

        # æ›´æ–° latest è½¯é“¾æ¥
        latest_link = self.runs_dir / "latest"
        if latest_link.exists():
            latest_link.unlink()
        try:
            latest_link.symlink_to(run_id)
        except OSError:
            # Windows å¯èƒ½éœ€è¦ç®¡ç†å‘˜æƒé™åˆ›å»ºè½¯é“¾æ¥
            pass

        # å†™å…¥å…ƒæ•°æ®
        metadata = {
            "run_id": run_id,
            "timestamp": datetime.now().isoformat(),
            "config": self.config
        }
        (run_dir / "metadata.json").write_text(
            json.dumps(metadata, ensure_ascii=False, indent=2),
            encoding="utf-8"
        )

        return run_dir

    def execute(self, project_name: str, options: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®Œæ•´çš„ç¤ºä¾‹ç”Ÿæˆæµç¨‹

        Args:
            project_name: é¡¹ç›®åç§°
            options: é€‰é¡¹ {
                content_density: "minimal" | "moderate" | "comprehensive",
                output_mode: "preview" | "apply" | "report",
                target_files: ["1.2.å†…å®¹ç›®æ ‡é—®é¢˜.tex", ...],
                narrative_hint: "ç”¨æˆ·è‡ªå®šä¹‰çš„å™äº‹æç¤ºï¼ˆå¯é€‰ï¼‰"
            }

        Returns:
            Dict: æ‰§è¡Œç»“æœæŠ¥å‘Š
        """

        # ========== é˜¶æ®µ 0ï¼šåˆå§‹åŒ– ==========
        # ğŸ†• åˆ›å»ºè¿è¡Œç›®å½•ï¼ˆæ‰€æœ‰è¾“å‡ºéƒ½æ”¾åœ¨è¿™é‡Œï¼Œä¸æ±¡æŸ“é¡¹ç›®ï¼‰
        run_dir = self._create_run_directory()

        project_path = Path("projects") / project_name
        report = {
            "project": project_name,
            "run_id": run_dir.name,  # ğŸ†• è®°å½•è¿è¡Œ ID
            "run_dir": str(run_dir),  # ğŸ†• è®°å½•è¿è¡Œç›®å½•
            "stages": {},
            "final_result": None
        }

        try:
            # ========== é˜¶æ®µ 1ï¼šèµ„æºæ‰«æï¼ˆç¡¬ç¼–ç ï¼‰ ==========
            report["stages"]["scan"] = self._stage_scan_resources(project_path)

            # ========== é˜¶æ®µ 2ï¼šè¯­ä¹‰åˆ†æï¼ˆAIï¼‰ ==========
            report["stages"]["analyze"] = self._stage_analyze_sections(
                project_path, options.get("target_files"), run_dir  # ğŸ†• ä¼ é€’ run_dir
            )

            # ========== é˜¶æ®µ 3ï¼šå†…å®¹ç”Ÿæˆï¼ˆAI + ç¡¬ç¼–ç ï¼‰ ==========
            report["stages"]["generate"] = self._stage_generate_content(
                project_path,
                report["stages"]["scan"]["resources"],
                report["stages"]["analyze"]["themes"],
                options.get("content_density", "moderate"),
                options.get("narrative_hint"),  # ä¼ é€’ç”¨æˆ·æç¤º
                run_dir  # ğŸ†• ä¼ é€’ run_dir
            )

            # ========== é˜¶æ®µ 4ï¼šåº”ç”¨å˜æ›´ï¼ˆç¡¬ç¼–ç ä¿æŠ¤ + AI è§£é‡Šï¼‰ ==========
            if options.get("output_mode") == "apply":
                report["stages"]["apply"] = self._stage_apply_changes(
                    project_path,
                    report["stages"]["generate"]["contents"]
                )

            # ========== é˜¶æ®µ 5ï¼šè´¨é‡è¯„ä¼°ï¼ˆAIï¼‰ ==========
            report["stages"]["quality"] = self._stage_evaluate_quality(
                report["stages"]["generate"]["contents"]
            )

            report["final_result"] = "success"

        except Exception as e:
            report["final_result"] = "failed"
            report["error"] = str(e)

        return report

    def _stage_scan_resources(self, project_path: Path) -> Dict:
        """é˜¶æ®µ 1ï¼šæ‰«æèµ„æº"""
        scanner = ResourceScanner(project_path)
        resources = scanner.scan_all()

        return {
            "status": "completed",
            "resources": resources,
            "summary": {
                "figures": len(resources.figures),
                "code": len(resources.code),
                "references": len(resources.references)
            }
        }

    def _stage_analyze_sections(
        self,
        project_path: Path,
        target_files: List[str] = None,
        run_dir: Path = None  # ğŸ†•
    ) -> Dict:
        """é˜¶æ®µ 2ï¼šåˆ†æç« èŠ‚ä¸»é¢˜"""
        analyzer = SemanticAnalyzer(self.llm_client)
        themes = {}

        # é»˜è®¤ç›®æ ‡æ–‡ä»¶
        if target_files is None:
            target_files = [
                "extraTex/1.2.å†…å®¹ç›®æ ‡é—®é¢˜.tex",
                "extraTex/1.4.ç‰¹è‰²ä¸åˆ›æ–°.tex",
                "extraTex/1.5.ç ”ç©¶è®¡åˆ’.tex"
            ]

        for file_path in target_files:
            full_path = project_path / file_path
            if not full_path.exists():
                continue

            content = full_path.read_text(encoding="utf-8")
            theme = analyzer.analyze_section_theme(content)
            themes[file_path] = theme

        # ğŸ†• ä¿å­˜åˆ†æç»“æœåˆ° runs/<run_id>/analysis/
        if run_dir:
            analysis_file = run_dir / "analysis" / "section_themes.json"
            analysis_file.parent.mkdir(parents=True, exist_ok=True)
            themes_dict = {
                k: {
                    "theme": v.theme,
                    "key_concepts": v.key_concepts,
                    "writing_style": v.writing_style
                }
                for k, v in themes.items()
            }
            analysis_file.write_text(
                json.dumps(themes_dict, ensure_ascii=False, indent=2),
                encoding="utf-8"
            )

        return {
            "status": "completed",
            "themes": themes
        }

    def _stage_generate_content(
        self,
        project_path: Path,
        resources: 'ResourceReport',
        themes: Dict[str, 'SectionTheme'],
        density: str,
        narrative_hint: str = None,
        run_dir: Path = None  # ğŸ†•
    ) -> Dict:
        """é˜¶æ®µ 3ï¼šç”Ÿæˆå†…å®¹"""
        generator = AIContentGenerator(
            self.llm_client,
            self.templates,
            FormatGuard(project_path, run_dir)  # ğŸ†• ä¼ é€’ run_dir
        )

        contents = {}
        all_resources = (
            resources.figures +
            resources.code +
            resources.references
        )

        for file_path, theme in themes.items():
            full_path = project_path / file_path
            existing_content = full_path.read_text(encoding="utf-8")

            # ç”Ÿæˆå†…å®¹ï¼ˆä¼ é€’ç”¨æˆ·æç¤ºï¼‰
            new_content = generator.generate_section_content(
                resources=all_resources,
                section_theme=theme,
                existing_content=existing_content,
                content_density=density,
                narrative_hint=narrative_hint  # ä¼ é€’ç”¨æˆ·æç¤º
            )

            contents[file_path] = {
                "old_content": existing_content,
                "new_content": new_content,
                "theme": theme
            }

        return {
            "status": "completed",
            "contents": contents
        }

    def _stage_apply_changes(
        self,
        project_path: Path,
        contents: Dict
    ) -> Dict:
        """é˜¶æ®µ 4ï¼šåº”ç”¨å˜æ›´"""
        guard = FormatGuard(project_path)
        results = {}

        for file_path, content_data in contents.items():
            try:
                full_path = project_path / file_path
                success = guard.safe_modify_file(
                    file_path=full_path,
                    new_content=content_data["new_content"],
                    ai_explanation=f"æ ¹æ®ä¸»é¢˜ '{content_data['theme'].theme}' ç”Ÿæˆç¤ºä¾‹å†…å®¹"
                )
                results[file_path] = {"status": "applied" if success else "failed"}
            except Exception as e:
                results[file_path] = {"status": "failed", "error": str(e)}

        return {
            "status": "completed",
            "results": results
        }

    def _stage_evaluate_quality(self, contents: Dict) -> Dict:
        """é˜¶æ®µ 5ï¼šè´¨é‡è¯„ä¼°"""
        analyzer = SemanticAnalyzer(self.llm_client)
        evaluations = {}

        for file_path, content_data in contents.items():
            evaluation = analyzer.evaluate_content_quality(
                content_data["new_content"],
                content_data["theme"]
            )
            evaluations[file_path] = evaluation

        return {
            "status": "completed",
            "evaluations": evaluations
        }
```

### 5.2 æ‰§è¡Œç¤ºä¾‹

#### ç¤ºä¾‹ 1ï¼šåŸºæœ¬ä½¿ç”¨ï¼ˆAI è‡ªåŠ¨æ¨æ–­ï¼‰

**ç”¨æˆ·è°ƒç”¨**ï¼š
```python
skill = CompleteExampleSkill(config)
result = skill.execute(
    project_name="NSFC_Young",
    options={
        "content_density": "moderate",
        "output_mode": "preview",
        "target_files": ["extraTex/1.2.å†…å®¹ç›®æ ‡é—®é¢˜.tex"]
    }
)
```

#### ç¤ºä¾‹ 2ï¼šä½¿ç”¨ç”¨æˆ·æç¤ºï¼ˆè‡ªå®šä¹‰å™äº‹æ–¹å‘ï¼‰

**åœºæ™¯**ï¼šç”Ÿæˆä¸€ä¸ªå…³äºæ·±åº¦å­¦ä¹ åœ¨åŒ»ç–—å½±åƒåˆ†æä¸­åº”ç”¨çš„ç¤ºä¾‹

```python
skill = CompleteExampleSkill(config)
result = skill.execute(
    project_name="NSFC_Young",
    options={
        "content_density": "moderate",
        "output_mode": "preview",
        "target_files": ["extraTex/1.2.å†…å®¹ç›®æ ‡é—®é¢˜.tex"],
        "narrative_hint": "ç”Ÿæˆä¸€ä¸ªå…³äºæ·±åº¦å­¦ä¹ åœ¨åŒ»ç–—å½±åƒåˆ†æä¸­åº”ç”¨çš„ç¤ºä¾‹ï¼Œé‡ç‚¹å…³æ³¨ CNN æ¶æ„å’Œæ•°æ®å¢å¼ºç­–ç•¥"
    }
)
```

**AI ç”Ÿæˆå†…å®¹ç¤ºä¾‹**ï¼ˆåŸºäºç”¨æˆ·æç¤ºï¼‰ï¼š
```
æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºæ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œçš„åŒ»å­¦å½±åƒè¯Šæ–­æ–¹æ³•ã€‚
å¦‚å›¾ 1 æ‰€ç¤ºï¼Œ{PLACEHOLDER:figures/zzmx-115.jpg} å±•ç¤ºäº†
æ‰€æå‡ºçš„ CNN æ¶æ„ï¼ŒåŒ…å« 5 ä¸ªå·ç§¯å±‚å’Œ 3 ä¸ªå…¨è¿æ¥å±‚ã€‚
ä¸ºäº†è§£å†³åŒ»ç–—æ•°æ®æ ‡æ³¨ä¸è¶³çš„é—®é¢˜ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†æ•°æ®å¢å¼ºç­–ç•¥ï¼Œ
åŒ…æ‹¬æ—‹è½¬ã€ç¿»è½¬å’Œå¼ºåº¦å˜æ¢ç­‰æ–¹æ³•ã€‚
æ ¹æ®æ–‡çŒ® {PLACEHOLDER:references:zhang2023deep} çš„ç ”ç©¶ï¼Œ
æˆ‘ä»¬çš„æ–¹æ³•åœ¨è‚ºç»“èŠ‚æ£€æµ‹ä»»åŠ¡ä¸Šå–å¾—äº†æ›´å¥½çš„æ€§èƒ½ã€‚
```

#### ç¤ºä¾‹ 3ï¼šææ–™ç§‘å­¦åœºæ™¯

```python
result = skill.execute(
    project_name="NSFC_Young",
    options={
        "narrative_hint": "åˆ›å»ºä¸€ä¸ªå…³äºæ–°å‹çº³ç±³ææ–™åˆæˆä¸è¡¨å¾çš„ç¤ºä¾‹ï¼ŒåŒ…æ‹¬ XRDã€SEM ç­‰è¡¨å¾æ–¹æ³•"
    }
)
```

#### ç¤ºä¾‹ 4ï¼šä¸´åºŠè¯•éªŒåœºæ™¯

```python
result = skill.execute(
    project_name="NSFC_Young",
    options={
        "narrative_hint": "æ¨¡æ‹Ÿä¸€ä¸ªå¤šä¸­å¿ƒä¸´åºŠè¯•éªŒçš„è®¾è®¡ä¸åˆ†ææµç¨‹ï¼Œé‡ç‚¹æè¿°éšæœºåŒ–å’Œç›²æ³•å®æ–½"
    }
)
```

**æ‰§è¡Œæµç¨‹**ï¼ˆå¸¦ç”¨æˆ·æç¤ºï¼‰ï¼š
```
1. ğŸ” æ‰«æé˜¶æ®µ
   - å‘ç° 2 å¼ å›¾ç‰‡
   - å‘ç° 0 ä¸ªä»£ç æ–‡ä»¶
   - å‘ç° 15 æ¡æ–‡çŒ®

2. ğŸ§  åˆ†æé˜¶æ®µ
   - åˆ†æç« èŠ‚ä¸»é¢˜ï¼š"ç ”ç©¶å†…å®¹ã€ç›®æ ‡ä¸å…³é”®ç§‘å­¦é—®é¢˜"
   - å…³é”®æ¦‚å¿µï¼š["ç†è®ºæ¡†æ¶", "æ¨¡å‹æ„å»º", "å®éªŒéªŒè¯"]
   - å†™ä½œé£æ ¼ï¼šå­¦æœ¯

3. ğŸ’¡ æ¨ç†é˜¶æ®µ
   - figures/zzmx-115.jpg â†’ ç›¸å…³æ€§ 0.85ï¼ˆé«˜ï¼‰
   - figures/zzmx-mobile-105.jpg â†’ ç›¸å…³æ€§ 0.72ï¼ˆä¸­ï¼‰
   - references:zhang2023deep â†’ ç›¸å…³æ€§ 0.91ï¼ˆé«˜ï¼‰

4. âœï¸ ç”Ÿæˆé˜¶æ®µï¼ˆğŸ†• æ”¯æŒç”¨æˆ·æç¤ºï¼‰
   - ç”¨æˆ·æç¤ºï¼š"ç”Ÿæˆä¸€ä¸ªå…³äºæ·±åº¦å­¦ä¹ åœ¨åŒ»ç–—å½±åƒåˆ†æä¸­åº”ç”¨çš„ç¤ºä¾‹"
   - AI ç”Ÿæˆå™è¿°ï¼š
     "æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºæ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œçš„åŒ»å­¦å½±åƒè¯Šæ–­æ–¹æ³•ã€‚
      å¦‚å›¾ 1 æ‰€ç¤ºï¼Œ{PLACEHOLDER:figures/zzmx-115.jpg} å±•ç¤ºäº†
      æ‰€æå‡ºçš„ CNN æ¶æ„..."
   - **å…³é”®**ï¼šAI æ ¹æ®ç”¨æˆ·æç¤ºè°ƒæ•´äº†å†…å®¹æ–¹å‘å’Œé£æ ¼

5. ğŸ¨ åŒ…è£…é˜¶æ®µ
   - ç¡¬ç¼–ç åŒ…è£…ä¸º LaTeX ä»£ç 

6. ğŸ” ä¼˜åŒ–é˜¶æ®µ
   - AI è‡ªæˆ‘å®¡æŸ¥ï¼šè¿è´¯æ€§ 0.92ï¼Œå­¦æœ¯é£æ ¼ 0.88
   - è¾“å‡ºä¼˜åŒ–åçš„å†…å®¹

7. âœ… éªŒè¯é˜¶æ®µ
   - æ ¼å¼éªŒè¯é€šè¿‡
   - ç¼–è¯‘éªŒè¯é€šè¿‡

8. ğŸ“Š æŠ¥å‘Šé˜¶æ®µ
   - ç”Ÿæˆè´¨é‡æŠ¥å‘Š
```

---

## 6. ç›®å½•ç»“æ„

```
skills/complete_example/
â”œâ”€â”€ SKILL.md                        # Skill å®šä¹‰æ–‡æ¡£
â”œâ”€â”€ config.yaml                     # é…ç½®æ–‡ä»¶
â”œâ”€â”€ README.md                       # ä½¿ç”¨è¯´æ˜
â”‚
â”œâ”€â”€ core/                           # æ ¸å¿ƒæ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ skill_controller.py         # ä¸»æ§åˆ¶å™¨
â”‚   â”œâ”€â”€ semantic_analyzer.py        # AI è¯­ä¹‰åˆ†æå™¨
â”‚   â”œâ”€â”€ ai_content_generator.py     # AI å†…å®¹ç”Ÿæˆå™¨
â”‚   â”œâ”€â”€ resource_scanner.py         # èµ„æºæ‰«æå™¨
â”‚   â””â”€â”€ format_guard.py             # æ ¼å¼å®ˆæŠ¤å™¨
â”‚
â”œâ”€â”€ templates/                      # å†…å®¹æ¨¡æ¿ï¼ˆç¡¬ç¼–ç ï¼‰
â”‚   â”œâ”€â”€ figure_insertion.jinja2
â”‚   â”œâ”€â”€ code_listing.jinja2
â”‚   â””â”€â”€ reference_example.jinja2
â”‚
â”œâ”€â”€ scripts/                        # åŠŸèƒ½è„šæœ¬
â”‚   â”œâ”€â”€ scan_resources.py           # æ‰«æé¡¹ç›®èµ„æº
â”‚   â”œâ”€â”€ generate_example.py         # ç”Ÿæˆç¤ºä¾‹å†…å®¹
â”‚   â”œâ”€â”€ validate_format.py          # éªŒè¯æ ¼å¼ä¸€è‡´æ€§
â”‚   â””â”€â”€ batch_process.py            # æ‰¹é‡å¤„ç†å¤šä¸ªé¡¹ç›®
â”‚
â”œâ”€â”€ tests/                          # æµ‹è¯•ç”¨ä¾‹
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_scanner.py
â”‚   â”œâ”€â”€ test_analyzer.py
â”‚   â”œâ”€â”€ test_generator.py
â”‚   â”œâ”€â”€ test_format_guard.py
â”‚   â””â”€â”€ test_integration.py
â”‚
â”œâ”€â”€ utils/                          # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ llm_client.py               # LLM å®¢æˆ·ç«¯å°è£…
â”‚   â”œâ”€â”€ latex_parser.py             # LaTeX è§£æå·¥å…·
â”‚   â”œâ”€â”€ bibtex_parser.py            # BibTeX è§£æå·¥å…·
â”‚   â””â”€â”€ file_utils.py               # æ–‡ä»¶æ“ä½œå·¥å…·
â”‚
â”œâ”€â”€ runs/                           # ğŸ†• æ‰€æœ‰è¿è¡Œè¾“å‡ºï¼ˆéš”ç¦»é¡¹ç›®æ±¡æŸ“ï¼‰
â”‚   â”œâ”€â”€ <run_id>/                   # æ¯æ¬¡è¿è¡Œçš„å”¯ä¸€ ID
â”‚   â”‚   â”œâ”€â”€ backups/                # å¤‡ä»½æ–‡ä»¶
â”‚   â”‚   â”‚   â””â”€â”€ extraTex_1.2.å†…å®¹ç›®æ ‡é—®é¢˜.tex.backup
â”‚   â”‚   â”œâ”€â”€ logs/                   # æ—¥å¿—æ–‡ä»¶
â”‚   â”‚   â”‚   â”œâ”€â”€ execution.log       # æ‰§è¡Œæ—¥å¿—
â”‚   â”‚   â”‚   â”œâ”€â”€ format_check.log    # æ ¼å¼æ£€æŸ¥æ—¥å¿—
â”‚   â”‚   â”‚   â””â”€â”€ compile.log         # ç¼–è¯‘æ—¥å¿—
â”‚   â”‚   â”œâ”€â”€ analysis/               # AI åˆ†æç»“æœç¼“å­˜
â”‚   â”‚   â”‚   â”œâ”€â”€ section_themes.json
â”‚   â”‚   â”‚   â””â”€â”€ resource_scores.json
â”‚   â”‚   â”œâ”€â”€ output/                 # ç”Ÿæˆçš„è¾“å‡ºæ–‡ä»¶
â”‚   â”‚   â”‚   â”œâ”€â”€ preview/            # é¢„è§ˆæ¨¡å¼è¾“å‡º
â”‚   â”‚   â”‚   â”œâ”€â”€ applied/            # åº”ç”¨æ¨¡å¼è¾“å‡º
â”‚   â”‚   â”‚   â””â”€â”€ report/             # æŠ¥å‘Šæ¨¡å¼è¾“å‡º
â”‚   â”‚   â””â”€â”€ metadata.json           # è¿è¡Œå…ƒæ•°æ®
â”‚   â””â”€â”€ latest -> <run_id>          # è½¯é“¾æ¥æŒ‡å‘æœ€æ–°è¿è¡Œ
â”‚
â”œâ”€â”€ workspace/                      # ä¸´æ—¶å·¥ä½œç©ºé—´
â”‚   â”œâ”€â”€ temp/                       # ä¸´æ—¶æ–‡ä»¶
â”‚   â””â”€â”€ cache/                      # ç¼“å­˜æ–‡ä»¶
â”‚
â””â”€â”€ examples/                       # ä½¿ç”¨ç¤ºä¾‹
    â”œâ”€â”€ basic_usage.py
    â””â”€â”€ advanced_usage.py
```

---

## 7. é…ç½®æ–‡ä»¶è®¾è®¡

### 7.1 config.yaml

```yaml
skill_info:
  name: complete_example
  version: 1.0.0
  description: AI å¢å¼ºç‰ˆ LaTeX ç¤ºä¾‹æ™ºèƒ½ç”Ÿæˆå™¨
  author: "ChineseResearchLaTeX Project"

# ========== LLM é…ç½® ==========
llm:
  provider: "claude"  # claude / openai / local
  model: "claude-sonnet-4-20250514"  # æˆ– gpt-4
  api_key_env: "ANTHROPIC_API_KEY"  # ç¯å¢ƒå˜é‡å
  temperature:
    analysis: 0.3    # åˆ†æä»»åŠ¡ï¼ˆä½æ¸©åº¦ï¼Œç¨³å®šï¼‰
    generation: 0.8  # ç”Ÿæˆä»»åŠ¡ï¼ˆé«˜æ¸©åº¦ï¼Œåˆ›é€ æ€§ï¼‰
    refinement: 0.5  # ä¼˜åŒ–ä»»åŠ¡ï¼ˆä¸­æ¸©åº¦ï¼‰
  max_tokens: 4000

# ========== å‚æ•°å®šä¹‰ ==========
parameters:
  project:
    type: string
    required: true
    description: é¡¹ç›®åç§°æˆ–è·¯å¾„

  content_density:
    type: string
    allowed_values: ["minimal", "moderate", "comprehensive"]
    default: "moderate"
    description: |
      minimal:    æ¯ç« èŠ‚ 2 ä¸ªèµ„æºï¼Œ200 å­—
      moderate:   æ¯ç« èŠ‚ 4 ä¸ªèµ„æºï¼Œ300 å­—
      comprehensive: æ¯ç« èŠ‚ 6 ä¸ªèµ„æºï¼Œ500 å­—

  output_mode:
    type: string
    allowed_values: ["preview", "apply", "report"]
    default: "preview"
    description: |
      preview:  åªæ˜¾ç¤ºé¢„è§ˆï¼Œä¸ä¿®æ”¹æ–‡ä»¶
      apply:    ç›´æ¥ä¿®æ”¹æ–‡ä»¶ï¼ˆæœ‰å¤‡ä»½ï¼‰
      report:   ç”Ÿæˆè¯¦ç»†æŠ¥å‘Šæ–‡ä»¶

  target_files:
    type: array
    default: null
    description: |
      ç›®æ ‡æ–‡ä»¶åˆ—è¡¨ï¼ˆç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•ï¼‰
      null è¡¨ç¤ºè‡ªåŠ¨æ£€æµ‹æ‰€æœ‰ extraTex/*.tex

  narrative_hint:
    type: string
    default: null
    description: |
      ç”¨æˆ·è‡ªå®šä¹‰çš„å™äº‹æç¤ºï¼Œç”¨äºæŒ‡å¯¼ AI ç”Ÿæˆç‰¹å®šé£æ ¼çš„ç¤ºä¾‹å†…å®¹ã€‚
      è¿™æ˜¯"ç¤ºä¾‹åœºæ™¯"è€Œé"ä¸¥è‚ƒåœºæ™¯"ï¼Œå› æ­¤ AI å¯ä»¥æ ¹æ®æç¤ºç¼–é€ ç›¸åº”çš„å™äº‹ã€‚
      ç¤ºä¾‹ï¼š
        - "ç”Ÿæˆä¸€ä¸ªå…³äºæ·±åº¦å­¦ä¹ åœ¨åŒ»ç–—å½±åƒåˆ†æä¸­åº”ç”¨çš„ç¤ºä¾‹"
        - "åˆ›å»ºä¸€ä¸ªä½¿ç”¨ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ–¹æ³•çš„ç¤ºä¾‹ç ”ç©¶"
        - "ç¼–å†™ä¸€ä¸ªå…³äºææ–™ç§‘å­¦å®éªŒè®¾è®¡çš„ç¤ºä¾‹ï¼Œé‡ç‚¹å…³æ³¨ XRD è¡¨å¾"
        - "æ¨¡æ‹Ÿä¸€ä¸ªå¤šä¸­å¿ƒä¸´åºŠè¯•éªŒçš„è®¾è®¡ä¸åˆ†ææµç¨‹"
      null è¡¨ç¤º AI æ ¹æ®ç« èŠ‚ä¸»é¢˜è‡ªåŠ¨æ¨æ–­å™äº‹æ–¹å‘ã€‚

# ========== ğŸ†• è¿è¡Œç®¡ç†é…ç½® ==========
run_management:
  # è¿è¡Œè¾“å‡ºæ ¹ç›®å½•ï¼ˆæ‰€æœ‰è¾“å‡ºéƒ½æ”¾åœ¨è¿™é‡Œï¼Œä¸æ±¡æŸ“é¡¹ç›®ï¼‰
  runs_root: "skills/complete_example/runs"

  # è¿è¡Œ ID ç”Ÿæˆç­–ç•¥
  run_id_strategy: "timestamp_uuid"  # timestamp_uuid / sequential / custom

  # ä¿ç•™ç­–ç•¥
  retention:
    max_runs: 50              # æœ€å¤šä¿ç•™ 50 æ¬¡è¿è¡Œè®°å½•
    max_age_days: 30          # æœ€å¤šä¿ç•™ 30 å¤©
    auto_cleanup: true        # è‡ªåŠ¨æ¸…ç†è¿‡æœŸè®°å½•

  # å¤‡ä»½ç­–ç•¥
  backup:
    location: "runs/{run_id}/backups"  # ğŸ†• å¤‡ä»½ä½ç½®ï¼ˆä¸åœ¨é¡¹ç›®ç›®å½•ï¼‰
    compress: false                    # æ˜¯å¦å‹ç¼©å¤‡ä»½æ–‡ä»¶
    format: "tar.gz"                   # å‹ç¼©æ ¼å¼ï¼ˆå¦‚æœå¯ç”¨å‹ç¼©ï¼‰

  # æ—¥å¿—ç­–ç•¥
  logging:
    location: "runs/{run_id}/logs"     # ğŸ†• æ—¥å¿—ä½ç½®ï¼ˆä¸åœ¨é¡¹ç›®ç›®å½•ï¼‰
    level: "INFO"                      # æ—¥å¿—çº§åˆ«
    rotation: true                     # æ—¥å¿—è½®è½¬
    max_size_mb: 10                    # å•ä¸ªæ—¥å¿—æ–‡ä»¶æœ€å¤§å¤§å°

# ========== èµ„æºæ‰«æé…ç½® ==========
scan:
  targets:
    - name: "figures"
      enabled: true
      patterns: ["*.jpg", "*.jpeg", "*.png", "*.pdf", "*.eps"]
      extract_metadata: true

    - name: "code"
      enabled: true
      patterns: ["*.py", "*.m", "*.r", "*.cpp", "*.c"]
      max_lines: 100  # è¶…è¿‡æ­¤è¡Œæ•°åªæˆªå–ç‰‡æ®µ

    - name: "references"
      enabled: true
      patterns: ["*.bib"]
      parse_entries: true

# ========== å†…å®¹ç”Ÿæˆé…ç½® ==========
generation:
  # èµ„æºé€‰æ‹©ç­–ç•¥
  selection_strategy: "ai_score"  # ai_score / random / manual

  # ç›¸å…³æ€§é˜ˆå€¼
  relevance_threshold: 0.5

  # æ¯ç§èµ„æºç±»å‹çš„æ•°é‡é™åˆ¶
  max_figures_per_section: 2
  max_code_per_section: 1
  max_references_per_section: 3

  # å†…å®¹æ¨¡æ¿
  templates:
    figure_insertion: |
      \begin{{figure}}[htbp]
        \centering
        \includegraphics[width=0.8\textwidth]{{{path}}}
        \caption{{{caption}}}
        \label{{{label}}}
      \end{{figure}}

    code_listing: |
      \begin{{lstlisting}}[language={lang}, caption={caption}, firstline=1, lastline={lastline}]
      {code}
      \end{{lstlisting}}

    reference_citation: "\cite{{{citekey}}}"

# ========== æ ¼å¼ä¿æŠ¤é…ç½® ==========
format_protection:
  # å—ä¿æŠ¤çš„ LaTeX å‘½ä»¤
  protected_commands:
    - "\\setlength"
    - "\\geometry"
    - "\\definecolor"
    - "\\setCJKfamilyfont"
    - "\\setmainfont"
    - "\\titleformat"
    - "\\setlist"
    - "\\newcommand"
    - "\\renewcommand"

  # å—ä¿æŠ¤çš„æ–‡ä»¶ï¼ˆç»å¯¹ä¸ä¿®æ”¹ï¼‰
  protected_files:
    - "extraTex/@config.tex"
    - "main.tex"

  # å¤‡ä»½ç­–ç•¥
  backup:
    enabled: true
    keep_count: 5  # ä¿ç•™æœ€è¿‘ 5 ä¸ªå¤‡ä»½

  # ç¼–è¯‘éªŒè¯
  compile_verify:
    enabled: true
    engine: "xelatex"
    timeout: 60  # ç§’

# ========== AI æç¤ºè¯æ¨¡æ¿ ==========
prompts:
  analyze_theme: |
    ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å­¦æœ¯å†™ä½œåˆ†æä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹ LaTeX ç« èŠ‚çš„å†…å®¹ä¸»é¢˜ã€‚

    ç« èŠ‚å†…å®¹ï¼ˆå‰ {max_chars} å­—ç¬¦ï¼‰ï¼š
    {content}

    è¯·è¿”å› JSON æ ¼å¼çš„åˆ†æç»“æœï¼š
    {{
      "theme": "ç« èŠ‚çš„æ ¸å¿ƒä¸»é¢˜ï¼ˆä¸€å¥è¯æ¦‚æ‹¬ï¼‰",
      "key_concepts": ["å…³é”®æ¦‚å¿µ1", "å…³é”®æ¦‚å¿µ2", "å…³é”®æ¦‚å¿µ3"],
      "writing_style": "å­¦æœ¯/æŠ€æœ¯/è¯´æ˜/æ··åˆ",
      "suggested_resources": ["å»ºè®®çš„å›¾ç‰‡ç±»å‹", "å»ºè®®çš„æ–‡çŒ®é¢†åŸŸ"],
      "tone": "æ­£å¼/åŠæ­£å¼/é€šä¿—",
      "target_audience": "è¯„å®¡ä¸“å®¶/åŒè¡Œ/å­¦ç”Ÿ/å¤§ä¼—"
    }}

  reason_relevance: |
    ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å­¦æœ¯å†™ä½œé¡¾é—®ã€‚è¯·è¯„ä¼°ä»¥ä¸‹èµ„æºæ˜¯å¦é€‚åˆç”¨äºæŒ‡å®šç« èŠ‚ã€‚

    ç« èŠ‚ä¿¡æ¯ï¼š
    - ä¸»é¢˜ï¼š{section_theme}
    - å…³é”®æ¦‚å¿µï¼š{key_concepts}
    - å†™ä½œé£æ ¼ï¼š{writing_style}

    èµ„æºä¿¡æ¯ï¼š
    - è·¯å¾„ï¼š{resource_path}
    - ç±»å‹ï¼š{resource_type}
    - å…ƒæ•°æ®ï¼š{metadata}

    è¯·è¿”å› JSON æ ¼å¼çš„è¯„ä¼°ç»“æœï¼š
    {{
      "relevance_score": 0.85,
      "reason": "è¯¦ç»†è¯´æ˜ç†ç”±ï¼ˆ100-200å­—ï¼‰",
      "suggested_usage": "å»ºè®®å¦‚ä½•ä½¿ç”¨è¿™ä¸ªèµ„æº"
    }}

  generate_narrative: |
    ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„ç§‘ç ”å†™ä½œåŠ©æ‰‹ï¼Œä¸“ç²¾äºå›½å®¶è‡ªç„¶ç§‘å­¦åŸºé‡‘ç”³è¯·ä¹¦çš„æ’°å†™ã€‚

    æ ¹æ®ä»¥ä¸‹ä¿¡æ¯ï¼Œç”Ÿæˆä¸€æ®µè¿è´¯çš„ç¤ºä¾‹å†…å®¹ã€‚

    ## ç« èŠ‚ä¿¡æ¯
    - ä¸»é¢˜ï¼š{theme}
    - å…³é”®æ¦‚å¿µï¼š{key_concepts}
    - å†™ä½œé£æ ¼ï¼š{writing_style}
    - ç›®æ ‡è¯»è€…ï¼š{target_audience}

    ## ç”¨æˆ·å™äº‹æç¤º
    {narrative_hint}

    ## ä¸Šä¸‹æ–‡ç‰‡æ®µ
    {context}

    ## å¯ç”¨èµ„æº
    {resources}

    ## ç”Ÿæˆè¦æ±‚
    1. ç”Ÿæˆ {target_length} å­—çš„ç¤ºä¾‹æ®µè½
    2. è‡ªç„¶åœ°å¼•ç”¨èµ„æº
    3. ä½¿ç”¨æ­£å¼çš„å­¦æœ¯å†™ä½œé£æ ¼
    4. **é‡è¦**ï¼šæ ¹æ®ã€ç”¨æˆ·å™äº‹æç¤ºã€‘è°ƒæ•´å†…å®¹æ–¹å‘å’Œé£æ ¼
    5. **å…è®¸ç¼–é€ **ï¼šè¿™æ˜¯ç¤ºä¾‹åœºæ™¯ï¼Œå¯ä»¥æ ¹æ®æç¤ºç¼–é€ åˆç†çš„ç ”ç©¶å†…å®¹ã€æ•°æ®å’Œç»“è®º
    6. åœ¨åº”è¯¥æ’å…¥ LaTeX ä»£ç çš„åœ°æ–¹ç”¨ {{PLACEHOLDER:èµ„æºè·¯å¾„}} æ ‡è®°

    åªè¿”å›ç”Ÿæˆçš„æ–‡æœ¬ï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚

# ========== è´¨é‡è¯„ä¼°æ ‡å‡† ==========
quality_thresholds:
  coherence_min: 0.8        # è¿è´¯æ€§æœ€ä½è¦æ±‚
  academic_tone_min: 0.75   # å­¦æœ¯é£æ ¼æœ€ä½è¦æ±‚
  overall_score_min: 0.8    # æ€»ä½“è¯„åˆ†æœ€ä½è¦æ±‚

# ========== æ—¥å¿—é…ç½® ==========
# ğŸš« å·²åºŸå¼ƒï¼Œä½¿ç”¨ run_management.logging æ›¿ä»£ï¼ˆé¿å…æ±¡æŸ“é¡¹ç›®ç›®å½•ï¼‰
# æ—§é…ç½®ä¼šåœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º .complete_example.logï¼Œå·²å¼ƒç”¨
# æ–°é…ç½®å°†æ—¥å¿—æ”¾åœ¨ runs/<run_id>/logs/ ä¸­
# logging:
#   level: "INFO"
#   file: ".complete_example.log"  # âŒ æ—§è®¾è®¡ï¼Œä¼šæ±¡æŸ“é¡¹ç›®
```

---

## 8. æµ‹è¯•ç­–ç•¥

### 8.1 å•å…ƒæµ‹è¯•

```python
# tests/test_scanner.py
def test_resource_scanner():
    """æµ‹è¯•èµ„æºæ‰«æå™¨"""
    scanner = ResourceScanner(Path("projects/NSFC_Young"))
    report = scanner.scan_all()

    assert report.summary["total_figures"] >= 0
    assert report.summary["total_code"] >= 0
    assert isinstance(report.figures, list)

# tests/test_analyzer.py
def test_semantic_analyzer():
    """æµ‹è¯•è¯­ä¹‰åˆ†æå™¨ï¼ˆéœ€è¦ mock LLMï¼‰"""
    analyzer = SemanticAnalyzer(mock_llm_client)
    content = read_file("projects/NSFC_Young/extraTex/1.2.å†…å®¹ç›®æ ‡é—®é¢˜.tex")
    theme = analyzer.analyze_section_theme(content)

    assert theme.theme is not None
    assert len(theme.key_concepts) >= 2
    assert theme.writing_style in ["å­¦æœ¯", "æŠ€æœ¯", "è¯´æ˜", "æ··åˆ"]

# tests/test_format_guard.py
def test_format_guard():
    """æµ‹è¯•æ ¼å¼ä¿æŠ¤å™¨"""
    guard = FormatGuard(Path("projects/NSFC_Young"))

    # æµ‹è¯•å—ä¿æŠ¤æ¨¡å¼æå–
    content = "\\setlength{\\parindent}{2em}\\some other text"
    zones = guard.extract_protected_zones(content)
    assert len(zones) == 1
    assert zones[0].content == "\\setlength{\\parindent}{2em}"

    # æµ‹è¯•å—ä¿æŠ¤æ–‡ä»¶
    assert "extraTex/@config.tex" in FormatGuard.PROTECTED_FILES
```

### 8.2 é›†æˆæµ‹è¯•

```python
# tests/test_integration.py
def test_full_workflow_preview():
    """æµ‹è¯•å®Œæ•´å·¥ä½œæµï¼ˆé¢„è§ˆæ¨¡å¼ï¼‰"""
    skill = CompleteExampleSkill(test_config)
    result = skill.execute(
        project_name="NSFC_Young",
        options={"output_mode": "preview"}
    )

    assert result["final_result"] == "success"
    assert "scan" in result["stages"]
    assert "analyze" in result["stages"]
    assert "generate" in result["stages"]

def test_full_workflow_apply():
    """æµ‹è¯•å®Œæ•´å·¥ä½œæµï¼ˆåº”ç”¨æ¨¡å¼ï¼‰"""
    # éœ€è¦æµ‹è¯•é¡¹ç›®å‰¯æœ¬
    with TemporaryDirectory() as tmpdir:
        # å¤åˆ¶æµ‹è¯•é¡¹ç›®
        test_project = copy_test_project(tmpdir)

        skill = CompleteExampleSkill(test_config)
        result = skill.execute(
            project_name=test_project,
            options={"output_mode": "apply"}
        )

        assert result["final_result"] == "success"

        # éªŒè¯æ–‡ä»¶è¢«ä¿®æ”¹
        assert file_was_modified(test_project, "extraTex/1.2.å†…å®¹ç›®æ ‡é—®é¢˜.tex")

        # éªŒè¯æ ¼å¼æ–‡ä»¶æœªè¢«ä¿®æ”¹
        assert format_file_unchanged(test_project, "extraTex/@config.tex")
```

### 8.3 AI èƒ½åŠ›æµ‹è¯•

```python
# tests/test_ai_capabilities.py
def test_ai_topic_understanding():
    """æµ‹è¯• AI çš„ä¸»é¢˜ç†è§£èƒ½åŠ›"""
    analyzer = SemanticAnalyzer(real_llm_client)

    # æµ‹è¯•ç”¨ä¾‹ 1ï¼šç ”ç©¶å†…å®¹ç« èŠ‚
    content1 = "\\subsubsection{ç ”ç©¶å†…å®¹}\næœ¬ç ”ç©¶..."
    theme1 = analyzer.analyze_section_theme(content1)
    assert "ç ”ç©¶å†…å®¹" in theme1.theme or "ç ”ç©¶" in theme1.theme

    # æµ‹è¯•ç”¨ä¾‹ 2ï¼šç‰¹è‰²ä¸åˆ›æ–°ç« èŠ‚
    content2 = "\\subsubsection{ç‰¹è‰²ä¸åˆ›æ–°}\næœ¬é¡¹ç›®åˆ›æ–°ç‚¹..."
    theme2 = analyzer.analyze_section_theme(content2)
    assert "åˆ›æ–°" in theme2.theme or "ç‰¹è‰²" in theme2.theme

def test_ai_resource_reasoning():
    """æµ‹è¯• AI çš„èµ„æºæ¨ç†èƒ½åŠ›"""
    analyzer = SemanticAnalyzer(real_llm_client)

    theme = SectionTheme(
        theme="ç ”ç©¶æ–¹æ³•ä¸å®éªŒè®¾è®¡",
        key_concepts=["å®éªŒè£…ç½®", "æ•°æ®é‡‡é›†"],
        writing_style="å­¦æœ¯"
    )

    # æµ‹è¯•å›¾ç‰‡æ¨ç†
    figure_resource = ResourceInfo(
        path="figures/experimental-setup.jpg",
        type="figure",
        filename="experimental-setup.jpg",
        metadata={}
    )

    relevance = analyzer.reason_resource_relevance(figure_resource, theme)
    assert relevance.relevance_score > 0.5  # åº”è¯¥ç›¸å…³
    assert len(relevance.reason) > 50  # åº”è¯¥æœ‰è¯¦ç»†ç†ç”±

def test_ai_content_quality():
    """æµ‹è¯• AI ç”Ÿæˆå†…å®¹çš„è´¨é‡"""
    generator = AIContentGenerator(mock_llm, templates, mock_guard)

    content = generator.generate_section_content(
        resources=test_resources,
        section_theme=test_theme,
        existing_content=test_existing_content,
        content_density="moderate"
    )

    # éªŒè¯å†…å®¹åŒ…å«å¿…è¦çš„å…ƒç´ 
    assert len(content) > 200  # åº”è¯¥æœ‰è¶³å¤Ÿé•¿åº¦
    assert "\\includegraphics" in content or "\\cite" in content  # åº”è¯¥åŒ…å«èµ„æºå¼•ç”¨
```

---

## 9. å¼€å‘é‡Œç¨‹ç¢‘

### Phase 1: åŸºç¡€æ¶æ„ï¼ˆ1-2 å¤©ï¼‰
- [ ] åˆ›å»ºç›®å½•ç»“æ„
- [ ] ç¼–å†™ SKILL.md åˆç¨¿
- [ ] åˆ›å»º config.yaml
- [ ] å®ç° LLM å®¢æˆ·ç«¯å°è£…

### Phase 2: ç¡¬ç¼–ç å±‚ï¼ˆ2-3 å¤©ï¼‰
- [ ] å®ç° ResourceScanner
- [ ] å®ç° FormatGuard
- [ ] å®ç°å·¥å…·å‡½æ•°ï¼ˆLaTeX è§£æã€BibTeX è§£æç­‰ï¼‰
- [ ] ç¼–å†™å•å…ƒæµ‹è¯•

### Phase 3: AI æ™ºèƒ½å±‚ï¼ˆ3-4 å¤©ï¼‰
- [ ] å®ç° SemanticAnalyzer
- [ ] å®ç° AIContentGenerator
- [ ] è®¾è®¡å’Œä¼˜åŒ–æç¤ºè¯
- [ ] ç¼–å†™ AI èƒ½åŠ›æµ‹è¯•

### Phase 4: é›†æˆä¸å·¥ä½œæµï¼ˆ2-3 å¤©ï¼‰
- [ ] å®ç° CompleteExampleSkill ä¸»æ§åˆ¶å™¨
- [ ] å®ç°å®Œæ•´å·¥ä½œæµ
- [ ] ç¼–å†™é›†æˆæµ‹è¯•
- [ ] ä¼˜åŒ–é”™è¯¯å¤„ç†å’Œæ—¥å¿—

### Phase 5: æ–‡æ¡£ä¸ç¤ºä¾‹ï¼ˆ1-2 å¤©ï¼‰
- [ ] å®Œå–„ SKILL.md
- [ ] ç¼–å†™ README.md
- [ ] åˆ›å»ºä½¿ç”¨ç¤ºä¾‹
- [ ] ç¼–å†™æœ€ä½³å®è·µæ–‡æ¡£

### Phase 6: æµ‹è¯•ä¸ä¼˜åŒ–ï¼ˆ2-3 å¤©ï¼‰
- [ ] åœ¨ NSFC_Young ä¸Šå®æˆ˜æµ‹è¯•
- [ ] åœ¨ NSFC_General ä¸Šæµ‹è¯•
- [ ] æ€§èƒ½ä¼˜åŒ–
- [ ] ä¿®å¤ bug

**æ€»è®¡ï¼š11-17 å¤©**

---

## 10. é£é™©ä¸å¯¹ç­–

| é£é™© | å½±å“ | æ¦‚ç‡ | å¯¹ç­– |
|------|------|------|------|
| **AI ç”Ÿæˆè´¨é‡ä¸ç¨³å®š** | é«˜ | ä¸­ | 1. ä½¿ç”¨ä½æ¸©åº¦å‚æ•°<br>2. å¤šæ¬¡ç”Ÿæˆå–æœ€ä½³<br>3. äººå·¥å®¡æ ¸æœºåˆ¶ |
| **æ ¼å¼è¢«æ„å¤–ä¿®æ”¹** | é«˜ | ä½ | 1. FormatGuard ä¸¥æ ¼ä¿æŠ¤<br>2. å“ˆå¸ŒéªŒè¯<br>3. è‡ªåŠ¨å¤‡ä»½å›æ»š |
| **LLM API æˆæœ¬è¿‡é«˜** | ä¸­ | ä¸­ | 1. ç¼“å­˜åˆ†æç»“æœ<br>2. ä½¿ç”¨æ›´ä¾¿å®œçš„æ¨¡å‹<br>3. æ‰¹é‡å¤„ç†ä¼˜åŒ– |
| **ç¼–è¯‘å¤±è´¥** | é«˜ | ä½ | 1. ç¼–è¯‘å‰éªŒè¯è¯­æ³•<br>2. è‡ªåŠ¨å›æ»š<br>3. é”™è¯¯æ—¥å¿—åˆ†æ |
| **ç”Ÿæˆå†…å®¹ä¸è¿è´¯** | ä¸­ | ä¸­ | 1. AI è‡ªæˆ‘å®¡æŸ¥<br>2. è´¨é‡é˜ˆå€¼è¿‡æ»¤<br>3. äººå·¥åé¦ˆæœºåˆ¶ |
| **è¦†ç›–ç”¨æˆ·å†…å®¹** | é«˜ | æä½ | 1. é»˜è®¤é¢„è§ˆæ¨¡å¼<br>2. ä»…åœ¨æ ‡è®°åŒºåŸŸæ’å…¥<br>3. æ˜ç¡®ç¡®è®¤æœºåˆ¶ |

---

## 11. ä¸ç°æœ‰ Skill çš„å¯¹æ¯”

| ç‰¹æ€§ | make_latex_model | complete_example | äº’è¡¥æ€§ |
|------|------------------|------------------|--------|
| **æ ¸å¿ƒç›®æ ‡** | æ ¼å¼é«˜ä¿çœŸä¼˜åŒ– | å†…å®¹å®Œæ•´ç¤ºä¾‹ç”Ÿæˆ | âœ… äº’è¡¥ |
| **ä¸»è¦è¾“å…¥** | Word PDF åŸºå‡† | é¡¹ç›®èµ„æºæ–‡ä»¶ | âœ… ä¸åŒ |
| **è¾“å‡º** | æ ¼å¼å¯¹é½çš„ LaTeX | å†…å®¹ä¸°å¯Œçš„ç¤ºä¾‹ | âœ… äº’è¡¥ |
| **æ ¼å¼ä¿®æ”¹** | æ˜¯ï¼ˆç²¾ç¡®å¯¹é½ï¼‰ | å¦ï¼ˆä¸¥æ ¼ä¿æŠ¤ï¼‰ | âœ… èŒè´£åˆ†ç¦» |
| **AI åˆ©ç”¨** | ä½ï¼ˆè§„åˆ™é©±åŠ¨ï¼‰ | é«˜ï¼ˆè¯­ä¹‰é©±åŠ¨ï¼‰ | âœ… èƒ½åŠ›äº’è¡¥ |
| **ä½¿ç”¨åœºæ™¯** | æ ¼å¼è°ƒè¯• | æ–°å»º/è¡¥å……ç¤ºä¾‹ | âœ… é˜¶æ®µäº’è¡¥ |
| **æ¨èæµç¨‹** | â‘  complete_example â†’ â‘¡ make_latex_model | âœ… ä¸²è”ä½¿ç”¨ |

---

## 12. æ€»ç»“

### 12.1 æ ¸å¿ƒä¼˜åŠ¿

1. **AI å……åˆ†å‘æŒ¥**ï¼šè¯­ä¹‰ç†è§£ã€æ™ºèƒ½æ¨ç†ã€åˆ›é€ æ€§ç”Ÿæˆã€è‡ªæˆ‘ä¼˜åŒ–
2. **ç¡¬ç¼–ç ä¿éšœå®‰å…¨**ï¼šæ ¼å¼ä¿æŠ¤ã€ç¼–è¯‘éªŒè¯ã€å¤‡ä»½å›æ»š
3. **æœ‰æœºåä½œ**ï¼šAI æä¾›æ™ºèƒ½ â†’ ç¡¬ç¼–ç ä¿éšœå®‰å…¨ â†’ AI ä¼˜åŒ–è´¨é‡
4. **å¯è¿½æº¯æ€§**ï¼šæ‰€æœ‰å†³ç­–éƒ½æœ‰ AI è§£é‡Šï¼Œå¯å®¡æŸ¥
5. **å¯é…ç½®æ€§**ï¼šé€šè¿‡ YAML é…ç½®çµæ´»æ§åˆ¶

### 12.2 AI åˆ©ç”¨ç‡

```
åŸè®¡åˆ’ï¼šğŸŸ¥ 15%ï¼ˆæ¨¡æ¿æ›¿æ¢ï¼‰
AI å¢å¼ºç‰ˆï¼šğŸŸ¢ 70%ï¼ˆè¯­ä¹‰ç†è§£ + æ™ºèƒ½ç”Ÿæˆ + è‡ªæˆ‘ä¼˜åŒ–ï¼‰
æå‡å¹…åº¦ï¼š+366%
```

### 12.3 ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. âœ… **ç”¨æˆ·ç¡®è®¤è®¡åˆ’**
2. åˆ›å»ºç›®å½•ç»“æ„
3. å®ç° LLM å®¢æˆ·ç«¯å°è£…
4. å®ç° ResourceScannerï¼ˆç¡¬ç¼–ç å±‚ï¼‰
5. å®ç° FormatGuardï¼ˆç¡¬ç¼–ç å±‚ï¼‰
6. å®ç° SemanticAnalyzerï¼ˆAI å±‚ï¼‰
7. å®ç° AIContentGeneratorï¼ˆAI å±‚ï¼‰
8. å®ç° CompleteExampleSkillï¼ˆä¸»æ§åˆ¶å™¨ï¼‰
9. ç¼–å†™æµ‹è¯•ç”¨ä¾‹
10. åœ¨ NSFC_Young ä¸Šå®æˆ˜æµ‹è¯•
11. ç¼–å†™æ–‡æ¡£
12. å‘å¸ƒ v1.0.0

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.2
**æœ€åæ›´æ–°**: 2026-01-07 15:00
**çŠ¶æ€**: å·²ä¼˜åŒ–ï¼ˆæ–°å¢ç”¨æˆ·è‡ªå®šä¹‰å™äº‹æç¤ºæ”¯æŒ + è¿è¡Œç›®å½•éš”ç¦»è®¾è®¡ï¼‰

## v1.2 æ›´æ–°å†…å®¹

### ğŸ†• è¿è¡Œç›®å½•éš”ç¦»ï¼ˆé›¶é¡¹ç›®æ±¡æŸ“ï¼‰

**æ ¸å¿ƒæ”¹è¿›**ï¼šæ‰€æœ‰è¿è¡Œè¾“å‡ºï¼ˆå¤‡ä»½ã€æ—¥å¿—ã€åˆ†æç»“æœç­‰ï¼‰éƒ½æ”¾åœ¨ `skills/complete_example/runs/<run_id>/` ç›®å½•ä¸­ï¼Œ**å®Œå…¨ä¸å¯¹é¡¹ç›®ç›®å½•é€ æˆä»»ä½•æ±¡æŸ“**ã€‚

**å…·ä½“å˜æ›´**ï¼š

| ç»„ä»¶ | æ—§è®¾è®¡ | æ–°è®¾è®¡ | ä¼˜åŠ¿ |
|------|--------|--------|------|
| **å¤‡ä»½æ–‡ä»¶** | `é¡¹ç›®ç›®å½•/æ–‡ä»¶.backup` | `runs/<run_id>/backups/æ–‡ä»¶.backup` | âœ… é¡¹ç›®ç›®å½•å¹²å‡€ |
| **æ—¥å¿—æ–‡ä»¶** | `é¡¹ç›®ç›®å½•/.complete_example.log` | `runs/<run_id>/logs/execution.log` | âœ… é¡¹ç›®ç›®å½•å¹²å‡€ |
| **åˆ†æç¼“å­˜** | æ— ç¼“å­˜ | `runs/<run_id>/analysis/` | âœ… å¯è¿½æº¯ã€å¯å¤ç° |
| **è¿è¡Œå…ƒæ•°æ®** | æ—  | `runs/<run_id>/metadata.json` | âœ… å®Œæ•´è®°å½• |
| **è½¯é“¾æ¥** | æ—  | `runs/latest -> <run_id>` | âœ… å¿«é€Ÿè®¿é—®æœ€æ–°è¿è¡Œ |

**è¿è¡Œç›®å½•ç»“æ„**ï¼š
```
skills/complete_example/runs/
â”œâ”€â”€ 20260107_150000_a3b4c5d6/          # è¿è¡Œ ID
â”‚   â”œâ”€â”€ backups/                         # å¤‡ä»½æ–‡ä»¶
â”‚   â”œâ”€â”€ logs/                            # æ—¥å¿—æ–‡ä»¶
â”‚   â”œâ”€â”€ analysis/                        # AI åˆ†æç»“æœ
â”‚   â”œâ”€â”€ output/                          # è¾“å‡ºæ–‡ä»¶
â”‚   â””â”€â”€ metadata.json                    # è¿è¡Œå…ƒæ•°æ®
â””â”€â”€ latest -> 20260107_150000_a3b4c5d6   # è½¯é“¾æ¥
```

### ğŸ†• é…ç½®æ–‡ä»¶å¢å¼º

æ–°å¢ `run_management` é…ç½®èŠ‚ï¼Œæ§åˆ¶è¿è¡Œç›®å½•è¡Œä¸ºï¼š

```yaml
run_management:
  runs_root: "skills/complete_example/runs"
  retention:
    max_runs: 50
    max_age_days: 30
    auto_cleanup: true
  backup:
    location: "runs/{run_id}/backups"
  logging:
    location: "runs/{run_id}/logs"
```

### ğŸ”§ ä»£ç å˜æ›´

- `FormatGuard.__init__(project_path, run_dir)`ï¼šæ–°å¢ `run_dir` å‚æ•°
- `FormatGuard.safe_modify_file()`ï¼šå¤‡ä»½åˆ° `runs/<run_id>/backups/`
- `FormatGuard._log_modification()`ï¼šæ—¥å¿—å†™å…¥ `runs/<run_id>/logs/`
- `CompleteExampleSkill._create_run_directory()`ï¼šğŸ†• æ–°æ–¹æ³•ï¼Œåˆ›å»ºè¿è¡Œç›®å½•
- `CompleteExampleSkill.execute()`ï¼šåˆå§‹åŒ–æ—¶åˆ›å»ºè¿è¡Œç›®å½•
- `_stage_analyze_sections()`ï¼šä¿å­˜åˆ†æç»“æœåˆ°è¿è¡Œç›®å½•
- `_stage_generate_content()`ï¼šä¼ é€’ `run_dir` åˆ° `FormatGuard`
